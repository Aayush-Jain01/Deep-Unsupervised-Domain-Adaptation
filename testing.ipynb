{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **TODO:** finish structuring train, test, main\n",
    "- **TODO:** plot_accuracies_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total no. of images in amazon dataset: 2817\n"
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "\n",
    "# root_dir = \"datasets/office/amazon/images\"\n",
    "# path = \"datasets/office/amazon\"\n",
    "# name_dataset = \"office\"\n",
    "\n",
    "data_domain = \"amazon\"\n",
    "img_size = 224\n",
    "#\n",
    "# Pytorch ImageFolder fits our dataset structure\n",
    "# dataset = datasets.ImageFolder(root=root_dir, transform=data_transform)\n",
    "image_data_folder = datasets.ImageFolder(root= \"datasets/office/%s/images\" % data_domain)\n",
    "print(\"total no. of images in amazon dataset:\",len(image_data_folder))\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.RandomSizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader.py\n",
    "class OfficeAmazonDataset(Dataset):\n",
    "    \"\"\"Class to create an iterable dataset \n",
    "    of images and corresponding labels \"\"\"\n",
    "        \n",
    "    def __init__(self, image_folder_dataset, transform=None):\n",
    "        super(OfficeAmazonDataset, self).__init__()\n",
    "        self.image_folder_dataset = image_folder_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_folder_dataset.imgs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # read image, class from folder_dataset given index\n",
    "        img, img_label = image_folder_dataset[idx][0], image_folder_dataset[idx][1]\n",
    "        \n",
    "        # apply transformations (it already returns them as torch tensors)\n",
    "        if self.transform is not None:\n",
    "            self.transform(img)\n",
    "        \n",
    "        img_label_pair = {\"image\": img,\n",
    "                         \"class\": img_label}\n",
    "        \n",
    "        return img_label_pair\n",
    "\n",
    "def get_dataloader(dataset, batch_size):\n",
    "        \n",
    "    def get_subset(indices, start, end):\n",
    "        return indices[start:start + end]\n",
    "    \n",
    "    # Split train/val data ratios\n",
    "    TRAIN_RATIO, VALIDATION_RATIO = 0.7, 0.3\n",
    "    train_set_size = int(len(dataset) * TRAIN_RATIO)\n",
    "    validation_set_size = int(len(dataset) * VALIDATION_RATIO)\n",
    "\n",
    "    # Generate random indices for train and val sets\n",
    "    indices = torch.randperm(len(dataset))\n",
    "    train_indices = get_subset(indices, 0, train_set_size)\n",
    "    validation_indices = get_subset(indices, train_set_size, validation_set_size)\n",
    "    # test_indices = get_subset(indices, train_count + validation_count, len(dataset))\n",
    "\n",
    "    # Create sampler objects \n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(validation_indices)\n",
    "\n",
    "    # Create data loaders for data\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, \n",
    "                              sampler=train_sampler, num_workers=4)\n",
    "\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_size, \n",
    "                            sampler=val_sampler, num_workers=4)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_dataset = OfficeAmazonDataset(image_folder_dataset=image_data_folder, transform=data_transforms)\n",
    "train_loader, val_loader = get_dataloader(amazon_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean and std of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_mean_std(path_dataset):\n",
    "    \"\"\"\n",
    "    Compute mean and standard deviation of an image dataset.\n",
    "    Acknowledgment : http://forums.fast.ai/t/image-normalization-in-pytorch/7534\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.ImageFolder(root=path_dataset,\n",
    "                                   transform=transform)\n",
    "    # Choose a large batch size to better approximate. Optimally load the dataset entirely on memory.\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=4096, shuffle=False, num_workers=4)\n",
    "\n",
    "    pop_mean = []\n",
    "    pop_std = []\n",
    "\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        # shape (batch_size, 3, height, width)\n",
    "        numpy_image = data[0].numpy()\n",
    "\n",
    "        # shape (3,) -> 3 channels\n",
    "        batch_mean = np.mean(numpy_image, axis=(0, 2, 3))\n",
    "        batch_std = np.std(numpy_image, axis=(0, 2, 3))\n",
    "\n",
    "        pop_mean.append(batch_mean)\n",
    "        pop_std.append(batch_std)\n",
    "\n",
    "    # shape (num_iterations, 3) -> (mean across 0th axis) -> shape (3,)\n",
    "    pop_mean = np.array(pop_mean).mean(axis=0)\n",
    "    pop_std = np.array(pop_std).mean(axis=0)\n",
    "\n",
    "    values = {\n",
    "        'mean': pop_mean,\n",
    "        'std': pop_std\n",
    "    }\n",
    "\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieved from: https://forums.fast.ai/t/image-normalization-in-pytorch/7534/7\n",
    "# this cell takes too much memory and time to compute\n",
    "data_domain = \"amazon\"\n",
    "path_dataset = \"datasets/office/%s/images\" % data_domain\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), # original image size 300x300 pixels\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=path_dataset,\n",
    "                               transform=transform)\n",
    "\n",
    "# set large batch size to get good approximate of mean, std of full dataset\n",
    "data_loader = DataLoader(dataset, batch_size=2048, shuffle=False, num_workers=0) # 4096\n",
    "\n",
    "mean = []\n",
    "std = []\n",
    "\n",
    "# for i, data in enumerate(data_loader, 0):\n",
    "    # shape is (batch_size, channels, height, width)\n",
    "    npy_image = data[0].numpy()\n",
    "    \n",
    "    # compute mean, std per batch shape (3,) three channels\n",
    "    batch_mean = np.mean(npy_image, axis=(0,2,3))\n",
    "    batch_std = np.std(npy_image, axis=(0,2,3))\n",
    "    \n",
    "    mean.append(batch_mean)\n",
    "    std.append(batch_std)\n",
    "    \n",
    "# shape (num_iterations, 3) -> (mean across 0th axis) -> shape (3,)\n",
    "mean = np.array(mean).mean(axis=0) # average over batch averages\n",
    "std = np.arry(std).mean(axis=0) # average over batch stds\n",
    "\n",
    "values = {\n",
    "    \"mean\": mean,\n",
    "    \"std\": std\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing dataloader for office dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataloader import get_office_dataloader\n",
    "amazon_dataloader = get_office_dataloader(\"amazon\", 2048)\n",
    "amazon_dataloader.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# from torch.autograd import Variable, Function\n",
    "# from utils import load_state_dict_from_url\n",
    "# from loss import CORAL_loss\n",
    "\n",
    "\n",
    "class DeepCORAL(nn.Module):\n",
    "\t\"\"\"\n",
    "\tDeepCORAL network as defined in the paper.\n",
    "\tNetwork architecture based on following repository:\n",
    "    https://github.com/SSARCandy/DeepCORAL/blob/master/models.py\n",
    "    :param num_classes: int --> office dataset has 31 different classes\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, num_classes=1000):\n",
    "\t\tsuper(DeepCORAL, self).__init__()\n",
    "\t\tself.sharedNetwork = AlexNet()\n",
    "\t\tself.fc8 = nn.Linear(4096, num_classes) # fc8 activation\n",
    "\n",
    "\t\t# initiliaze fc8 weights according to the CORAL paper (N(0, 0.005))\n",
    "\t\tself.fc8.weight.data.normal_(0.0, 0.005)\n",
    "\n",
    "\tdef forward(self, source, target): # computes activations for BOTH domains\n",
    "\t\tsource = self.sharedNetwork(source)\n",
    "\t\tsource = self.fc8(source)\n",
    "\n",
    "\t\ttarget = self.sharedNetwork(target)\n",
    "\t\ttarget = self.fc8(target)\n",
    "\n",
    "\t\treturn source, target\n",
    "\n",
    "\n",
    "class AlexNet(nn.Module):\n",
    "\t\"\"\"\n",
    "\tAlexNet model obtained from official Pytorch repository:\n",
    "    https://github.com/pytorch/vision/blob/master/torchvision/models/alexnet.py\n",
    "\t\"\"\"\n",
    "\tdef __init__(self, num_classes=1000):\n",
    "\t\tsuper(AlexNet, self).__init__()\n",
    "\n",
    "\t\tself.features = nn.Sequential(\n",
    "\t\t\tnn.Conv2d(in_channels=3, out_channels=64, kernel_size=11, stride=4, padding=2),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\t\t\tnn.Conv2d(in_channels=64, out_channels=192, kernel_size=5, padding=2),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\t\t\tnn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.MaxPool2d(kernel_size=3, stride=2),\n",
    "\t\t)\n",
    "\n",
    "\t\tself.avgpool = nn.AdaptiveAvgPool2d(output_size=(6,6))\n",
    "\n",
    "\t\tself.classifier = nn.Sequential(\n",
    "\t\t\tnn.Dropout(),\n",
    "\t\t\tnn.Linear(256 * 6 * 6, 4096),\n",
    "\t\t\tnn.ReLU(inplace=True),\n",
    "\t\t\tnn.Dropout(),\n",
    "\t\t\tnn.Linear(4096, 4096),\n",
    "\t\t\tnn.ReLU(inplace=True), # take fc8 (without activation)\n",
    "\t\t\t# nn.Linear(4096, num_classes),\n",
    "\t\t\t)\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# define forward pass of network\n",
    "\t\tx = self.features(x)\n",
    "\t\tx = self.avgpool(x)\n",
    "\t\tx = torch.flatten(x, 1) # flatten to input into classifier\n",
    "\t\t# x = x.view(x.size(0), 246 * 6 * 6)\n",
    "\t\tx = self.classifier(x)\n",
    "\t\treturn x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "# from torch.utils import model_zoo\n",
    "import numpy as np\n",
    "try: # import pytorch data getters\n",
    "\tfrom torch.hub import load_state_dict_from_url\n",
    "except ImportError:\n",
    "\tfrom torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Created on Saturday Feb 22 2020\n",
    "\n",
    "@authors: Alan Preciado, Santosh Muthireddy\n",
    "\"\"\"\n",
    "def load_pretrained_AlexNet(model, progress=True):\n",
    "# def alexnet(pretrained=False, progress=True, **kwargs):\n",
    "\t\"\"\"\n",
    "\tAlexNet model architecture from the paper\n",
    "\tpretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "\tprogress (bool): If True, displays a progress bar of the download to stderr\n",
    "\t\"\"\"\n",
    "\n",
    "\t__all_ = [\"AlexNet\", \"alexnet\", \"Alexnet\"]\n",
    "\n",
    "\tmodel_url = {\n",
    "\t    'alexnet':'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
    "\t}\n",
    "\n",
    "\tstate_dict = load_state_dict_from_url(model_url['alexnet'], progress=progress)\n",
    "\tmodel_dict = model.state_dict() # check this one\n",
    "\n",
    "\t# filter out unmatching dictionary\n",
    "\t# reference: https://github.com/SSARCandy/DeepCORAL/blob/master/main.py\n",
    "\tstate_dict = {k: v for k, v in state_dict.items() if k in model_dict}\n",
    "\n",
    "\tmodel_dict.update(state_dict)\n",
    "\tmodel.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "def show_image(dataset, domain, image_class, image_name):\n",
    "\t\"\"\"\n",
    "\tPlot images from given domain, class\n",
    "\t\"\"\"\n",
    "\timage_file = io.imread(os.path.join(\"data\", dataset, domain, \"images\", image_class, image_name))\n",
    "\tplt.imshow(image_file)\n",
    "\tplt.pause(0.001)\n",
    "\tplt.figure()\n",
    "\n",
    "\n",
    "def accuracy(prediction, target):\n",
    "\tpass\n",
    "\n",
    "\n",
    "def save_model(model, path):\n",
    "\ttorch.save(model.state_dict(), path)\n",
    "\tprint(\"checkpoint saved in {}\".format(path))\n",
    "\n",
    "\n",
    "def load_model(model, path):\n",
    "\tmodel.load_state_dict(torch.load(path))\n",
    "\tprint(\"checkpoint loaded from {}\".format(path))\n",
    "\n",
    "\n",
    "def get_mean_std_dataset(root_dir):\n",
    "\t\"\"\"\n",
    "\tFunction to compute mean and std of image dataset.\n",
    "\tMove batch_size param according to memory resources.\n",
    "\tretrieved from: https://forums.fast.ai/t/image-normalization-in-pytorch/7534/7\n",
    "\t\"\"\"\n",
    "\n",
    "\t# data_domain = \"amazon\"\n",
    "\t# path_dataset = \"datasets/office/%s/images\" % data_domain\n",
    "    \n",
    "\ttransform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), # original image size 300x300 pixels\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "\tdataset = datasets.ImageFolder(root=root_dir,\n",
    "\t                               transform=transform)\n",
    "\n",
    "\t# set large batch size to get good approximate of mean, std of full dataset\n",
    "\t# batch_size: 4096, 2048\n",
    "\tdata_loader = DataLoader(dataset, batch_size=2048,\n",
    "\t                        shuffle=False, num_workers=0)\n",
    "\n",
    "\tmean = []\n",
    "\tstd = []\n",
    "\n",
    "\tfor i, data in enumerate(data_loader, 0):\n",
    "\t\t# shape is (batch_size, channels, height, width)\n",
    "\t\tnpy_image = data[0].numpy()\n",
    "\n",
    "\t\t# compute mean, std per batch shape (3,) three channels\n",
    "\t\tbatch_mean = np.mean(npy_image, axis=(0,2,3))\n",
    "\t\tbatch_std = np.std(npy_image, axis=(0,2,3))\n",
    "\n",
    "\t\tmean.append(batch_mean)\n",
    "\t\tstd.append(batch_std)\n",
    "\n",
    "\t# shape (num_iterations, 3) -> (mean across 0th axis) -> shape (3,)\n",
    "\tmean = np.array(mean).mean(axis=0) # average over batch averages\n",
    "\tstd = np.arry(std).mean(axis=0) # average over batch stds\n",
    "\n",
    "\tvalues = {\n",
    "\t\t\"mean\": mean,\n",
    "\t\t\"std\": std\n",
    "\t}\n",
    "\n",
    "\treturn values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from PIL import Image\n",
    "from utils import get_mean_std_dataset\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Created on Saturday Feb 22 2020\n",
    "\n",
    "@authors: Alan Preciado, Santosh Muthireddy\n",
    "\"\"\"\n",
    "class OfficeAmazonDataset(Dataset):\n",
    "    \"\"\"Class to create an iterable dataset\n",
    "    of images and corresponding labels \"\"\"\n",
    "\n",
    "    def __init__(self, image_folder_dataset, transform=None):\n",
    "        super(OfficeAmazonDataset, self).__init__()\n",
    "        self.image_folder_dataset = image_folder_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_folder_dataset.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # read image, class from folder_dataset given index\n",
    "        img, img_label = image_folder_dataset[idx][0], image_folder_dataset[idx][1]\n",
    "\n",
    "        # apply transformations (it already returns them as torch tensors)\n",
    "        if self.transform is not None:\n",
    "            self.transform(img)\n",
    "\n",
    "        img_label_pair = {\"image\": img,\n",
    "                         \"class\": img_label}\n",
    "\n",
    "        return img_label_pair\n",
    "\n",
    "\n",
    "def get_dataloader(dataset, batch_size, train_ratio=0.7):\n",
    "    \"\"\"\n",
    "    Splits a dataset into train and test.\n",
    "    Returns train_loader and test_loader.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_subset(indices, start, end):\n",
    "        return indices[start:start+end]\n",
    "\n",
    "    # Split train/val data ratios\n",
    "    TRAIN_RATIO, VALIDATION_RATIO = train_ratio, 1-train_ratio\n",
    "    train_set_size = int(len(dataset) * TRAIN_RATIO)\n",
    "    validation_set_size = int(len(dataset) * VALIDATION_RATIO)\n",
    "\n",
    "    # Generate random indices for train and val sets\n",
    "    indices = torch.randperm(len(dataset))\n",
    "    train_indices = get_subset(indices, 0, train_set_size)\n",
    "    validation_indices = get_subset(indices, train_set_size, validation_set_size)\n",
    "    # test_indices = get_subset(indices,train_count+validation_count,len(dataset))\n",
    "\n",
    "    # Create sampler objects\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(validation_indices)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "                              sampler=train_sampler, num_workers=4)\n",
    "\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "                            sampler=val_sampler, num_workers=4)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def get_office_dataloader(name_dataset, batch_size, train=True):\n",
    "    \"\"\"\n",
    "    Creates dataloader for the datasets in office datasetself.\n",
    "    Makes use of get_mean_std_dataset to compute mean and std along the\n",
    "    color channels for each dataset in office.\n",
    "    \"\"\"\n",
    "    # Ideally compute mean and std with get_mean_std_dataset.py\n",
    "    # Values retrieved from:\n",
    "    # https://github.com/DenisDsh/PyTorch-Deep-CORAL/blob/master/data_loader.py\n",
    "\n",
    "    root_dir = \"datasets/office/%s/images\" % name_dataset\n",
    "\n",
    "    __datasets__ = [\"amazon\", \"dslr\", \"webcam\"]\n",
    "\n",
    "    if name_dataset not in __datasets__:\n",
    "        raise ValueError(\"must introduce one of the three datasets in office\")\n",
    "\n",
    "    mean_std = {\n",
    "        \"amazon\":{\n",
    "            \"mean\":[0.7923, 0.7862, 0.7841],\n",
    "            \"std\":[0.3149, 0.3174, 0.3193]\n",
    "        },\n",
    "        \"dslr\":{\n",
    "            \"mean\":[0.4708, 0.4486, 0.4063],\n",
    "            \"std\":[0.2039, 0.1920, 0.1996]\n",
    "        },\n",
    "        \"webcam\":{\n",
    "            \"mean\":[0.6119, 0.6187, 0.6173],\n",
    "            \"std\":[0.2506, 0.2555, 0.2577]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    data_transforms = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            # transforms.RandomSizedCrop(224),\n",
    "            # transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean_std[name_dataset][\"mean\"],\n",
    "                                 std=mean_std[name_dataset][\"std\"])\n",
    "        ])\n",
    "\n",
    "    dataset = datasets.ImageFolder(root=root_dir,\n",
    "                                   transform=data_transforms)\n",
    "\n",
    "    # note on shuffling in data loader:\n",
    "    # https://stackoverflow.com/questions/54354465/impact-of-using-data-shuffling-in-pytorch-dataloader\n",
    "    dataset_loader = DataLoader(dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=train,\n",
    "                                num_workers=4)\n",
    "\n",
    "    return dataset_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Created on Saturday Feb 25 2020\n",
    "\n",
    "@authors: Alan Preciado, Santosh Muthireddy\n",
    "\"\"\"\n",
    "def CORAL_loss(source, target):\n",
    "\t\"\"\"\n",
    "\tFrom the paper, the vectors that compose Ds and Dt are D-dimensional vectors.\n",
    "\t:param source: torch tensor: source data (Ds) with dimensions DxNs\n",
    "\t:param target: torch tensor: target data (Dt) with dimensons DxNt\n",
    "\t\"\"\"\n",
    "\n",
    "\td = source.size(1) # d-dimensional vectors (same for source, target)\n",
    "\n",
    "\tsource_covariance = compute_covariance(source)\n",
    "\ttarget_covariance = compute_covariance(target)\n",
    "\n",
    "\t# take Frobenius norm (https://pytorch.org/docs/stable/torch.html)\n",
    "\tloss = torch.norm(torch.mul((source_covariance-target_covariance),(source_covariance-target_covariance)), p=\"fro\")\n",
    "\t# loss = torch.norm(torch.mm((source_covariance-target_covariance),(source_covariance-target_covariance)), p=\"fro\")\n",
    "\n",
    "\tloss = loss / (4*d*d)\n",
    "\n",
    "\treturn loss\n",
    "\n",
    "\n",
    "def compute_covariance(data):\n",
    "\t\"\"\"\n",
    "\tCompute covariance matrix for given dataset as shown in paper.\n",
    "\tEquations 2 and 3.\n",
    "\t:param data: torch tensor: input source/target data\n",
    "\t\"\"\"\n",
    "\n",
    "\t# data dimensions: nxd (this for Ns or Nt)\n",
    "\tn = data.size(0)\n",
    "\n",
    "\t# proper matrix multiplication for right side of equation (2)\n",
    "\tones_vector = torch.ones(n).resize(1, n) \t# 1xN dimensional vector (transposed)\n",
    "\tone_onto_D = torch.mm(ones_vector, data)\n",
    "\tmult_right_terms = torch.mm(one_onto_D.t(), one_onto_D)\n",
    "\tmult_right_terms = torch.div(mult_right_terms, n) # element-wise divison\n",
    "\n",
    "\t# matrix multiplication for left side of equation (2)\n",
    "\tmult_left_terms = torch.mm(data.t(), data)\n",
    "\n",
    "\tcovariance_matrix = 1/(n-1) * torch.add(mult_left_terms, -1*(mult_right_terms))\n",
    "\n",
    "\treturn covariance_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py\n",
    "def train(model, optimizer, epoch, _lambda):\n",
    "    \"\"\"\n",
    "    This method fits the network params one epoch at a time.\n",
    "    Implementation based on: https://github.com/SSARCandy/DeepCORAL/blob/master/main.py\n",
    "    \"\"\"\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    results = [] # list to append loss values at each epoch\n",
    "    \n",
    "    # first cast into an iterable list the data loaders\n",
    "    # shapes: data_source -> (batch_size, channels, height, width), data_target -> (batch_size)\n",
    "    # source[0][1][0].size() --> torch.Size([128, 3, 224, 224])\n",
    "\n",
    "    source, target = list(enumerate(source_loader)), list(enumerate(target_loader))\n",
    "    train_steps = min(len(source), len(target))\n",
    "    \n",
    "    # start batch training\n",
    "    for batch_idx in tnrange(train_steps):\n",
    "    # for batch_idx in range(train_steps):\n",
    "        # second fetch data in batches\n",
    "        # _, source_data -> torch.Size([128, 3, 224, 224]), labels -> torch.Size([128])\n",
    "        _, (source_data, source_label) = source[batch_idx]\n",
    "        _, (target_data, _) = target[batch_idx] # unsupervised learning\n",
    "        \n",
    "        if CUDA:\n",
    "            # move to device\n",
    "            source_data = source_data.cuda()\n",
    "            source_label = source_label.cuda()\n",
    "            target_data = target_data.cuda()\n",
    "        \n",
    "        # create pytorch variables, the variables and functions build a dynamic graph of computation\n",
    "        source_data, source_label = Variable(source_data), Variable(source_label)\n",
    "        target_data = Variable(target_data)\n",
    "        \n",
    "        # reset to zero optimizer gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # do a forward pass through network (recall DeepCORAL outputs source, target activation maps)\n",
    "        output1, output2 = model(source_data, target_data)\n",
    "        \n",
    "        # compute losses (classification and coral loss)\n",
    "        classification_loss = torch.nn.functional.cross_entropy(out1, source_label) # only for source data\n",
    "        coral_loss = CORAL_loss(output1, output2)\n",
    "        \n",
    "        # compute total loss (equation 6 paper)\n",
    "        total_loss = classification_loss + _lambda*coral_loss\n",
    "        \n",
    "        # compute gradients of network (backprop in pytorch)\n",
    "        total_loss.backwards()\n",
    "        \n",
    "        # update weights of network\n",
    "        optimizer.step()\n",
    "        \n",
    "        # append results for each batch iteration as dictionaries\n",
    "        results.append({\n",
    "            'epoch': epoch,\n",
    "            'step': batch_idx + 1,\n",
    "            'total_steps': train_steps,\n",
    "            'lambda': _lambda,\n",
    "            'coral_loss': coral_loss.data[0],\n",
    "            'classification_loss': classification_loss.data[0],\n",
    "            'total_loss': total_loss.data[0]\n",
    "        })\n",
    "        \n",
    "        # print training info\n",
    "        print('Train Epoch: {:2d} [{:2d}/{:2d}]\\t'\n",
    "              'Lambda value: {:.4f}, Classification loss: {:.6f}, CORAL loss: {:.6f}, Total_Loss: {:.6f}'.format(\n",
    "                  epoch,\n",
    "                  batch_idx + 1,\n",
    "                  train_steps,\n",
    "                  _lambda,\n",
    "                  classification_loss.data[0],\n",
    "                  coral_loss.data[0],\n",
    "                  total_loss.data[0]\n",
    "              ))\n",
    "\n",
    "    return results\n",
    "\n",
    "# test.py\n",
    "def test(model, data_loader, epoch):\n",
    "    \"\"\"\n",
    "    Computes classification accuracy of (labeled) data using cross-entropy.\n",
    "    Retreived from: https://github.com/SSARCandy/DeepCORAL/blob/master/main.py\n",
    "    \"\"\"\n",
    "    # eval() it indicates the model that nothing new is \n",
    "    # to be learnt and the model is used for testing\n",
    "    model.eval()\n",
    "    \n",
    "    test_loss = 0\n",
    "    correct_class = 0\n",
    "    \n",
    "    # go over dataloader batches, labels\n",
    "    for data, label in data_loader:\n",
    "        if CUDA:\n",
    "            data, label = data.cuda(), label.cuda()\n",
    "        \n",
    "        # note on volatile: https://stackoverflow.com/questions/49837638/what-is-volatile-variable-in-pytorch\n",
    "        data, label = Variable(data, volatile=True), Variable(label)\n",
    "        output, _ = model(data, data) # just use one ouput of DeepCORAL\n",
    "        \n",
    "        # sum batch loss when computing classification\n",
    "        test_loss += torch.nn.functional.cross_entropy(output, label, size_average=False).data[0]\n",
    "        \n",
    "        # get the index of the max log-probability\n",
    "        pred = out.data.max(1, keepdim=True)[1]\n",
    "        correct_class += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    \n",
    "    # compute test loss as correclty classified labels divided by total data size\n",
    "    test_loss = test_loss/len(data_loader.dataset)\n",
    "    \n",
    "    # return dictionary containing info of each epoch\n",
    "    return {\n",
    "        \"epoch\": epoch,\n",
    "        \"average_loss\": test_loss,\n",
    "        \"correct_class\": correct_class,\n",
    "        \"total elems\": len(data_loader.dataset),\n",
    "        \"accuracy %\": 100.*correct_class/len(data_loader.dataset)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main.py\n",
    "from __future__ import division\n",
    "import argparse\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from loss import CORAL_loss\n",
    "import tqdm\n",
    "from tqdm import tnrange\n",
    "from utils import load_pretrained_AlexNet, save_model, load_model\n",
    "from dataloader import get_office_dataloader\n",
    "from model import DeepCORAL, AlexNet\n",
    "\n",
    "# define train parameters as in the paper (page 5)\n",
    "CUDA = True if torch.cuda.is_available() else False\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 5e-4\n",
    "MOMENTUM = 0.9\n",
    "BATCH_SIZE = [32, 32] # batch_s, batch_t [128, 56]\n",
    "EPOCHS = 1\n",
    "\n",
    "# create dataloaders (Amazon as source and Webcam as target)\n",
    "# TODO: try different combinations between 3 datasets to test adaptation\n",
    "source_loader = get_office_dataloader(name_dataset=\"amazon\", batch_size=BATCH_SIZE[0])\n",
    "target_loader = get_office_dataloader(name_dataset=\"webcam\", batch_size=BATCH_SIZE[1])\n",
    "\n",
    "# argparse ...\n",
    "model = DeepCORAL(num_classes=31) # input no. of classes in custom dataset\n",
    "\n",
    "# define optimizer pytorch: https://pytorch.org/docs/stable/optim.html\n",
    "# specify per-layer learning rates: 10*learning_rate for last two fc layers according to paper\n",
    "optimizer = torch.optim.SGD([\n",
    "    {\"params\": model.sharedNetwork.parameters()},\n",
    "    {\"params\": model.fc8.parameters(), \"lr\":10*LEARNING_RATE},\n",
    "], lr=LEARNING_RATE, momentum=MOMENTUM)\n",
    "\n",
    "if CUDA:\n",
    "    model = model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pre-trained model...\n",
      "loaded model correctly...\n"
     ]
    }
   ],
   "source": [
    "# load pre-trained model --> TODO: check it is loading properly\n",
    "# if args.load is not NONE:\n",
    "    # load_model(model, args.load)\n",
    "# else:\n",
    "    # load_pretrained_AlexNet(model.sharedNetwork, progress=True)\n",
    "\n",
    "load_pretrained_AlexNet(model.sharedNetwork, progress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e367f60e33de40c8bb78931b77c69f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# store statistics of train/test\n",
    "training_s_statistic = []\n",
    "testing_s_statistic = []\n",
    "testing_t_statistic = []\n",
    "\n",
    "# iterate over epochs\n",
    "for epoch in tnrange(EPOCHS):\n",
    "    # compute lambda value\n",
    "    _lambda = (epoch+1)/EPOCHS\n",
    "    \n",
    "    result_train = train(model, optimizer, epoch+1, _lambda)\n",
    "    \n",
    "    print('###EPOCH {}: Classification: {:.6f}, CORAL loss: {:.6f}, Total_Loss: {:.6f}'.format(\n",
    "            epoch+1,\n",
    "            sum(row['classification_loss'] / row['total_steps'] for row in result_train),\n",
    "            sum(row['coral_loss'] / row['total_steps'] for row in result_train),\n",
    "            sum(row['total_loss'] / row['total_steps'] for row in result_train),\n",
    "        ))\n",
    "    \n",
    "    training_s_statistic.append(result_train)\n",
    "    \n",
    "    # check these ones\n",
    "    test_source = test(model, source_loader, epoch)\n",
    "    test_target = test(model, target_loader, epoch)\n",
    "    testing_s_statistic.append(test_source)\n",
    "    testing_t_statistic.append(test_target)\n",
    "    \n",
    "    print('###Test Source: Epoch: {}, avg_loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "            epoch+1,\n",
    "            test_source['average_loss'],\n",
    "            test_source['correct'],\n",
    "            test_source['total'],\n",
    "            test_source['accuracy'],\n",
    "        ))\n",
    "    \n",
    "    print('###Test Target: Epoch: {}, avg_loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)'.format(\n",
    "        epoch+1,\n",
    "        test_target['average_loss'],\n",
    "        test_target['correct'],\n",
    "        test_target['total'],\n",
    "        test_target['accuracy'],\n",
    "    ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_covariance(data):\n",
    "\t\"\"\"\n",
    "\tCompute covariance matrix for given dataset as shown in paper (eqs 2 and 3).\n",
    "\t:param data: torch tensor: input source/target data\n",
    "\t\"\"\"\n",
    "\n",
    "\t# data dimensions: nxd (this for Ns or Nt)\n",
    "\tn = data.size(0) # get batch size\n",
    "\n",
    "  # check gpu or cpu \n",
    "\tif data.is_cuda:\n",
    "\t\tdevice = torch.device(\"gpu\")\n",
    "\telse:\n",
    "\t\tdevice = torch.device(\"cpu\")\n",
    "\n",
    "\t# proper matrix multiplication for right side of equation (2)\n",
    "\tones_vector = torch.ones(n).resize(1, n).to(device=device) \t# 1xN dimensional vector (transposed)\n",
    "\tone_onto_D = torch.mm(ones_vector, data)\n",
    "\tmult_right_terms = torch.mm(one_onto_D.t(), one_onto_D)\n",
    "\tmult_right_terms = torch.div(mult_right_terms, n) # element-wise divison\n",
    "\n",
    "\t# matrix multiplication for left side of equation (2)\n",
    "\tmult_left_terms = torch.mm(data.t(), data)\n",
    "\n",
    "\tcovariance_matrix= 1/(n-1) * torch.add(mult_left_terms,-1*(mult_right_terms))\n",
    "\n",
    "\treturn covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python_3_6] *",
   "language": "python",
   "name": "conda-env-Python_3_6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
