{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **TODO:** train, test, main\n",
    "- **TODO:** plot_accuracies_losses.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total no. of images in amazon dataset: 2817\n"
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "\n",
    "# root_dir = \"datasets/office/amazon/images\"\n",
    "# path = \"datasets/office/amazon\"\n",
    "# name_dataset = \"office\"\n",
    "\n",
    "data_domain = \"amazon\"\n",
    "img_size = 224\n",
    "#\n",
    "# Pytorch ImageFolder fits our dataset structure\n",
    "# dataset = datasets.ImageFolder(root=root_dir, transform=data_transform)\n",
    "image_data_folder = datasets.ImageFolder(root= \"datasets/office/%s/images\" % data_domain)\n",
    "print(\"total no. of images in amazon dataset:\",len(image_data_folder))\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.RandomSizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader.py\n",
    "class OfficeAmazonDataset(Dataset):\n",
    "    \"\"\"Class to create an iterable dataset \n",
    "    of images and corresponding labels \"\"\"\n",
    "        \n",
    "    def __init__(self, image_folder_dataset, transform=None):\n",
    "        super(OfficeAmazonDataset, self).__init__()\n",
    "        self.image_folder_dataset = image_folder_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_folder_dataset.imgs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # read image, class from folder_dataset given index\n",
    "        img, img_label = image_folder_dataset[idx][0], image_folder_dataset[idx][1]\n",
    "        \n",
    "        # apply transformations (it already returns them as torch tensors)\n",
    "        if self.transform is not None:\n",
    "            self.transform(img)\n",
    "        \n",
    "        img_label_pair = {\"image\": img,\n",
    "                         \"class\": img_label}\n",
    "        \n",
    "        return img_label_pair\n",
    "\n",
    "def get_dataloader(dataset, batch_size):\n",
    "        \n",
    "    def get_subset(indices, start, end):\n",
    "        return indices[start:start + end]\n",
    "    \n",
    "    # Split train/val data ratios\n",
    "    TRAIN_RATIO, VALIDATION_RATIO = 0.7, 0.3\n",
    "    train_set_size = int(len(dataset) * TRAIN_RATIO)\n",
    "    validation_set_size = int(len(dataset) * VALIDATION_RATIO)\n",
    "\n",
    "    # Generate random indices for train and val sets\n",
    "    indices = torch.randperm(len(dataset))\n",
    "    train_indices = get_subset(indices, 0, train_set_size)\n",
    "    validation_indices = get_subset(indices, train_set_size, validation_set_size)\n",
    "    # test_indices = get_subset(indices, train_count + validation_count, len(dataset))\n",
    "\n",
    "    # Create sampler objects \n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(validation_indices)\n",
    "\n",
    "    # Create data loaders for data\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, \n",
    "                              sampler=train_sampler, num_workers=4)\n",
    "\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_size, \n",
    "                            sampler=val_sampler, num_workers=4)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_dataset = OfficeAmazonDataset(image_folder_dataset=image_data_folder, transform=data_transforms)\n",
    "train_loader, val_loader = get_dataloader(amazon_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean and std of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_mean_std(path_dataset):\n",
    "    \"\"\"\n",
    "    Compute mean and standard deviation of an image dataset.\n",
    "    Acknowledgment : http://forums.fast.ai/t/image-normalization-in-pytorch/7534\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.ImageFolder(root=path_dataset,\n",
    "                                   transform=transform)\n",
    "    # Choose a large batch size to better approximate. Optimally load the dataset entirely on memory.\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=4096, shuffle=False, num_workers=4)\n",
    "\n",
    "    pop_mean = []\n",
    "    pop_std = []\n",
    "\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        # shape (batch_size, 3, height, width)\n",
    "        numpy_image = data[0].numpy()\n",
    "\n",
    "        # shape (3,) -> 3 channels\n",
    "        batch_mean = np.mean(numpy_image, axis=(0, 2, 3))\n",
    "        batch_std = np.std(numpy_image, axis=(0, 2, 3))\n",
    "\n",
    "        pop_mean.append(batch_mean)\n",
    "        pop_std.append(batch_std)\n",
    "\n",
    "    # shape (num_iterations, 3) -> (mean across 0th axis) -> shape (3,)\n",
    "    pop_mean = np.array(pop_mean).mean(axis=0)\n",
    "    pop_std = np.array(pop_std).mean(axis=0)\n",
    "\n",
    "    values = {\n",
    "        'mean': pop_mean,\n",
    "        'std': pop_std\n",
    "    }\n",
    "\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieved from: https://forums.fast.ai/t/image-normalization-in-pytorch/7534/7\n",
    "# this cell takes too much memory and time to compute\n",
    "data_domain = \"amazon\"\n",
    "path_dataset = \"datasets/office/%s/images\" % data_domain\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), # original image size 300x300 pixels\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=path_dataset,\n",
    "                               transform=transform)\n",
    "\n",
    "# set large batch size to get good approximate of mean, std of full dataset\n",
    "data_loader = DataLoader(dataset, batch_size=2048, shuffle=False, num_workers=0) # 4096\n",
    "\n",
    "mean = []\n",
    "std = []\n",
    "\n",
    "# for i, data in enumerate(data_loader, 0):\n",
    "    # shape is (batch_size, channels, height, width)\n",
    "    npy_image = data[0].numpy()\n",
    "    \n",
    "    # compute mean, std per batch shape (3,) three channels\n",
    "    batch_mean = np.mean(npy_image, axis=(0,2,3))\n",
    "    batch_std = np.std(npy_image, axis=(0,2,3))\n",
    "    \n",
    "    mean.append(batch_mean)\n",
    "    std.append(batch_std)\n",
    "    \n",
    "# shape (num_iterations, 3) -> (mean across 0th axis) -> shape (3,)\n",
    "mean = np.array(mean).mean(axis=0) # average over batch averages\n",
    "std = np.arry(std).mean(axis=0) # average over batch stds\n",
    "\n",
    "values = {\n",
    "    \"mean\": mean,\n",
    "    \"std\": std\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### testing dataloader for office dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dataloader import get_office_dataloader\n",
    "amazon_dataloader = get_office_dataloader(\"amazon\", 2048)\n",
    "amazon_dataloader.batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "import os\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from PIL import Image\n",
    "from utils import get_mean_std_dataset\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Created on Saturday Feb 22 2020\n",
    "\n",
    "@authors: Alan Preciado, Santosh Muthireddy\n",
    "\"\"\"\n",
    "class OfficeAmazonDataset(Dataset):\n",
    "    \"\"\"Class to create an iterable dataset\n",
    "    of images and corresponding labels \"\"\"\n",
    "\n",
    "    def __init__(self, image_folder_dataset, transform=None):\n",
    "        super(OfficeAmazonDataset, self).__init__()\n",
    "        self.image_folder_dataset = image_folder_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_folder_dataset.imgs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # read image, class from folder_dataset given index\n",
    "        img, img_label = image_folder_dataset[idx][0], image_folder_dataset[idx][1]\n",
    "\n",
    "        # apply transformations (it already returns them as torch tensors)\n",
    "        if self.transform is not None:\n",
    "            self.transform(img)\n",
    "\n",
    "        img_label_pair = {\"image\": img,\n",
    "                         \"class\": img_label}\n",
    "\n",
    "        return img_label_pair\n",
    "\n",
    "\n",
    "def get_dataloader(dataset, batch_size, train_ratio=0.7):\n",
    "    \"\"\"\n",
    "    Splits a dataset into train and test.\n",
    "    Returns train_loader and test_loader.\n",
    "    \"\"\"\n",
    "\n",
    "    def get_subset(indices, start, end):\n",
    "        return indices[start:start+end]\n",
    "\n",
    "    # Split train/val data ratios\n",
    "    TRAIN_RATIO, VALIDATION_RATIO = train_ratio, 1-train_ratio\n",
    "    train_set_size = int(len(dataset) * TRAIN_RATIO)\n",
    "    validation_set_size = int(len(dataset) * VALIDATION_RATIO)\n",
    "\n",
    "    # Generate random indices for train and val sets\n",
    "    indices = torch.randperm(len(dataset))\n",
    "    train_indices = get_subset(indices, 0, train_set_size)\n",
    "    validation_indices = get_subset(indices, train_set_size, validation_set_size)\n",
    "    # test_indices = get_subset(indices,train_count+validation_count,len(dataset))\n",
    "\n",
    "    # Create sampler objects\n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(validation_indices)\n",
    "\n",
    "    # Create data loaders\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "                              sampler=train_sampler, num_workers=4)\n",
    "\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_size,\n",
    "                            sampler=val_sampler, num_workers=4)\n",
    "\n",
    "    return train_loader, val_loader\n",
    "\n",
    "\n",
    "def get_office_dataloader(name_dataset, batch_size, train=True):\n",
    "    \"\"\"\n",
    "    Creates dataloader for the datasets in office datasetself.\n",
    "    Makes use of get_mean_std_dataset to compute mean and std along the\n",
    "    color channels for each dataset in office.\n",
    "    \"\"\"\n",
    "    # Ideally compute mean and std with get_mean_std_dataset.py\n",
    "    # Values retrieved from:\n",
    "    # https://github.com/DenisDsh/PyTorch-Deep-CORAL/blob/master/data_loader.py\n",
    "\n",
    "    root_dir = \"datasets/office/%s/images\" % name_dataset\n",
    "\n",
    "    __datasets__ = [\"amazon\", \"dslr\", \"webcam\"]\n",
    "\n",
    "    if name_dataset not in __datasets__:\n",
    "        raise ValueError(\"must introduce one of the three datasets in office\")\n",
    "\n",
    "    mean_std = {\n",
    "        \"amazon\":{\n",
    "            \"mean\":[0.7923, 0.7862, 0.7841],\n",
    "            \"std\":[0.3149, 0.3174, 0.3193]\n",
    "        },\n",
    "        \"dslr\":{\n",
    "            \"mean\":[0.4708, 0.4486, 0.4063],\n",
    "            \"std\":[0.2039, 0.1920, 0.1996]\n",
    "        },\n",
    "        \"webcam\":{\n",
    "            \"mean\":[0.6119, 0.6187, 0.6173],\n",
    "            \"std\":[0.2506, 0.2555, 0.2577]\n",
    "        }\n",
    "    }\n",
    "\n",
    "    data_transforms = transforms.Compose([\n",
    "            transforms.Resize((224, 224)),\n",
    "            # transforms.RandomSizedCrop(224),\n",
    "            # transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=mean_std[name_dataset][\"mean\"],\n",
    "                                 std=mean_std[name_dataset][\"std\"])\n",
    "        ])\n",
    "\n",
    "    dataset = datasets.ImageFolder(root=root_dir,\n",
    "                                   transform=data_transforms)\n",
    "\n",
    "    # note on shuffling in data loader:\n",
    "    # https://stackoverflow.com/questions/54354465/impact-of-using-data-shuffling-in-pytorch-dataloader\n",
    "    dataset_loader = DataLoader(dataset,\n",
    "                                batch_size=batch_size,\n",
    "                                shuffle=train,\n",
    "                                num_workers=4)\n",
    "\n",
    "    return dataset_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Created on Saturday Feb 25 2020\n",
    "\n",
    "@authors: Alan Preciado, Santosh Muthireddy\n",
    "\"\"\"\n",
    "def CORAL_loss(source, target):\n",
    "    \"\"\"\n",
    "    From the paper, the vectors that compose Ds and Dt are D-dimensional vectors.\n",
    "    :param source: torch tensor: source data (Ds) with dimensions DxNs\n",
    "    :param target: torch tensor: target data (Dt) with dimensons DxNt\n",
    "    \"\"\"\n",
    "\n",
    "    d = source.size(1) # d-dimensional vectors (same for source, target)\n",
    "\n",
    "    source_covariance = compute_covariance(source)\n",
    "    target_covariance = compute_covariance(target)\n",
    "\n",
    "    # take Frobenius norm (https://pytorch.org/docs/stable/torch.html)\n",
    "    loss = torch.norm(torch.mul((source_covariance-target_covariance),(source_covariance-target_covariance)), p=\"fro\")\n",
    "    # loss = torch.norm(torch.mm((source_covariance-target_covariance),(source_covariance-target_covariance)), p=\"fro\")\n",
    "\n",
    "    loss = loss / (4*d*d)\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def compute_covariance(data):\n",
    "    \"\"\"\n",
    "    Compute covariance matrix for given dataset as shown in paper.\n",
    "    Equations 2 and 3.\n",
    "    :param data: torch tensor: input source/target data\n",
    "    \"\"\"\n",
    "\n",
    "    # data dimensions: nxd (this for Ns or Nt)\n",
    "    n = data.size(0)\n",
    "\n",
    "    # proper matrix multiplication for right side of equation (2)\n",
    "    ones_vector = torch.ones(n).resize(1, n) \t# 1xN dimensional vector (transposed)\n",
    "    one_onto_D = torch.mm(ones_vector, data)\n",
    "    mult_right_terms = torch.mm(one_onto_D.t(), one_onto_D)\n",
    "    mult_right_terms = torch.div(mult_right_terms, n) # element-wise divison\n",
    "\n",
    "    # matrix multiplication for left side of equation (2)\n",
    "    mult_left_terms = torch.mm(data.t(), data)\n",
    "\n",
    "    covariance_matrix = 1/(n-1) * torch.add(mult_left_terms, -1*(mult_right_terms))\n",
    "\n",
    "    return covariance_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "# from torch.utils import model_zoo\n",
    "import numpy as np\n",
    "try: # import pytorch data getters\n",
    "    from torch.hub import load_state_dict_from_url\n",
    "except ImportError:\n",
    "    from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Created on Saturday Feb 22 2020\n",
    "\n",
    "@authors: Alan Preciado, Santosh Muthireddy\n",
    "\"\"\"\n",
    "def load_pretrained_AlexNet(model, progress=True):\n",
    "# def alexnet(pretrained=False, progress=True, **kwargs):\n",
    "    \"\"\"\n",
    "    AlexNet model architecture from the paper\n",
    "    pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "    progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "\n",
    "    __all_ = [\"AlexNet\", \"alexnet\", \"Alexnet\"]\n",
    "\n",
    "    model_url = {\n",
    "        'alexnet':'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
    "    }\n",
    "\n",
    "    state_dict = load_state_dict_from_url(model_url['alexnet'], progress=progress)\n",
    "    model_dict = model.state_dict() # check this one\n",
    "\n",
    "    # filter out unmatching dictionary\n",
    "    # reference: https://github.com/SSARCandy/DeepCORAL/blob/master/main.py\n",
    "    state_dict = {k: v for k, v in state_dict.items() if k in model_dict}\n",
    "\n",
    "    model_dict.update(state_dict)\n",
    "    model.load_state_dict(state_dict)\n",
    "\n",
    "\n",
    "def show_image(dataset, domain, image_class, image_name):\n",
    "    \"\"\"\n",
    "    Plot images from given domain, class\n",
    "    \"\"\"\n",
    "    image_file = io.imread(os.path.join(\"data\", dataset, domain, \"images\", image_class, image_name))\n",
    "    plt.imshow(image_file)\n",
    "    plt.pause(0.001)\n",
    "    plt.figure()\n",
    "\n",
    "\n",
    "def accuracy(prediction, target):\n",
    "    pass\n",
    "\n",
    "\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(\"checkpoint saved in {}\".format(path))\n",
    "\n",
    "\n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    print(\"checkpoint loaded from {}\".format(path))\n",
    "\n",
    "\n",
    "def get_mean_std_dataset(root_dir):\n",
    "    \"\"\"\n",
    "    Function to compute mean and std of image dataset.\n",
    "    Move batch_size param according to memory resources.\n",
    "    retrieved from: https://forums.fast.ai/t/image-normalization-in-pytorch/7534/7\n",
    "    \"\"\"\n",
    "\n",
    "    # data_domain = \"amazon\"\n",
    "    # path_dataset = \"datasets/office/%s/images\" % data_domain\n",
    "\n",
    "    transform = transforms.Compose([\n",
    "            transforms.Resize((224, 224)), # original image size 300x300 pixels\n",
    "            transforms.ToTensor()])\n",
    "\n",
    "    dataset = datasets.ImageFolder(root=root_dir,\n",
    "                                   transform=transform)\n",
    "\n",
    "    # set large batch size to get good approximate of mean, std of full dataset\n",
    "    # batch_size: 4096, 2048\n",
    "    data_loader = DataLoader(dataset, batch_size=2048,\n",
    "                            shuffle=False, num_workers=0)\n",
    "\n",
    "    mean = []\n",
    "    std = []\n",
    "\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        # shape is (batch_size, channels, height, width)\n",
    "        npy_image = data[0].numpy()\n",
    "\n",
    "        # compute mean, std per batch shape (3,) three channels\n",
    "        batch_mean = np.mean(npy_image, axis=(0,2,3))\n",
    "        batch_std = np.std(npy_image, axis=(0,2,3))\n",
    "\n",
    "        mean.append(batch_mean)\n",
    "        std.append(batch_std)\n",
    "\n",
    "    # shape (num_iterations, 3) -> (mean across 0th axis) -> shape (3,)\n",
    "    mean = np.array(mean).mean(axis=0) # average over batch averages\n",
    "    std = np.arry(std).mean(axis=0) # average over batch stds\n",
    "\n",
    "    values = {\n",
    "        \"mean\": mean,\n",
    "        \"std\": std\n",
    "    }\n",
    "\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# main\n",
    "from __future__ import division\n",
    "import argparse\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# import models --> DeepCoral, AlexNet\n",
    "# import utils --> load_alex_net, save, load\n",
    "# from data_loader import get_office_dataloader\n",
    "\n",
    "CUDA = True if torch.cuda.is_available() else False\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 5e-4\n",
    "MOMENTUM = 0.9\n",
    "BATCH_SIZE = [200, 56] # source, target\n",
    "EPOCHS = 2\n",
    "\n",
    "# create dataloaders (amazon source vs webcam target)\n",
    "source_loader = get_office_dataloader(name_dataset=\"amazon\", batch_size=BATCH_SIZE[0])\n",
    "target_loader = get_office_dataloader(name_dataset=\"webcam\", batch_size=BATCH_SIZE[1])\n",
    "\n",
    "def train(model, optimizer, epoch, _lambda):\n",
    "    \"\"\"\n",
    "    This method fits the network params one epoch at a time.\n",
    "    Implementation based on: https://github.com/SSARCandy/DeepCORAL/blob/master/main.py\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(enumerate(source_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python36] *",
   "language": "python",
   "name": "conda-env-Python36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
