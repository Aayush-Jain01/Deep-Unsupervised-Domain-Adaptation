{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **TODO:** utils.py (mean, std, plot img, covariance), train.py, main.py (call everything), loss.py (accuracy, coral) , plot_loss_accuracy.py\n",
    "- **TODO:** get mean, standard deviation of dataset (each domain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total no. of images in amazon dataset: 2817\n"
     ]
    }
   ],
   "source": [
    "# main.py\n",
    "\n",
    "# root_dir = \"datasets/office/amazon/images\"\n",
    "# path = \"datasets/office/amazon\"\n",
    "# name_dataset = \"office\"\n",
    "\n",
    "data_domain = \"amazon\"\n",
    "img_size = 224\n",
    "#\n",
    "# Pytorch ImageFolder fits our dataset structure\n",
    "# dataset = datasets.ImageFolder(root=root_dir, transform=data_transform)\n",
    "image_data_folder = datasets.ImageFolder(root= \"datasets/office/%s/images\" % data_domain)\n",
    "print(\"total no. of images in amazon dataset:\",len(image_data_folder))\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.RandomSizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataloader.py\n",
    "class OfficeAmazonDataset(Dataset):\n",
    "    \"\"\"Class to create an iterable dataset \n",
    "    of images and corresponding labels \"\"\"\n",
    "        \n",
    "    def __init__(self, image_folder_dataset, transform=None):\n",
    "        super(OfficeAmazonDataset, self).__init__()\n",
    "        self.image_folder_dataset = image_folder_dataset\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_folder_dataset.imgs)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # read image, class from folder_dataset given index\n",
    "        img, img_label = image_folder_dataset[idx][0], image_folder_dataset[idx][1]\n",
    "        \n",
    "        # apply transformations (it already returns them as torch tensors)\n",
    "        if self.transform is not None:\n",
    "            self.transform(img)\n",
    "        \n",
    "        img_label_pair = {\"image\": img,\n",
    "                         \"class\": img_label}\n",
    "        \n",
    "        return img_label_pair\n",
    "\n",
    "def get_dataloader(dataset, batch_size):\n",
    "        \n",
    "    def get_subset(indices, start, end):\n",
    "        return indices[start:start + end]\n",
    "    \n",
    "    # Split train/val data ratios\n",
    "    TRAIN_RATIO, VALIDATION_RATIO = 0.7, 0.3\n",
    "    train_set_size = int(len(dataset) * TRAIN_RATIO)\n",
    "    validation_set_size = int(len(dataset) * VALIDATION_RATIO)\n",
    "\n",
    "    # Generate random indices for train and val sets\n",
    "    indices = torch.randperm(len(dataset))\n",
    "    train_indices = get_subset(indices, 0, train_set_size)\n",
    "    validation_indices = get_subset(indices, train_set_size, validation_set_size)\n",
    "    # test_indices = get_subset(indices, train_count + validation_count, len(dataset))\n",
    "\n",
    "    # Create sampler objects \n",
    "    train_sampler = SubsetRandomSampler(train_indices)\n",
    "    val_sampler = SubsetRandomSampler(validation_indices)\n",
    "\n",
    "    # Create data loaders for data\n",
    "    train_loader = DataLoader(dataset, batch_size=batch_size, \n",
    "                              sampler=train_sampler, num_workers=4)\n",
    "\n",
    "    val_loader = DataLoader(dataset, batch_size=batch_size, \n",
    "                            sampler=val_sampler, num_workers=4)\n",
    "    \n",
    "    return train_loader, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon_dataset = OfficeAmazonDataset(image_folder_dataset=image_data_folder, transform=data_transforms)\n",
    "train_loader, val_loader = get_dataloader(amazon_dataset, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean and std of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_mean_std(path_dataset):\n",
    "    \"\"\"\n",
    "    Compute mean and standard deviation of an image dataset.\n",
    "    Acknowledgment : http://forums.fast.ai/t/image-normalization-in-pytorch/7534\n",
    "    \"\"\"\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(224),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    dataset = datasets.ImageFolder(root=path_dataset,\n",
    "                                   transform=transform)\n",
    "    # Choose a large batch size to better approximate. Optimally load the dataset entirely on memory.\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=4096, shuffle=False, num_workers=4)\n",
    "\n",
    "    pop_mean = []\n",
    "    pop_std = []\n",
    "\n",
    "    for i, data in enumerate(data_loader, 0):\n",
    "        # shape (batch_size, 3, height, width)\n",
    "        numpy_image = data[0].numpy()\n",
    "\n",
    "        # shape (3,) -> 3 channels\n",
    "        batch_mean = np.mean(numpy_image, axis=(0, 2, 3))\n",
    "        batch_std = np.std(numpy_image, axis=(0, 2, 3))\n",
    "\n",
    "        pop_mean.append(batch_mean)\n",
    "        pop_std.append(batch_std)\n",
    "\n",
    "    # shape (num_iterations, 3) -> (mean across 0th axis) -> shape (3,)\n",
    "    pop_mean = np.array(pop_mean).mean(axis=0)\n",
    "    pop_std = np.array(pop_std).mean(axis=0)\n",
    "\n",
    "    values = {\n",
    "        'mean': pop_mean,\n",
    "        'std': pop_std\n",
    "    }\n",
    "\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://forums.fast.ai/t/image-normalization-in-pytorch/7534/7\n",
    "data_domain = \"amazon\"\n",
    "path_dataset = \"datasets/office/%s/images\" % data_domain\n",
    "\n",
    "transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)), # original image size 300x300 pixels\n",
    "        transforms.ToTensor()])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=path_dataset,\n",
    "                               transform=transform)\n",
    "\n",
    "# set large batch size to get good approximate of mean, std of full dataset\n",
    "data_loader = DataLoader(dataset, batch_size=2048, shuffle=False, num_workers=0) # 4096\n",
    "\n",
    "mean = []\n",
    "std = []\n",
    "\n",
    "for i, data in enumerate(data_loader, 0):\n",
    "    # shape is (batch_size, channels, height, width)\n",
    "    npy_image = data[0].numpy()\n",
    "    \n",
    "    # compute mean, std per batch shape (3,) three channels\n",
    "    batch_mean = np.mean(npy_image, axis=(0,2,3))\n",
    "    batch_std = np.std(npy_image, axis=(0,2,3))\n",
    "    \n",
    "    mean.append(batch_mean)\n",
    "    std.append(batch_std)\n",
    "    \n",
    "# shape (num_iterations, 3) -> (mean across 0th axis) -> shape (3,)\n",
    "mean = np.array(mean).mean(axis=0) # average over batch averages\n",
    "std = np.arry(std).mean(axis=0) # average over batch stds\n",
    "\n",
    "values = {\n",
    "    \"mean\": mean,\n",
    "    \"std\": std\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0234f1d70131>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'values' is not defined"
     ]
    }
   ],
   "source": [
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Python_3_6] *",
   "language": "python",
   "name": "conda-env-Python_3_6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
