{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "deepCORAL_colab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "r3UBtfgPc_J0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyvuKq0weowj",
        "colab_type": "code",
        "outputId": "ec790e96-3fb5-4136-f361-f0e77de28778",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!unzip \"/content/office.zip\" # upload ZIP from computer\n",
        "# !unzip \"/content/drive/My Drive/office.zip\" --> NOT UNZIPING FULL SET"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/office.zip\n",
            "   creating: office/\n",
            "   creating: office/webcam/\n",
            "   creating: office/dslr/\n",
            "   creating: office/amazon/\n",
            "   creating: office/webcam/images/\n",
            "   creating: office/dslr/images/\n",
            "   creating: office/amazon/images/\n",
            "   creating: office/webcam/images/trash_can/\n",
            "  inflating: office/webcam/images/trash_can/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/trash_can/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/trash_can/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/trash_can/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/trash_can/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/trash_can/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/trash_can/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/trash_can/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/trash_can/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/trash_can/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/trash_can/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/trash_can/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/trash_can/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/trash_can/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/trash_can/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/trash_can/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/trash_can/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/trash_can/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/trash_can/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/trash_can/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/trash_can/frame_0001.jpg  \n",
            "   creating: office/webcam/images/tape_dispenser/\n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0023.jpg  \n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0022.jpg  \n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/tape_dispenser/frame_0001.jpg  \n",
            "   creating: office/webcam/images/stapler/\n",
            "  inflating: office/webcam/images/stapler/frame_0024.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0023.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0022.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/stapler/frame_0001.jpg  \n",
            "   creating: office/webcam/images/speaker/\n",
            "  inflating: office/webcam/images/speaker/frame_0030.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0029.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0028.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0027.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0026.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0025.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0024.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0023.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0022.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/speaker/frame_0001.jpg  \n",
            "   creating: office/webcam/images/scissors/\n",
            "  inflating: office/webcam/images/scissors/frame_0025.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0024.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0023.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0022.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/scissors/frame_0001.jpg  \n",
            "   creating: office/webcam/images/ruler/\n",
            "  inflating: office/webcam/images/ruler/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/ruler/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/ruler/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/ruler/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/ruler/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/ruler/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/ruler/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/ruler/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/ruler/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/ruler/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/ruler/frame_0001.jpg  \n",
            "   creating: office/webcam/images/ring_binder/\n",
            "  inflating: office/webcam/images/ring_binder/frame_0040.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0039.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0038.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0037.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0036.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0035.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0034.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0033.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0032.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0031.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0030.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0029.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0028.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0027.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0026.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0025.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0024.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0023.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0022.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/ring_binder/frame_0001.jpg  \n",
            "   creating: office/webcam/images/punchers/\n",
            "  inflating: office/webcam/images/punchers/frame_0027.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0026.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0025.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0024.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0023.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0022.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/punchers/frame_0001.jpg  \n",
            "   creating: office/webcam/images/projector/\n",
            "  inflating: office/webcam/images/projector/frame_0030.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0029.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0028.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0027.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0026.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0025.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0024.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0023.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0022.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/projector/frame_0001.jpg  \n",
            "   creating: office/webcam/images/printer/\n",
            "  inflating: office/webcam/images/printer/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/printer/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/printer/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/printer/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/printer/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/printer/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/printer/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/printer/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/printer/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/printer/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/printer/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/printer/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/printer/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/printer/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/printer/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/printer/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/printer/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/printer/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/printer/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/printer/frame_0001.jpg  \n",
            "   creating: office/webcam/images/phone/\n",
            "  inflating: office/webcam/images/phone/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/phone/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/phone/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/phone/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/phone/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/phone/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/phone/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/phone/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/phone/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/phone/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/phone/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/phone/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/phone/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/phone/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/phone/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/phone/frame_0001.jpg  \n",
            "   creating: office/webcam/images/pen/\n",
            "  inflating: office/webcam/images/pen/frame_0032.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0031.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0030.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0029.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0028.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0027.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0026.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0025.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0024.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0023.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0022.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/pen/frame_0001.jpg  \n",
            "   creating: office/webcam/images/paper_notebook/\n",
            "  inflating: office/webcam/images/paper_notebook/frame_0028.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0027.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0026.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0025.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0024.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0023.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0022.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/paper_notebook/frame_0001.jpg  \n",
            "   creating: office/webcam/images/mug/\n",
            "  inflating: office/webcam/images/mug/frame_0027.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0026.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0025.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0024.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0023.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0022.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/mug/frame_0001.jpg  \n",
            "   creating: office/webcam/images/mouse/\n",
            "  inflating: office/webcam/images/mouse/frame_0030.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0029.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0028.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0027.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0026.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0025.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0024.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0023.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0022.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/mouse/frame_0001.jpg  \n",
            "   creating: office/webcam/images/monitor/\n",
            "  inflating: office/webcam/images/monitor/frame_0043.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0042.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0041.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0040.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0039.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0038.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0037.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0036.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0035.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0034.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0033.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0032.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0031.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0030.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0029.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0028.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0027.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0026.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0025.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0024.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0023.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0022.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/monitor/frame_0001.jpg  \n",
            "   creating: office/webcam/images/mobile_phone/\n",
            "  inflating: office/webcam/images/mobile_phone/frame_0030.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0029.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0028.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0027.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0026.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0025.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0024.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0023.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0022.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/mobile_phone/frame_0001.jpg  \n",
            "   creating: office/webcam/images/letter_tray/\n",
            "  inflating: office/webcam/images/letter_tray/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/letter_tray/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/letter_tray/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/letter_tray/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/letter_tray/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/letter_tray/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/letter_tray/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/letter_tray/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/letter_tray/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/letter_tray/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/letter_tray/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/letter_tray/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/letter_tray/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/letter_tray/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/letter_tray/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/letter_tray/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/letter_tray/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/letter_tray/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/letter_tray/frame_0001.jpg  \n",
            "   creating: office/webcam/images/laptop_computer/\n",
            "  inflating: office/webcam/images/laptop_computer/frame_0030.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0029.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0028.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0027.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0026.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0025.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0024.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0023.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0022.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/laptop_computer/frame_0001.jpg  \n",
            "   creating: office/webcam/images/keyboard/\n",
            "  inflating: office/webcam/images/keyboard/frame_0027.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0026.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0025.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0024.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0023.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0022.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/keyboard/frame_0001.jpg  \n",
            "   creating: office/webcam/images/headphones/\n",
            "  inflating: office/webcam/images/headphones/frame_0027.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0026.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0025.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0024.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0023.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0022.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/headphones/frame_0001.jpg  \n",
            "   creating: office/webcam/images/file_cabinet/\n",
            "  inflating: office/webcam/images/file_cabinet/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/file_cabinet/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/file_cabinet/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/file_cabinet/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/file_cabinet/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/file_cabinet/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/file_cabinet/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/file_cabinet/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/file_cabinet/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/file_cabinet/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/file_cabinet/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/file_cabinet/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/file_cabinet/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/file_cabinet/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/file_cabinet/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/file_cabinet/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/file_cabinet/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/file_cabinet/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/file_cabinet/frame_0001.jpg  \n",
            "   creating: office/webcam/images/desktop_computer/\n",
            "  inflating: office/webcam/images/desktop_computer/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/desktop_computer/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/desktop_computer/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/desktop_computer/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/desktop_computer/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/desktop_computer/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/desktop_computer/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/desktop_computer/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/desktop_computer/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/desktop_computer/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/desktop_computer/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/desktop_computer/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/desktop_computer/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/desktop_computer/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/desktop_computer/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/desktop_computer/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/desktop_computer/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/desktop_computer/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/desktop_computer/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/desktop_computer/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/desktop_computer/frame_0001.jpg  \n",
            "   creating: office/webcam/images/desk_lamp/\n",
            "  inflating: office/webcam/images/desk_lamp/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/desk_lamp/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/desk_lamp/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/desk_lamp/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/desk_lamp/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/desk_lamp/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/desk_lamp/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/desk_lamp/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/desk_lamp/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/desk_lamp/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/desk_lamp/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/desk_lamp/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/desk_lamp/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/desk_lamp/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/desk_lamp/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/desk_lamp/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/desk_lamp/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/desk_lamp/frame_0001.jpg  \n",
            "   creating: office/webcam/images/desk_chair/\n",
            "  inflating: office/webcam/images/desk_chair/frame_0040.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0039.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0038.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0037.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0036.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0035.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0034.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0033.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0032.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0031.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0030.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0029.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0028.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0027.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0026.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0025.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0024.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0023.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0022.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/desk_chair/frame_0001.jpg  \n",
            "   creating: office/webcam/images/calculator/\n",
            "  inflating: office/webcam/images/calculator/frame_0031.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0030.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0029.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0028.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0027.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0026.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0025.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0024.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0023.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0022.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/calculator/frame_0001.jpg  \n",
            "   creating: office/webcam/images/bottle/\n",
            "  inflating: office/webcam/images/bottle/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/bottle/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/bottle/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/bottle/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/bottle/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/bottle/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/bottle/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/bottle/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/bottle/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/bottle/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/bottle/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/bottle/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/bottle/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/bottle/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/bottle/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/bottle/frame_0001.jpg  \n",
            "   creating: office/webcam/images/bookcase/\n",
            "  inflating: office/webcam/images/bookcase/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/bookcase/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/bookcase/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/bookcase/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/bookcase/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/bookcase/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/bookcase/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/bookcase/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/bookcase/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/bookcase/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/bookcase/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/bookcase/frame_0001.jpg  \n",
            "   creating: office/webcam/images/bike_helmet/\n",
            "  inflating: office/webcam/images/bike_helmet/frame_0028.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0027.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0026.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0025.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0024.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0023.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0022.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/bike_helmet/frame_0001.jpg  \n",
            "   creating: office/webcam/images/bike/\n",
            "  inflating: office/webcam/images/bike/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/bike/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/bike/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/bike/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/bike/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/bike/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/bike/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/bike/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/bike/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/bike/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/bike/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/bike/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/bike/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/bike/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/bike/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/bike/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/bike/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/bike/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/bike/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/bike/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/bike/frame_0001.jpg  \n",
            "   creating: office/webcam/images/back_pack/\n",
            "  inflating: office/webcam/images/back_pack/frame_0029.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0028.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0027.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0026.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0025.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0024.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0023.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0022.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0021.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0020.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0019.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0018.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0017.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0016.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0015.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0014.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0013.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0012.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0011.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0010.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0009.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0008.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0007.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0006.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0005.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0004.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0003.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0002.jpg  \n",
            "  inflating: office/webcam/images/back_pack/frame_0001.jpg  \n",
            "   creating: office/dslr/images/trash_can/\n",
            "  inflating: office/dslr/images/trash_can/frame_0015.jpg  \n",
            "  inflating: office/dslr/images/trash_can/frame_0014.jpg  \n",
            "  inflating: office/dslr/images/trash_can/frame_0013.jpg  \n",
            "  inflating: office/dslr/images/trash_can/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/trash_can/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/trash_can/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/trash_can/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/trash_can/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/trash_can/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/trash_can/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/trash_can/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/trash_can/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/trash_can/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/trash_can/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/trash_can/frame_0001.jpg  \n",
            "   creating: office/dslr/images/tape_dispenser/\n",
            "  inflating: office/dslr/images/tape_dispenser/frame_0022.jpg  \n",
            "  inflating: office/dslr/images/tape_dispenser/frame_0021.jpg  \n",
            "  inflating: office/dslr/images/tape_dispenser/frame_0020.jpg  \n",
            "  inflating: office/dslr/images/tape_dispenser/frame_0019.jpg  \n",
            "  inflating: office/dslr/images/tape_dispenser/frame_0018.jpg  \n",
            "  inflating: office/dslr/images/tape_dispenser/frame_0017.jpg  \n",
            "  inflating: office/dslr/images/tape_dispenser/frame_0016.jpg  \n",
            "  inflating: office/dslr/images/tape_dispenser/frame_0015.jpg  \n",
            "  inflating: office/dslr/images/tape_dispenser/frame_0014.jpg  \n",
            "  inflating: office/dslr/images/tape_dispenser/frame_0013.jpg  \n",
            "  inflating: office/dslr/images/tape_dispenser/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/tape_dispenser/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/tape_dispenser/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/tape_dispenser/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/tape_dispenser/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/tape_dispenser/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/tape_dispenser/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/tape_dispenser/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/tape_dispenser/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/tape_dispenser/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/tape_dispenser/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/tape_dispenser/frame_0001.jpg  \n",
            "   creating: office/dslr/images/stapler/\n",
            "  inflating: office/dslr/images/stapler/frame_0021.jpg  \n",
            "  inflating: office/dslr/images/stapler/frame_0020.jpg  \n",
            "  inflating: office/dslr/images/stapler/frame_0019.jpg  \n",
            "  inflating: office/dslr/images/stapler/frame_0018.jpg  \n",
            "  inflating: office/dslr/images/stapler/frame_0017.jpg  \n",
            "  inflating: office/dslr/images/stapler/frame_0016.jpg  \n",
            "  inflating: office/dslr/images/stapler/frame_0015.jpg  \n",
            "  inflating: office/dslr/images/stapler/frame_0014.jpg  \n",
            "  inflating: office/dslr/images/stapler/frame_0013.jpg  \n",
            "  inflating: office/dslr/images/stapler/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/stapler/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/stapler/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/stapler/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/stapler/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/stapler/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/stapler/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/stapler/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/stapler/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/stapler/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/stapler/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/stapler/frame_0001.jpg  \n",
            "   creating: office/dslr/images/speaker/\n",
            "  inflating: office/dslr/images/speaker/frame_0026.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0025.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0024.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0023.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0022.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0021.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0020.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0019.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0018.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0017.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0016.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0015.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0014.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0013.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/speaker/frame_0001.jpg  \n",
            "   creating: office/dslr/images/scissors/\n",
            "  inflating: office/dslr/images/scissors/frame_0018.jpg  \n",
            "  inflating: office/dslr/images/scissors/frame_0017.jpg  \n",
            "  inflating: office/dslr/images/scissors/frame_0016.jpg  \n",
            "  inflating: office/dslr/images/scissors/frame_0015.jpg  \n",
            "  inflating: office/dslr/images/scissors/frame_0014.jpg  \n",
            "  inflating: office/dslr/images/scissors/frame_0013.jpg  \n",
            "  inflating: office/dslr/images/scissors/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/scissors/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/scissors/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/scissors/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/scissors/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/scissors/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/scissors/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/scissors/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/scissors/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/scissors/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/scissors/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/scissors/frame_0001.jpg  \n",
            "   creating: office/dslr/images/ruler/\n",
            "  inflating: office/dslr/images/ruler/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/ruler/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/ruler/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/ruler/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/ruler/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/ruler/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/ruler/frame_0001.jpg  \n",
            "   creating: office/dslr/images/ring_binder/\n",
            "  inflating: office/dslr/images/ring_binder/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/ring_binder/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/ring_binder/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/ring_binder/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/ring_binder/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/ring_binder/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/ring_binder/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/ring_binder/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/ring_binder/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/ring_binder/frame_0001.jpg  \n",
            "   creating: office/dslr/images/punchers/\n",
            "  inflating: office/dslr/images/punchers/frame_0018.jpg  \n",
            "  inflating: office/dslr/images/punchers/frame_0017.jpg  \n",
            "  inflating: office/dslr/images/punchers/frame_0016.jpg  \n",
            "  inflating: office/dslr/images/punchers/frame_0015.jpg  \n",
            "  inflating: office/dslr/images/punchers/frame_0014.jpg  \n",
            "  inflating: office/dslr/images/punchers/frame_0013.jpg  \n",
            "  inflating: office/dslr/images/punchers/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/punchers/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/punchers/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/punchers/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/punchers/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/punchers/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/punchers/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/punchers/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/punchers/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/punchers/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/punchers/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/punchers/frame_0001.jpg  \n",
            "   creating: office/dslr/images/projector/\n",
            "  inflating: office/dslr/images/projector/frame_0023.jpg  \n",
            "  inflating: office/dslr/images/projector/frame_0022.jpg  \n",
            "  inflating: office/dslr/images/projector/frame_0021.jpg  \n",
            "  inflating: office/dslr/images/projector/frame_0020.jpg  \n",
            "  inflating: office/dslr/images/projector/frame_0019.jpg  \n",
            "  inflating: office/dslr/images/projector/frame_0018.jpg  \n",
            "  inflating: office/dslr/images/projector/frame_0017.jpg  \n",
            "  inflating: office/dslr/images/projector/frame_0016.jpg  \n",
            "  inflating: office/dslr/images/projector/frame_0015.jpg  \n",
            "  inflating: office/dslr/images/projector/frame_0014.jpg  \n",
            "  inflating: office/dslr/images/projector/frame_0013.jpg  \n",
            "  inflating: office/dslr/images/projector/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/projector/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/projector/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/projector/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/projector/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/projector/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/projector/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/projector/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/projector/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/projector/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/projector/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/projector/frame_0001.jpg  \n",
            "   creating: office/dslr/images/printer/\n",
            "  inflating: office/dslr/images/printer/frame_0015.jpg  \n",
            "  inflating: office/dslr/images/printer/frame_0014.jpg  \n",
            "  inflating: office/dslr/images/printer/frame_0013.jpg  \n",
            "  inflating: office/dslr/images/printer/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/printer/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/printer/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/printer/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/printer/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/printer/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/printer/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/printer/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/printer/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/printer/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/printer/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/printer/frame_0001.jpg  \n",
            "   creating: office/dslr/images/phone/\n",
            "  inflating: office/dslr/images/phone/frame_0013.jpg  \n",
            "  inflating: office/dslr/images/phone/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/phone/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/phone/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/phone/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/phone/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/phone/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/phone/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/phone/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/phone/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/phone/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/phone/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/phone/frame_0001.jpg  \n",
            "   creating: office/dslr/images/pen/\n",
            "  inflating: office/dslr/images/pen/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/pen/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/pen/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/pen/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/pen/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/pen/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/pen/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/pen/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/pen/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/pen/frame_0001.jpg  \n",
            "   creating: office/dslr/images/paper_notebook/\n",
            "  inflating: office/dslr/images/paper_notebook/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/paper_notebook/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/paper_notebook/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/paper_notebook/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/paper_notebook/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/paper_notebook/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/paper_notebook/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/paper_notebook/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/paper_notebook/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/paper_notebook/frame_0001.jpg  \n",
            "   creating: office/dslr/images/mug/\n",
            "  inflating: office/dslr/images/mug/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/mug/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/mug/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/mug/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/mug/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/mug/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/mug/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/mug/frame_0001.jpg  \n",
            "   creating: office/dslr/images/mouse/\n",
            "  inflating: office/dslr/images/mouse/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/mouse/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/mouse/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/mouse/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/mouse/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/mouse/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/mouse/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/mouse/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/mouse/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/mouse/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/mouse/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/mouse/frame_0001.jpg  \n",
            "   creating: office/dslr/images/monitor/\n",
            "  inflating: office/dslr/images/monitor/frame_0022.jpg  \n",
            "  inflating: office/dslr/images/monitor/frame_0021.jpg  \n",
            "  inflating: office/dslr/images/monitor/frame_0020.jpg  \n",
            "  inflating: office/dslr/images/monitor/frame_0019.jpg  \n",
            "  inflating: office/dslr/images/monitor/frame_0018.jpg  \n",
            "  inflating: office/dslr/images/monitor/frame_0017.jpg  \n",
            "  inflating: office/dslr/images/monitor/frame_0016.jpg  \n",
            "  inflating: office/dslr/images/monitor/frame_0015.jpg  \n",
            "  inflating: office/dslr/images/monitor/frame_0014.jpg  \n",
            "  inflating: office/dslr/images/monitor/frame_0013.jpg  \n",
            "  inflating: office/dslr/images/monitor/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/monitor/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/monitor/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/monitor/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/monitor/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/monitor/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/monitor/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/monitor/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/monitor/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/monitor/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/monitor/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/monitor/frame_0001.jpg  \n",
            "   creating: office/dslr/images/mobile_phone/\n",
            "  inflating: office/dslr/images/mobile_phone/frame_0031.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0030.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0029.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0028.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0027.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0026.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0025.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0024.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0023.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0022.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0021.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0020.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0019.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0018.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0017.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0016.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0015.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0014.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0013.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/mobile_phone/frame_0001.jpg  \n",
            "   creating: office/dslr/images/letter_tray/\n",
            "  inflating: office/dslr/images/letter_tray/frame_0016.jpg  \n",
            "  inflating: office/dslr/images/letter_tray/frame_0015.jpg  \n",
            "  inflating: office/dslr/images/letter_tray/frame_0014.jpg  \n",
            "  inflating: office/dslr/images/letter_tray/frame_0013.jpg  \n",
            "  inflating: office/dslr/images/letter_tray/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/letter_tray/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/letter_tray/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/letter_tray/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/letter_tray/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/letter_tray/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/letter_tray/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/letter_tray/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/letter_tray/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/letter_tray/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/letter_tray/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/letter_tray/frame_0001.jpg  \n",
            "   creating: office/dslr/images/laptop_computer/\n",
            "  inflating: office/dslr/images/laptop_computer/frame_0024.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0023.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0022.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0021.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0020.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0019.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0018.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0017.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0016.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0015.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0014.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0013.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/laptop_computer/frame_0001.jpg  \n",
            "   creating: office/dslr/images/keyboard/\n",
            "  inflating: office/dslr/images/keyboard/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/keyboard/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/keyboard/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/keyboard/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/keyboard/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/keyboard/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/keyboard/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/keyboard/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/keyboard/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/keyboard/frame_0001.jpg  \n",
            "   creating: office/dslr/images/headphones/\n",
            "  inflating: office/dslr/images/headphones/frame_0013.jpg  \n",
            "  inflating: office/dslr/images/headphones/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/headphones/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/headphones/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/headphones/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/headphones/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/headphones/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/headphones/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/headphones/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/headphones/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/headphones/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/headphones/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/headphones/frame_0001.jpg  \n",
            "   creating: office/dslr/images/file_cabinet/\n",
            "  inflating: office/dslr/images/file_cabinet/frame_0015.jpg  \n",
            "  inflating: office/dslr/images/file_cabinet/frame_0014.jpg  \n",
            "  inflating: office/dslr/images/file_cabinet/frame_0013.jpg  \n",
            "  inflating: office/dslr/images/file_cabinet/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/file_cabinet/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/file_cabinet/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/file_cabinet/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/file_cabinet/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/file_cabinet/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/file_cabinet/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/file_cabinet/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/file_cabinet/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/file_cabinet/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/file_cabinet/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/file_cabinet/frame_0001.jpg  \n",
            "   creating: office/dslr/images/desktop_computer/\n",
            "  inflating: office/dslr/images/desktop_computer/frame_0015.jpg  \n",
            "  inflating: office/dslr/images/desktop_computer/frame_0014.jpg  \n",
            "  inflating: office/dslr/images/desktop_computer/frame_0013.jpg  \n",
            "  inflating: office/dslr/images/desktop_computer/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/desktop_computer/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/desktop_computer/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/desktop_computer/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/desktop_computer/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/desktop_computer/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/desktop_computer/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/desktop_computer/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/desktop_computer/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/desktop_computer/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/desktop_computer/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/desktop_computer/frame_0001.jpg  \n",
            "   creating: office/dslr/images/desk_lamp/\n",
            "  inflating: office/dslr/images/desk_lamp/frame_0014.jpg  \n",
            "  inflating: office/dslr/images/desk_lamp/frame_0013.jpg  \n",
            "  inflating: office/dslr/images/desk_lamp/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/desk_lamp/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/desk_lamp/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/desk_lamp/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/desk_lamp/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/desk_lamp/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/desk_lamp/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/desk_lamp/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/desk_lamp/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/desk_lamp/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/desk_lamp/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/desk_lamp/frame_0001.jpg  \n",
            "   creating: office/dslr/images/desk_chair/\n",
            "  inflating: office/dslr/images/desk_chair/frame_0013.jpg  \n",
            "  inflating: office/dslr/images/desk_chair/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/desk_chair/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/desk_chair/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/desk_chair/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/desk_chair/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/desk_chair/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/desk_chair/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/desk_chair/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/desk_chair/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/desk_chair/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/desk_chair/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/desk_chair/frame_0001.jpg  \n",
            "   creating: office/dslr/images/calculator/\n",
            "  inflating: office/dslr/images/calculator/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/calculator/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/calculator/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/calculator/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/calculator/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/calculator/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/calculator/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/calculator/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/calculator/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/calculator/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/calculator/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/calculator/frame_0001.jpg  \n",
            "   creating: office/dslr/images/bottle/\n",
            "  inflating: office/dslr/images/bottle/frame_0016.jpg  \n",
            "  inflating: office/dslr/images/bottle/frame_0015.jpg  \n",
            "  inflating: office/dslr/images/bottle/frame_0014.jpg  \n",
            "  inflating: office/dslr/images/bottle/frame_0013.jpg  \n",
            "  inflating: office/dslr/images/bottle/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/bottle/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/bottle/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/bottle/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/bottle/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/bottle/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/bottle/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/bottle/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/bottle/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/bottle/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/bottle/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/bottle/frame_0001.jpg  \n",
            "   creating: office/dslr/images/bookcase/\n",
            "  inflating: office/dslr/images/bookcase/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/bookcase/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/bookcase/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/bookcase/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/bookcase/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/bookcase/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/bookcase/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/bookcase/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/bookcase/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/bookcase/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/bookcase/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/bookcase/frame_0001.jpg  \n",
            "   creating: office/dslr/images/bike_helmet/\n",
            "  inflating: office/dslr/images/bike_helmet/frame_0024.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0023.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0022.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0021.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0020.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0019.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0018.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0017.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0016.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0015.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0014.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0013.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/bike_helmet/frame_0001.jpg  \n",
            "   creating: office/dslr/images/bike/\n",
            "  inflating: office/dslr/images/bike/frame_0021.jpg  \n",
            "  inflating: office/dslr/images/bike/frame_0020.jpg  \n",
            "  inflating: office/dslr/images/bike/frame_0019.jpg  \n",
            "  inflating: office/dslr/images/bike/frame_0018.jpg  \n",
            "  inflating: office/dslr/images/bike/frame_0017.jpg  \n",
            "  inflating: office/dslr/images/bike/frame_0016.jpg  \n",
            "  inflating: office/dslr/images/bike/frame_0015.jpg  \n",
            "  inflating: office/dslr/images/bike/frame_0014.jpg  \n",
            "  inflating: office/dslr/images/bike/frame_0013.jpg  \n",
            "  inflating: office/dslr/images/bike/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/bike/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/bike/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/bike/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/bike/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/bike/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/bike/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/bike/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/bike/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/bike/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/bike/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/bike/frame_0001.jpg  \n",
            "   creating: office/dslr/images/back_pack/\n",
            "  inflating: office/dslr/images/back_pack/frame_0012.jpg  \n",
            "  inflating: office/dslr/images/back_pack/frame_0011.jpg  \n",
            "  inflating: office/dslr/images/back_pack/frame_0010.jpg  \n",
            "  inflating: office/dslr/images/back_pack/frame_0009.jpg  \n",
            "  inflating: office/dslr/images/back_pack/frame_0008.jpg  \n",
            "  inflating: office/dslr/images/back_pack/frame_0007.jpg  \n",
            "  inflating: office/dslr/images/back_pack/frame_0006.jpg  \n",
            "  inflating: office/dslr/images/back_pack/frame_0005.jpg  \n",
            "  inflating: office/dslr/images/back_pack/frame_0004.jpg  \n",
            "  inflating: office/dslr/images/back_pack/frame_0003.jpg  \n",
            "  inflating: office/dslr/images/back_pack/frame_0002.jpg  \n",
            "  inflating: office/dslr/images/back_pack/frame_0001.jpg  \n",
            "   creating: office/amazon/images/trash_can/\n",
            "  inflating: office/amazon/images/trash_can/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/trash_can/frame_0001.jpg  \n",
            "   creating: office/amazon/images/tape_dispenser/\n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0096.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0095.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0094.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0093.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0092.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/tape_dispenser/frame_0001.jpg  \n",
            "   creating: office/amazon/images/stapler/\n",
            "  inflating: office/amazon/images/stapler/frame_0099.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0098.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0097.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0096.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0095.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0094.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0093.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0092.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/stapler/frame_0001.jpg  \n",
            "   creating: office/amazon/images/speaker/\n",
            "  inflating: office/amazon/images/speaker/frame_0099.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0098.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0097.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0096.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0095.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0094.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0093.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0092.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/speaker/frame_0001.jpg  \n",
            "   creating: office/amazon/images/scissors/\n",
            "  inflating: office/amazon/images/scissors/frame_0100.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0099.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0098.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0097.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0096.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0095.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0094.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0093.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0092.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/scissors/frame_0001.jpg  \n",
            "   creating: office/amazon/images/ruler/\n",
            "  inflating: office/amazon/images/ruler/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/ruler/frame_0001.jpg  \n",
            "   creating: office/amazon/images/ring_binder/\n",
            "  inflating: office/amazon/images/ring_binder/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/ring_binder/frame_0001.jpg  \n",
            "   creating: office/amazon/images/punchers/\n",
            "  inflating: office/amazon/images/punchers/frame_0098.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0097.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0096.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0095.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0094.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0093.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0092.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/punchers/frame_0001.jpg  \n",
            "   creating: office/amazon/images/projector/\n",
            "  inflating: office/amazon/images/projector/frame_0098.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0097.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0096.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0095.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0094.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0093.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0092.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/projector/frame_0001.jpg  \n",
            "   creating: office/amazon/images/printer/\n",
            "  inflating: office/amazon/images/printer/frame_0100.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0099.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0098.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0097.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0096.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0095.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0094.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0093.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0092.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/printer/frame_0001.jpg  \n",
            "   creating: office/amazon/images/phone/\n",
            "  inflating: office/amazon/images/phone/frame_0093.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0092.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/phone/frame_0001.jpg  \n",
            "   creating: office/amazon/images/pen/\n",
            "  inflating: office/amazon/images/pen/frame_0095.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0094.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0093.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0092.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/pen/frame_0001.jpg  \n",
            "   creating: office/amazon/images/paper_notebook/\n",
            "  inflating: office/amazon/images/paper_notebook/frame_0096.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0095.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0094.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0093.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0092.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/paper_notebook/frame_0001.jpg  \n",
            "   creating: office/amazon/images/mug/\n",
            "  inflating: office/amazon/images/mug/frame_0094.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0093.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0092.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/mug/frame_0001.jpg  \n",
            "   creating: office/amazon/images/mouse/\n",
            "  inflating: office/amazon/images/mouse/frame_0100.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0099.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0098.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0097.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0096.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0095.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0094.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0093.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0092.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/mouse/frame_0001.jpg  \n",
            "   creating: office/amazon/images/monitor/\n",
            "  inflating: office/amazon/images/monitor/frame_0099.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0098.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0097.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0096.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0095.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0094.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0093.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0092.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/monitor/frame_0001.jpg  \n",
            "   creating: office/amazon/images/mobile_phone/\n",
            "  inflating: office/amazon/images/mobile_phone/frame_0100.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0099.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0098.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0097.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0096.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0095.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0094.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0093.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0092.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/mobile_phone/frame_0001.jpg  \n",
            "   creating: office/amazon/images/letter_tray/\n",
            "  inflating: office/amazon/images/letter_tray/frame_0098.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0097.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0096.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0095.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0094.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0093.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0092.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/letter_tray/frame_0001.jpg  \n",
            "   creating: office/amazon/images/laptop_computer/\n",
            "  inflating: office/amazon/images/laptop_computer/frame_0100.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0099.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0098.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0097.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0096.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0095.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0094.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0093.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0092.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/laptop_computer/frame_0001.jpg  \n",
            "   creating: office/amazon/images/keyboard/\n",
            "  inflating: office/amazon/images/keyboard/frame_0100.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0099.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0098.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0097.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0096.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0095.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0094.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0093.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0092.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/keyboard/frame_0001.jpg  \n",
            "   creating: office/amazon/images/headphones/\n",
            "  inflating: office/amazon/images/headphones/frame_0099.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0098.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0097.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0096.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0095.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0094.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0093.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0092.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/headphones/frame_0001.jpg  \n",
            "   creating: office/amazon/images/file_cabinet/\n",
            "  inflating: office/amazon/images/file_cabinet/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/file_cabinet/frame_0001.jpg  \n",
            "   creating: office/amazon/images/desktop_computer/\n",
            "  inflating: office/amazon/images/desktop_computer/frame_0097.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0096.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0095.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0094.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0093.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0092.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/desktop_computer/frame_0001.jpg  \n",
            "   creating: office/amazon/images/desk_lamp/\n",
            "  inflating: office/amazon/images/desk_lamp/frame_0097.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0096.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0095.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0094.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0093.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0092.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/desk_lamp/frame_0001.jpg  \n",
            "   creating: office/amazon/images/desk_chair/\n",
            "  inflating: office/amazon/images/desk_chair/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/desk_chair/frame_0001.jpg  \n",
            "   creating: office/amazon/images/calculator/\n",
            "  inflating: office/amazon/images/calculator/frame_0094.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0093.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0092.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/calculator/frame_0001.jpg  \n",
            "   creating: office/amazon/images/bottle/\n",
            "  inflating: office/amazon/images/bottle/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/bottle/frame_0001.jpg  \n",
            "   creating: office/amazon/images/bookcase/\n",
            "  inflating: office/amazon/images/bookcase/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/bookcase/frame_0001.jpg  \n",
            "   creating: office/amazon/images/bike_helmet/\n",
            "  inflating: office/amazon/images/bike_helmet/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/bike_helmet/frame_0001.jpg  \n",
            "   creating: office/amazon/images/bike/\n",
            "  inflating: office/amazon/images/bike/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/bike/frame_0001.jpg  \n",
            "   creating: office/amazon/images/back_pack/\n",
            "  inflating: office/amazon/images/back_pack/frame_0092.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0091.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0090.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0089.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0088.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0087.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0086.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0085.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0084.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0083.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0082.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0081.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0080.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0079.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0078.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0077.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0076.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0075.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0074.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0073.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0072.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0071.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0070.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0069.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0068.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0067.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0066.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0065.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0064.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0063.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0062.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0061.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0060.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0059.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0058.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0057.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0056.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0055.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0054.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0053.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0052.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0051.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0050.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0049.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0048.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0047.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0046.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0045.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0044.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0043.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0042.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0041.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0040.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0039.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0038.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0037.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0036.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0035.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0034.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0033.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0032.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0031.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0030.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0029.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0028.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0027.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0026.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0025.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0024.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0023.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0022.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0021.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0020.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0019.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0018.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0017.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0016.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0015.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0014.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0013.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0012.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0011.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0010.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0009.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0008.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0007.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0006.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0005.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0004.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0003.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0002.jpg  \n",
            "  inflating: office/amazon/images/back_pack/frame_0001.jpg  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULT5B1V_qdLg",
        "colab_type": "code",
        "outputId": "013f34be-8b16-4675-85b4-188edf937b2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# verify image has been uploaded correctly to colab\n",
        "img = cv2.imread(\"/content/office/webcam/images/pen/frame_0002.jpg\")\n",
        "img_cvt=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img_cvt)\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQEAAAD8CAYAAAB3lxGOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xkz6q979hxgG",
        "colab_type": "code",
        "outputId": "bbde110c-52de-4bb8-9a65-269269620cfc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "print(\">>> Colab CUDA info <<<\")\n",
        "print(torch.cuda.current_device())\n",
        "print(torch.cuda.device(0))\n",
        "print(torch.cuda.device_count())\n",
        "print(torch.cuda.get_device_name(0))\n",
        "print(torch.cuda.is_available())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Colab CUDA info <<<\n",
            "0\n",
            "<torch.cuda.device object at 0x7f4deb8c7748>\n",
            "1\n",
            "Tesla K80\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJqDZL44jKue",
        "colab_type": "code",
        "outputId": "59f5762a-578d-4118-b2d0-1c5f92d9f2f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train DeepCORAL w/ domain adaptation\n",
        "!python /content/main.py --epochs 100 --batch_size_source 128 --batch_size_target 128 --name_source amazon --name_target webcam --adapt_domain"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating source/target dataloaders...\n",
            "source data: amazon\n",
            "target data: webcam\n",
            "using cuda...\n",
            "loading pre-trained AlexNet...\n",
            "loaded model correctly...\n",
            "model type: <class 'model.DeepCORAL'>\n",
            "adapt domain: True\n",
            "running training for 100 epochs...\n",
            "HBox(children=(IntProgress(value=0), HTML(value='')))\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  1 [ 1/ 6]\tLambda value: 0.0100, Classification loss: 3.446163, CORAL loss: 0.000009, Total_Loss: 3.446163\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  1 [ 2/ 6]\tLambda value: 0.0100, Classification loss: 3.013056, CORAL loss: 0.000015, Total_Loss: 3.013056\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  1 [ 3/ 6]\tLambda value: 0.0100, Classification loss: 2.715696, CORAL loss: 0.000094, Total_Loss: 2.715697\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  1 [ 4/ 6]\tLambda value: 0.0100, Classification loss: 2.241439, CORAL loss: 0.012358, Total_Loss: 2.241562\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  1 [ 5/ 6]\tLambda value: 0.0100, Classification loss: 1.866705, CORAL loss: 0.004886, Total_Loss: 1.866754\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  1 [ 6/ 6]\tLambda value: 0.0100, Classification loss: 1.723142, CORAL loss: 0.008024, Total_Loss: 1.723222\n",
            "[EPOCH] 1: Classification loss: 2.501034, CORAL loss: 0.004231, Total_Loss: 2.501076\n",
            "[Test Source]: Epoch: 1, avg_loss: 1.2983, Accuracy: 1781/2817 (63.22%)\n",
            "[Test Target]: Epoch: 1, avg_loss: 1.9891, Accuracy: 328/795 (41.26%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  2 [ 1/ 6]\tLambda value: 0.0200, Classification loss: 1.533039, CORAL loss: 0.037085, Total_Loss: 1.533781\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  2 [ 2/ 6]\tLambda value: 0.0200, Classification loss: 1.288119, CORAL loss: 0.036258, Total_Loss: 1.288844\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  2 [ 3/ 6]\tLambda value: 0.0200, Classification loss: 1.145796, CORAL loss: 0.033621, Total_Loss: 1.146469\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  2 [ 4/ 6]\tLambda value: 0.0200, Classification loss: 0.991435, CORAL loss: 0.260813, Total_Loss: 0.996651\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  2 [ 5/ 6]\tLambda value: 0.0200, Classification loss: 1.334179, CORAL loss: 0.254044, Total_Loss: 1.339260\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  2 [ 6/ 6]\tLambda value: 0.0200, Classification loss: 1.214310, CORAL loss: 0.110693, Total_Loss: 1.216523\n",
            "[EPOCH] 2: Classification loss: 1.251146, CORAL loss: 0.122086, Total_Loss: 1.253588\n",
            "[Test Source]: Epoch: 2, avg_loss: 0.9404, Accuracy: 2119/2817 (75.22%)\n",
            "[Test Target]: Epoch: 2, avg_loss: 2.0341, Accuracy: 352/795 (44.28%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  3 [ 1/ 6]\tLambda value: 0.0300, Classification loss: 1.078968, CORAL loss: 0.308050, Total_Loss: 1.088210\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  3 [ 2/ 6]\tLambda value: 0.0300, Classification loss: 1.045923, CORAL loss: 0.131002, Total_Loss: 1.049853\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  3 [ 3/ 6]\tLambda value: 0.0300, Classification loss: 1.040488, CORAL loss: 0.156145, Total_Loss: 1.045172\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  3 [ 4/ 6]\tLambda value: 0.0300, Classification loss: 1.257284, CORAL loss: 0.149206, Total_Loss: 1.261761\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  3 [ 5/ 6]\tLambda value: 0.0300, Classification loss: 1.496849, CORAL loss: 0.353411, Total_Loss: 1.507452\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  3 [ 6/ 6]\tLambda value: 0.0300, Classification loss: 1.007050, CORAL loss: 0.218887, Total_Loss: 1.013617\n",
            "[EPOCH] 3: Classification loss: 1.154427, CORAL loss: 0.219450, Total_Loss: 1.161011\n",
            "[Test Source]: Epoch: 3, avg_loss: 0.8072, Accuracy: 2204/2817 (78.24%)\n",
            "[Test Target]: Epoch: 3, avg_loss: 2.0751, Accuracy: 361/795 (45.41%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  4 [ 1/ 6]\tLambda value: 0.0400, Classification loss: 0.746614, CORAL loss: 0.819889, Total_Loss: 0.779409\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  4 [ 2/ 6]\tLambda value: 0.0400, Classification loss: 1.086682, CORAL loss: 0.412856, Total_Loss: 1.103196\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  4 [ 3/ 6]\tLambda value: 0.0400, Classification loss: 0.995064, CORAL loss: 0.241452, Total_Loss: 1.004722\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  4 [ 4/ 6]\tLambda value: 0.0400, Classification loss: 0.927711, CORAL loss: 0.274113, Total_Loss: 0.938676\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  4 [ 5/ 6]\tLambda value: 0.0400, Classification loss: 0.652365, CORAL loss: 0.126296, Total_Loss: 0.657417\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  4 [ 6/ 6]\tLambda value: 0.0400, Classification loss: 0.992616, CORAL loss: 0.092048, Total_Loss: 0.996298\n",
            "[EPOCH] 4: Classification loss: 0.900175, CORAL loss: 0.327776, Total_Loss: 0.913286\n",
            "[Test Source]: Epoch: 4, avg_loss: 0.7322, Accuracy: 2259/2817 (80.19%)\n",
            "[Test Target]: Epoch: 4, avg_loss: 2.2143, Accuracy: 331/795 (41.64%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  5 [ 1/ 6]\tLambda value: 0.0500, Classification loss: 0.755221, CORAL loss: 0.073865, Total_Loss: 0.758915\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  5 [ 2/ 6]\tLambda value: 0.0500, Classification loss: 0.783940, CORAL loss: 0.157005, Total_Loss: 0.791790\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  5 [ 3/ 6]\tLambda value: 0.0500, Classification loss: 0.716117, CORAL loss: 0.155658, Total_Loss: 0.723900\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  5 [ 4/ 6]\tLambda value: 0.0500, Classification loss: 0.616378, CORAL loss: 0.129662, Total_Loss: 0.622861\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  5 [ 5/ 6]\tLambda value: 0.0500, Classification loss: 0.681553, CORAL loss: 0.076938, Total_Loss: 0.685400\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  5 [ 6/ 6]\tLambda value: 0.0500, Classification loss: 0.572959, CORAL loss: 0.093356, Total_Loss: 0.577627\n",
            "[EPOCH] 5: Classification loss: 0.687695, CORAL loss: 0.114414, Total_Loss: 0.693415\n",
            "[Test Source]: Epoch: 5, avg_loss: 0.5920, Accuracy: 2360/2817 (83.78%)\n",
            "[Test Target]: Epoch: 5, avg_loss: 1.9515, Accuracy: 349/795 (43.90%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  6 [ 1/ 6]\tLambda value: 0.0600, Classification loss: 0.749871, CORAL loss: 0.080933, Total_Loss: 0.754727\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  6 [ 2/ 6]\tLambda value: 0.0600, Classification loss: 0.600179, CORAL loss: 0.095985, Total_Loss: 0.605938\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  6 [ 3/ 6]\tLambda value: 0.0600, Classification loss: 0.537175, CORAL loss: 0.369165, Total_Loss: 0.559325\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  6 [ 4/ 6]\tLambda value: 0.0600, Classification loss: 0.649071, CORAL loss: 0.161327, Total_Loss: 0.658750\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  6 [ 5/ 6]\tLambda value: 0.0600, Classification loss: 0.711447, CORAL loss: 0.049989, Total_Loss: 0.714446\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  6 [ 6/ 6]\tLambda value: 0.0600, Classification loss: 0.688463, CORAL loss: 0.061425, Total_Loss: 0.692148\n",
            "[EPOCH] 6: Classification loss: 0.656034, CORAL loss: 0.136471, Total_Loss: 0.664223\n",
            "[Test Source]: Epoch: 6, avg_loss: 0.5068, Accuracy: 2441/2817 (86.65%)\n",
            "[Test Target]: Epoch: 6, avg_loss: 1.9338, Accuracy: 348/795 (43.77%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  7 [ 1/ 6]\tLambda value: 0.0700, Classification loss: 0.637574, CORAL loss: 0.081611, Total_Loss: 0.643287\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  7 [ 2/ 6]\tLambda value: 0.0700, Classification loss: 0.592561, CORAL loss: 0.050656, Total_Loss: 0.596107\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  7 [ 3/ 6]\tLambda value: 0.0700, Classification loss: 0.568217, CORAL loss: 0.072137, Total_Loss: 0.573267\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  7 [ 4/ 6]\tLambda value: 0.0700, Classification loss: 0.531910, CORAL loss: 0.098731, Total_Loss: 0.538821\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  7 [ 5/ 6]\tLambda value: 0.0700, Classification loss: 0.760128, CORAL loss: 0.044219, Total_Loss: 0.763224\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  7 [ 6/ 6]\tLambda value: 0.0700, Classification loss: 0.654502, CORAL loss: 0.046935, Total_Loss: 0.657788\n",
            "[EPOCH] 7: Classification loss: 0.624149, CORAL loss: 0.065715, Total_Loss: 0.628749\n",
            "[Test Source]: Epoch: 7, avg_loss: 0.4471, Accuracy: 2479/2817 (88.00%)\n",
            "[Test Target]: Epoch: 7, avg_loss: 1.8964, Accuracy: 359/795 (45.16%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  8 [ 1/ 6]\tLambda value: 0.0800, Classification loss: 0.457141, CORAL loss: 0.091319, Total_Loss: 0.464446\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  8 [ 2/ 6]\tLambda value: 0.0800, Classification loss: 0.301766, CORAL loss: 0.083685, Total_Loss: 0.308461\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  8 [ 3/ 6]\tLambda value: 0.0800, Classification loss: 0.513283, CORAL loss: 0.039093, Total_Loss: 0.516410\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  8 [ 4/ 6]\tLambda value: 0.0800, Classification loss: 0.430052, CORAL loss: 0.054819, Total_Loss: 0.434438\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  8 [ 5/ 6]\tLambda value: 0.0800, Classification loss: 0.635869, CORAL loss: 0.325291, Total_Loss: 0.661892\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  8 [ 6/ 6]\tLambda value: 0.0800, Classification loss: 0.402747, CORAL loss: 0.105922, Total_Loss: 0.411220\n",
            "[EPOCH] 8: Classification loss: 0.456809, CORAL loss: 0.116688, Total_Loss: 0.466145\n",
            "[Test Source]: Epoch: 8, avg_loss: 0.3814, Accuracy: 2521/2817 (89.49%)\n",
            "[Test Target]: Epoch: 8, avg_loss: 1.9615, Accuracy: 346/795 (43.52%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  9 [ 1/ 6]\tLambda value: 0.0900, Classification loss: 0.255721, CORAL loss: 0.068410, Total_Loss: 0.261878\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  9 [ 2/ 6]\tLambda value: 0.0900, Classification loss: 0.440308, CORAL loss: 0.098663, Total_Loss: 0.449188\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  9 [ 3/ 6]\tLambda value: 0.0900, Classification loss: 0.441571, CORAL loss: 0.121664, Total_Loss: 0.452521\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  9 [ 4/ 6]\tLambda value: 0.0900, Classification loss: 0.521886, CORAL loss: 0.125477, Total_Loss: 0.533179\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  9 [ 5/ 6]\tLambda value: 0.0900, Classification loss: 0.542401, CORAL loss: 0.197792, Total_Loss: 0.560203\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  9 [ 6/ 6]\tLambda value: 0.0900, Classification loss: 0.630676, CORAL loss: 0.106300, Total_Loss: 0.640243\n",
            "[EPOCH] 9: Classification loss: 0.472094, CORAL loss: 0.119717, Total_Loss: 0.482869\n",
            "[Test Source]: Epoch: 9, avg_loss: 0.3385, Accuracy: 2566/2817 (91.09%)\n",
            "[Test Target]: Epoch: 9, avg_loss: 2.0209, Accuracy: 344/795 (43.27%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 10 [ 1/ 6]\tLambda value: 0.1000, Classification loss: 0.342803, CORAL loss: 0.159051, Total_Loss: 0.358708\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 10 [ 2/ 6]\tLambda value: 0.1000, Classification loss: 0.331823, CORAL loss: 0.200892, Total_Loss: 0.351912\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 10 [ 3/ 6]\tLambda value: 0.1000, Classification loss: 0.473766, CORAL loss: 0.216368, Total_Loss: 0.495402\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 10 [ 4/ 6]\tLambda value: 0.1000, Classification loss: 0.383366, CORAL loss: 0.134940, Total_Loss: 0.396861\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 10 [ 5/ 6]\tLambda value: 0.1000, Classification loss: 0.503952, CORAL loss: 0.087897, Total_Loss: 0.512742\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 10 [ 6/ 6]\tLambda value: 0.1000, Classification loss: 0.427272, CORAL loss: 0.116780, Total_Loss: 0.438950\n",
            "[EPOCH] 10: Classification loss: 0.410497, CORAL loss: 0.152655, Total_Loss: 0.425762\n",
            "[Test Source]: Epoch: 10, avg_loss: 0.2987, Accuracy: 2596/2817 (92.15%)\n",
            "[Test Target]: Epoch: 10, avg_loss: 1.8850, Accuracy: 358/795 (45.03%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 11 [ 1/ 6]\tLambda value: 0.1100, Classification loss: 0.640129, CORAL loss: 0.134012, Total_Loss: 0.654870\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 11 [ 2/ 6]\tLambda value: 0.1100, Classification loss: 0.467367, CORAL loss: 0.158220, Total_Loss: 0.484771\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 11 [ 3/ 6]\tLambda value: 0.1100, Classification loss: 0.409312, CORAL loss: 0.179150, Total_Loss: 0.429019\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 11 [ 4/ 6]\tLambda value: 0.1100, Classification loss: 0.289147, CORAL loss: 0.156150, Total_Loss: 0.306323\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 11 [ 5/ 6]\tLambda value: 0.1100, Classification loss: 0.326064, CORAL loss: 0.128285, Total_Loss: 0.340176\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 11 [ 6/ 6]\tLambda value: 0.1100, Classification loss: 0.246105, CORAL loss: 0.076587, Total_Loss: 0.254529\n",
            "[EPOCH] 11: Classification loss: 0.396354, CORAL loss: 0.138734, Total_Loss: 0.411615\n",
            "[Test Source]: Epoch: 11, avg_loss: 0.2567, Accuracy: 2629/2817 (93.33%)\n",
            "[Test Target]: Epoch: 11, avg_loss: 1.9299, Accuracy: 358/795 (45.03%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 12 [ 1/ 6]\tLambda value: 0.1200, Classification loss: 0.269975, CORAL loss: 0.137278, Total_Loss: 0.286449\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 12 [ 2/ 6]\tLambda value: 0.1200, Classification loss: 0.375725, CORAL loss: 0.098690, Total_Loss: 0.387568\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 12 [ 3/ 6]\tLambda value: 0.1200, Classification loss: 0.264401, CORAL loss: 0.180041, Total_Loss: 0.286006\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 12 [ 4/ 6]\tLambda value: 0.1200, Classification loss: 0.305123, CORAL loss: 0.097539, Total_Loss: 0.316828\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 12 [ 5/ 6]\tLambda value: 0.1200, Classification loss: 0.252751, CORAL loss: 0.142083, Total_Loss: 0.269801\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 12 [ 6/ 6]\tLambda value: 0.1200, Classification loss: 0.305844, CORAL loss: 0.095085, Total_Loss: 0.317255\n",
            "[EPOCH] 12: Classification loss: 0.295637, CORAL loss: 0.125119, Total_Loss: 0.310651\n",
            "[Test Source]: Epoch: 12, avg_loss: 0.2326, Accuracy: 2648/2817 (94.00%)\n",
            "[Test Target]: Epoch: 12, avg_loss: 1.9202, Accuracy: 361/795 (45.41%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 13 [ 1/ 6]\tLambda value: 0.1300, Classification loss: 0.257183, CORAL loss: 0.097213, Total_Loss: 0.269820\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 13 [ 2/ 6]\tLambda value: 0.1300, Classification loss: 0.375800, CORAL loss: 0.150432, Total_Loss: 0.395357\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 13 [ 3/ 6]\tLambda value: 0.1300, Classification loss: 0.273013, CORAL loss: 0.099327, Total_Loss: 0.285925\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 13 [ 4/ 6]\tLambda value: 0.1300, Classification loss: 0.343883, CORAL loss: 0.209671, Total_Loss: 0.371140\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 13 [ 5/ 6]\tLambda value: 0.1300, Classification loss: 0.181425, CORAL loss: 0.153478, Total_Loss: 0.201377\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 13 [ 6/ 6]\tLambda value: 0.1300, Classification loss: 0.404455, CORAL loss: 0.105963, Total_Loss: 0.418230\n",
            "[EPOCH] 13: Classification loss: 0.305960, CORAL loss: 0.136014, Total_Loss: 0.323642\n",
            "[Test Source]: Epoch: 13, avg_loss: 0.2095, Accuracy: 2670/2817 (94.78%)\n",
            "[Test Target]: Epoch: 13, avg_loss: 1.8329, Accuracy: 372/795 (46.79%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 14 [ 1/ 6]\tLambda value: 0.1400, Classification loss: 0.215719, CORAL loss: 0.172924, Total_Loss: 0.239928\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 14 [ 2/ 6]\tLambda value: 0.1400, Classification loss: 0.431703, CORAL loss: 0.115797, Total_Loss: 0.447915\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 14 [ 3/ 6]\tLambda value: 0.1400, Classification loss: 0.171674, CORAL loss: 0.101693, Total_Loss: 0.185911\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 14 [ 4/ 6]\tLambda value: 0.1400, Classification loss: 0.202884, CORAL loss: 0.163388, Total_Loss: 0.225758\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 14 [ 5/ 6]\tLambda value: 0.1400, Classification loss: 0.378755, CORAL loss: 0.091311, Total_Loss: 0.391538\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 14 [ 6/ 6]\tLambda value: 0.1400, Classification loss: 0.290770, CORAL loss: 0.148169, Total_Loss: 0.311514\n",
            "[EPOCH] 14: Classification loss: 0.281917, CORAL loss: 0.132214, Total_Loss: 0.300427\n",
            "[Test Source]: Epoch: 14, avg_loss: 0.1979, Accuracy: 2685/2817 (95.31%)\n",
            "[Test Target]: Epoch: 14, avg_loss: 1.9094, Accuracy: 370/795 (46.54%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 15 [ 1/ 6]\tLambda value: 0.1500, Classification loss: 0.300498, CORAL loss: 0.099100, Total_Loss: 0.315363\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 15 [ 2/ 6]\tLambda value: 0.1500, Classification loss: 0.208794, CORAL loss: 0.084739, Total_Loss: 0.221505\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 15 [ 3/ 6]\tLambda value: 0.1500, Classification loss: 0.194788, CORAL loss: 0.127807, Total_Loss: 0.213959\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 15 [ 4/ 6]\tLambda value: 0.1500, Classification loss: 0.197555, CORAL loss: 0.103895, Total_Loss: 0.213139\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 15 [ 5/ 6]\tLambda value: 0.1500, Classification loss: 0.412037, CORAL loss: 0.126492, Total_Loss: 0.431011\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 15 [ 6/ 6]\tLambda value: 0.1500, Classification loss: 0.256404, CORAL loss: 0.051353, Total_Loss: 0.264107\n",
            "[EPOCH] 15: Classification loss: 0.261679, CORAL loss: 0.098898, Total_Loss: 0.276514\n",
            "[Test Source]: Epoch: 15, avg_loss: 0.1750, Accuracy: 2692/2817 (95.56%)\n",
            "[Test Target]: Epoch: 15, avg_loss: 1.9567, Accuracy: 369/795 (46.42%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 16 [ 1/ 6]\tLambda value: 0.1600, Classification loss: 0.224371, CORAL loss: 0.135539, Total_Loss: 0.246057\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 16 [ 2/ 6]\tLambda value: 0.1600, Classification loss: 0.193967, CORAL loss: 0.122617, Total_Loss: 0.213586\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 16 [ 3/ 6]\tLambda value: 0.1600, Classification loss: 0.198647, CORAL loss: 0.109808, Total_Loss: 0.216216\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 16 [ 4/ 6]\tLambda value: 0.1600, Classification loss: 0.233815, CORAL loss: 0.070840, Total_Loss: 0.245150\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 16 [ 5/ 6]\tLambda value: 0.1600, Classification loss: 0.270483, CORAL loss: 0.137217, Total_Loss: 0.292438\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 16 [ 6/ 6]\tLambda value: 0.1600, Classification loss: 0.263147, CORAL loss: 0.096430, Total_Loss: 0.278576\n",
            "[EPOCH] 16: Classification loss: 0.230738, CORAL loss: 0.112075, Total_Loss: 0.248670\n",
            "[Test Source]: Epoch: 16, avg_loss: 0.1590, Accuracy: 2717/2817 (96.45%)\n",
            "[Test Target]: Epoch: 16, avg_loss: 1.9045, Accuracy: 366/795 (46.04%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 17 [ 1/ 6]\tLambda value: 0.1700, Classification loss: 0.263765, CORAL loss: 0.074946, Total_Loss: 0.276506\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 17 [ 2/ 6]\tLambda value: 0.1700, Classification loss: 0.325903, CORAL loss: 0.104970, Total_Loss: 0.343748\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 17 [ 3/ 6]\tLambda value: 0.1700, Classification loss: 0.232371, CORAL loss: 0.096101, Total_Loss: 0.248708\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 17 [ 4/ 6]\tLambda value: 0.1700, Classification loss: 0.205685, CORAL loss: 0.107963, Total_Loss: 0.224039\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 17 [ 5/ 6]\tLambda value: 0.1700, Classification loss: 0.263829, CORAL loss: 0.115767, Total_Loss: 0.283509\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 17 [ 6/ 6]\tLambda value: 0.1700, Classification loss: 0.143888, CORAL loss: 0.135989, Total_Loss: 0.167007\n",
            "[EPOCH] 17: Classification loss: 0.239240, CORAL loss: 0.105956, Total_Loss: 0.257253\n",
            "[Test Source]: Epoch: 17, avg_loss: 0.1399, Accuracy: 2733/2817 (97.02%)\n",
            "[Test Target]: Epoch: 17, avg_loss: 1.7854, Accuracy: 400/795 (50.31%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 18 [ 1/ 6]\tLambda value: 0.1800, Classification loss: 0.181198, CORAL loss: 0.113857, Total_Loss: 0.201692\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 18 [ 2/ 6]\tLambda value: 0.1800, Classification loss: 0.180335, CORAL loss: 0.082958, Total_Loss: 0.195268\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 18 [ 3/ 6]\tLambda value: 0.1800, Classification loss: 0.173693, CORAL loss: 0.133331, Total_Loss: 0.197693\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 18 [ 4/ 6]\tLambda value: 0.1800, Classification loss: 0.256300, CORAL loss: 0.108285, Total_Loss: 0.275791\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 18 [ 5/ 6]\tLambda value: 0.1800, Classification loss: 0.164471, CORAL loss: 0.082850, Total_Loss: 0.179384\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 18 [ 6/ 6]\tLambda value: 0.1800, Classification loss: 0.300520, CORAL loss: 0.079625, Total_Loss: 0.314853\n",
            "[EPOCH] 18: Classification loss: 0.209419, CORAL loss: 0.100151, Total_Loss: 0.227447\n",
            "[Test Source]: Epoch: 18, avg_loss: 0.1285, Accuracy: 2734/2817 (97.05%)\n",
            "[Test Target]: Epoch: 18, avg_loss: 1.9015, Accuracy: 385/795 (48.43%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 19 [ 1/ 6]\tLambda value: 0.1900, Classification loss: 0.185156, CORAL loss: 0.077949, Total_Loss: 0.199966\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 19 [ 2/ 6]\tLambda value: 0.1900, Classification loss: 0.186650, CORAL loss: 0.094234, Total_Loss: 0.204554\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 19 [ 3/ 6]\tLambda value: 0.1900, Classification loss: 0.248397, CORAL loss: 0.132214, Total_Loss: 0.273518\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 19 [ 4/ 6]\tLambda value: 0.1900, Classification loss: 0.227277, CORAL loss: 0.084385, Total_Loss: 0.243310\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 19 [ 5/ 6]\tLambda value: 0.1900, Classification loss: 0.161436, CORAL loss: 0.211606, Total_Loss: 0.201641\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 19 [ 6/ 6]\tLambda value: 0.1900, Classification loss: 0.127005, CORAL loss: 0.091691, Total_Loss: 0.144427\n",
            "[EPOCH] 19: Classification loss: 0.189320, CORAL loss: 0.115347, Total_Loss: 0.211236\n",
            "[Test Source]: Epoch: 19, avg_loss: 0.1093, Accuracy: 2755/2817 (97.80%)\n",
            "[Test Target]: Epoch: 19, avg_loss: 1.9427, Accuracy: 379/795 (47.67%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 20 [ 1/ 6]\tLambda value: 0.2000, Classification loss: 0.170276, CORAL loss: 0.086905, Total_Loss: 0.187657\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 20 [ 2/ 6]\tLambda value: 0.2000, Classification loss: 0.124763, CORAL loss: 0.076854, Total_Loss: 0.140134\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 20 [ 3/ 6]\tLambda value: 0.2000, Classification loss: 0.182690, CORAL loss: 0.071124, Total_Loss: 0.196915\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 20 [ 4/ 6]\tLambda value: 0.2000, Classification loss: 0.137827, CORAL loss: 0.087587, Total_Loss: 0.155344\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 20 [ 5/ 6]\tLambda value: 0.2000, Classification loss: 0.122717, CORAL loss: 0.053541, Total_Loss: 0.133425\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 20 [ 6/ 6]\tLambda value: 0.2000, Classification loss: 0.178797, CORAL loss: 0.100330, Total_Loss: 0.198863\n",
            "[EPOCH] 20: Classification loss: 0.152845, CORAL loss: 0.079390, Total_Loss: 0.168723\n",
            "[Test Source]: Epoch: 20, avg_loss: 0.0987, Accuracy: 2765/2817 (98.15%)\n",
            "[Test Target]: Epoch: 20, avg_loss: 1.9433, Accuracy: 357/795 (44.91%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 21 [ 1/ 6]\tLambda value: 0.2100, Classification loss: 0.183491, CORAL loss: 0.067532, Total_Loss: 0.197673\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 21 [ 2/ 6]\tLambda value: 0.2100, Classification loss: 0.118007, CORAL loss: 0.105307, Total_Loss: 0.140122\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 21 [ 3/ 6]\tLambda value: 0.2100, Classification loss: 0.199948, CORAL loss: 0.048291, Total_Loss: 0.210089\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 21 [ 4/ 6]\tLambda value: 0.2100, Classification loss: 0.112028, CORAL loss: 0.090193, Total_Loss: 0.130968\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 21 [ 5/ 6]\tLambda value: 0.2100, Classification loss: 0.088340, CORAL loss: 0.086712, Total_Loss: 0.106549\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 21 [ 6/ 6]\tLambda value: 0.2100, Classification loss: 0.153578, CORAL loss: 0.067942, Total_Loss: 0.167845\n",
            "[EPOCH] 21: Classification loss: 0.142565, CORAL loss: 0.077663, Total_Loss: 0.158874\n",
            "[Test Source]: Epoch: 21, avg_loss: 0.0848, Accuracy: 2771/2817 (98.37%)\n",
            "[Test Target]: Epoch: 21, avg_loss: 1.8801, Accuracy: 376/795 (47.30%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 22 [ 1/ 6]\tLambda value: 0.2200, Classification loss: 0.173445, CORAL loss: 0.087870, Total_Loss: 0.192777\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 22 [ 2/ 6]\tLambda value: 0.2200, Classification loss: 0.094630, CORAL loss: 0.098962, Total_Loss: 0.116401\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 22 [ 3/ 6]\tLambda value: 0.2200, Classification loss: 0.132911, CORAL loss: 0.086946, Total_Loss: 0.152039\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 22 [ 4/ 6]\tLambda value: 0.2200, Classification loss: 0.139952, CORAL loss: 0.239569, Total_Loss: 0.192657\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 22 [ 5/ 6]\tLambda value: 0.2200, Classification loss: 0.112124, CORAL loss: 0.106283, Total_Loss: 0.135506\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 22 [ 6/ 6]\tLambda value: 0.2200, Classification loss: 0.120341, CORAL loss: 0.113197, Total_Loss: 0.145244\n",
            "[EPOCH] 22: Classification loss: 0.128900, CORAL loss: 0.122138, Total_Loss: 0.155771\n",
            "[Test Source]: Epoch: 22, avg_loss: 0.0741, Accuracy: 2780/2817 (98.69%)\n",
            "[Test Target]: Epoch: 22, avg_loss: 1.9184, Accuracy: 379/795 (47.67%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 23 [ 1/ 6]\tLambda value: 0.2300, Classification loss: 0.119788, CORAL loss: 0.106895, Total_Loss: 0.144374\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 23 [ 2/ 6]\tLambda value: 0.2300, Classification loss: 0.172424, CORAL loss: 0.102257, Total_Loss: 0.195944\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 23 [ 3/ 6]\tLambda value: 0.2300, Classification loss: 0.059436, CORAL loss: 0.102782, Total_Loss: 0.083076\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 23 [ 4/ 6]\tLambda value: 0.2300, Classification loss: 0.164337, CORAL loss: 0.098619, Total_Loss: 0.187019\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 23 [ 5/ 6]\tLambda value: 0.2300, Classification loss: 0.094236, CORAL loss: 0.107715, Total_Loss: 0.119010\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 23 [ 6/ 6]\tLambda value: 0.2300, Classification loss: 0.164286, CORAL loss: 0.065888, Total_Loss: 0.179441\n",
            "[EPOCH] 23: Classification loss: 0.129085, CORAL loss: 0.097359, Total_Loss: 0.151477\n",
            "[Test Source]: Epoch: 23, avg_loss: 0.0682, Accuracy: 2785/2817 (98.86%)\n",
            "[Test Target]: Epoch: 23, avg_loss: 1.9560, Accuracy: 374/795 (47.04%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 24 [ 1/ 6]\tLambda value: 0.2400, Classification loss: 0.100183, CORAL loss: 0.083458, Total_Loss: 0.120213\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 24 [ 2/ 6]\tLambda value: 0.2400, Classification loss: 0.100969, CORAL loss: 0.097636, Total_Loss: 0.124402\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 24 [ 3/ 6]\tLambda value: 0.2400, Classification loss: 0.086017, CORAL loss: 0.048125, Total_Loss: 0.097567\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 24 [ 4/ 6]\tLambda value: 0.2400, Classification loss: 0.157140, CORAL loss: 0.102497, Total_Loss: 0.181740\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 24 [ 5/ 6]\tLambda value: 0.2400, Classification loss: 0.111663, CORAL loss: 0.102542, Total_Loss: 0.136274\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 24 [ 6/ 6]\tLambda value: 0.2400, Classification loss: 0.173823, CORAL loss: 0.052936, Total_Loss: 0.186528\n",
            "[EPOCH] 24: Classification loss: 0.121633, CORAL loss: 0.081199, Total_Loss: 0.141120\n",
            "[Test Source]: Epoch: 24, avg_loss: 0.0647, Accuracy: 2793/2817 (99.15%)\n",
            "[Test Target]: Epoch: 24, avg_loss: 1.8551, Accuracy: 392/795 (49.31%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 25 [ 1/ 6]\tLambda value: 0.2500, Classification loss: 0.068318, CORAL loss: 0.083696, Total_Loss: 0.089242\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 25 [ 2/ 6]\tLambda value: 0.2500, Classification loss: 0.097916, CORAL loss: 0.057865, Total_Loss: 0.112382\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 25 [ 3/ 6]\tLambda value: 0.2500, Classification loss: 0.096043, CORAL loss: 0.070591, Total_Loss: 0.113690\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 25 [ 4/ 6]\tLambda value: 0.2500, Classification loss: 0.136299, CORAL loss: 0.085308, Total_Loss: 0.157626\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 25 [ 5/ 6]\tLambda value: 0.2500, Classification loss: 0.114858, CORAL loss: 0.075178, Total_Loss: 0.133653\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 25 [ 6/ 6]\tLambda value: 0.2500, Classification loss: 0.084104, CORAL loss: 0.056874, Total_Loss: 0.098322\n",
            "[EPOCH] 25: Classification loss: 0.099590, CORAL loss: 0.071585, Total_Loss: 0.117486\n",
            "[Test Source]: Epoch: 25, avg_loss: 0.0575, Accuracy: 2794/2817 (99.18%)\n",
            "[Test Target]: Epoch: 25, avg_loss: 1.8122, Accuracy: 395/795 (49.69%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 26 [ 1/ 6]\tLambda value: 0.2600, Classification loss: 0.118767, CORAL loss: 0.094463, Total_Loss: 0.143327\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 26 [ 2/ 6]\tLambda value: 0.2600, Classification loss: 0.143777, CORAL loss: 0.096120, Total_Loss: 0.168768\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 26 [ 3/ 6]\tLambda value: 0.2600, Classification loss: 0.075030, CORAL loss: 0.060379, Total_Loss: 0.090728\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 26 [ 4/ 6]\tLambda value: 0.2600, Classification loss: 0.064509, CORAL loss: 0.072022, Total_Loss: 0.083234\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 26 [ 5/ 6]\tLambda value: 0.2600, Classification loss: 0.122524, CORAL loss: 0.069120, Total_Loss: 0.140495\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 26 [ 6/ 6]\tLambda value: 0.2600, Classification loss: 0.124322, CORAL loss: 0.071012, Total_Loss: 0.142786\n",
            "[EPOCH] 26: Classification loss: 0.108155, CORAL loss: 0.077186, Total_Loss: 0.128223\n",
            "[Test Source]: Epoch: 26, avg_loss: 0.0528, Accuracy: 2791/2817 (99.08%)\n",
            "[Test Target]: Epoch: 26, avg_loss: 1.8321, Accuracy: 386/795 (48.55%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 27 [ 1/ 6]\tLambda value: 0.2700, Classification loss: 0.107087, CORAL loss: 0.072822, Total_Loss: 0.126749\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 27 [ 2/ 6]\tLambda value: 0.2700, Classification loss: 0.098614, CORAL loss: 0.083570, Total_Loss: 0.121178\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 27 [ 3/ 6]\tLambda value: 0.2700, Classification loss: 0.134751, CORAL loss: 0.078199, Total_Loss: 0.155865\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 27 [ 4/ 6]\tLambda value: 0.2700, Classification loss: 0.100161, CORAL loss: 0.068228, Total_Loss: 0.118582\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 27 [ 5/ 6]\tLambda value: 0.2700, Classification loss: 0.105300, CORAL loss: 0.083691, Total_Loss: 0.127896\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 27 [ 6/ 6]\tLambda value: 0.2700, Classification loss: 0.080430, CORAL loss: 0.059923, Total_Loss: 0.096609\n",
            "[EPOCH] 27: Classification loss: 0.104391, CORAL loss: 0.074406, Total_Loss: 0.124480\n",
            "[Test Source]: Epoch: 27, avg_loss: 0.0460, Accuracy: 2798/2817 (99.33%)\n",
            "[Test Target]: Epoch: 27, avg_loss: 1.8079, Accuracy: 398/795 (50.06%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 28 [ 1/ 6]\tLambda value: 0.2800, Classification loss: 0.065350, CORAL loss: 0.090939, Total_Loss: 0.090813\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 28 [ 2/ 6]\tLambda value: 0.2800, Classification loss: 0.061566, CORAL loss: 0.061380, Total_Loss: 0.078752\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 28 [ 3/ 6]\tLambda value: 0.2800, Classification loss: 0.090579, CORAL loss: 0.076681, Total_Loss: 0.112050\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 28 [ 4/ 6]\tLambda value: 0.2800, Classification loss: 0.086269, CORAL loss: 0.082166, Total_Loss: 0.109276\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 28 [ 5/ 6]\tLambda value: 0.2800, Classification loss: 0.114165, CORAL loss: 0.089315, Total_Loss: 0.139173\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 28 [ 6/ 6]\tLambda value: 0.2800, Classification loss: 0.092913, CORAL loss: 0.037062, Total_Loss: 0.103290\n",
            "[EPOCH] 28: Classification loss: 0.085140, CORAL loss: 0.072924, Total_Loss: 0.105559\n",
            "[Test Source]: Epoch: 28, avg_loss: 0.0423, Accuracy: 2799/2817 (99.36%)\n",
            "[Test Target]: Epoch: 28, avg_loss: 1.8661, Accuracy: 397/795 (49.94%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 29 [ 1/ 6]\tLambda value: 0.2900, Classification loss: 0.112009, CORAL loss: 0.067079, Total_Loss: 0.131462\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 29 [ 2/ 6]\tLambda value: 0.2900, Classification loss: 0.081481, CORAL loss: 0.064038, Total_Loss: 0.100052\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 29 [ 3/ 6]\tLambda value: 0.2900, Classification loss: 0.071434, CORAL loss: 0.078635, Total_Loss: 0.094238\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 29 [ 4/ 6]\tLambda value: 0.2900, Classification loss: 0.062457, CORAL loss: 0.074277, Total_Loss: 0.083997\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 29 [ 5/ 6]\tLambda value: 0.2900, Classification loss: 0.091248, CORAL loss: 0.068053, Total_Loss: 0.110983\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 29 [ 6/ 6]\tLambda value: 0.2900, Classification loss: 0.101390, CORAL loss: 0.051348, Total_Loss: 0.116281\n",
            "[EPOCH] 29: Classification loss: 0.086670, CORAL loss: 0.067238, Total_Loss: 0.106169\n",
            "[Test Source]: Epoch: 29, avg_loss: 0.0372, Accuracy: 2800/2817 (99.40%)\n",
            "[Test Target]: Epoch: 29, avg_loss: 1.8974, Accuracy: 391/795 (49.18%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 30 [ 1/ 6]\tLambda value: 0.3000, Classification loss: 0.041938, CORAL loss: 0.110592, Total_Loss: 0.075116\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 30 [ 2/ 6]\tLambda value: 0.3000, Classification loss: 0.130823, CORAL loss: 0.066517, Total_Loss: 0.150778\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 30 [ 3/ 6]\tLambda value: 0.3000, Classification loss: 0.090302, CORAL loss: 0.062471, Total_Loss: 0.109044\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 30 [ 4/ 6]\tLambda value: 0.3000, Classification loss: 0.097939, CORAL loss: 0.062316, Total_Loss: 0.116634\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 30 [ 5/ 6]\tLambda value: 0.3000, Classification loss: 0.093232, CORAL loss: 0.091213, Total_Loss: 0.120596\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 30 [ 6/ 6]\tLambda value: 0.3000, Classification loss: 0.069014, CORAL loss: 0.074047, Total_Loss: 0.091228\n",
            "[EPOCH] 30: Classification loss: 0.087208, CORAL loss: 0.077859, Total_Loss: 0.110566\n",
            "[Test Source]: Epoch: 30, avg_loss: 0.0335, Accuracy: 2802/2817 (99.47%)\n",
            "[Test Target]: Epoch: 30, avg_loss: 1.9727, Accuracy: 389/795 (48.93%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 31 [ 1/ 6]\tLambda value: 0.3100, Classification loss: 0.082115, CORAL loss: 0.063488, Total_Loss: 0.101796\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 31 [ 2/ 6]\tLambda value: 0.3100, Classification loss: 0.054287, CORAL loss: 0.058801, Total_Loss: 0.072515\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 31 [ 3/ 6]\tLambda value: 0.3100, Classification loss: 0.089221, CORAL loss: 0.059989, Total_Loss: 0.107818\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 31 [ 4/ 6]\tLambda value: 0.3100, Classification loss: 0.077129, CORAL loss: 0.092931, Total_Loss: 0.105937\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 31 [ 5/ 6]\tLambda value: 0.3100, Classification loss: 0.050715, CORAL loss: 0.057416, Total_Loss: 0.068514\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 31 [ 6/ 6]\tLambda value: 0.3100, Classification loss: 0.074523, CORAL loss: 0.068876, Total_Loss: 0.095874\n",
            "[EPOCH] 31: Classification loss: 0.071332, CORAL loss: 0.066917, Total_Loss: 0.092076\n",
            "[Test Source]: Epoch: 31, avg_loss: 0.0315, Accuracy: 2805/2817 (99.57%)\n",
            "[Test Target]: Epoch: 31, avg_loss: 1.9467, Accuracy: 378/795 (47.55%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 32 [ 1/ 6]\tLambda value: 0.3200, Classification loss: 0.087621, CORAL loss: 0.049948, Total_Loss: 0.103605\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 32 [ 2/ 6]\tLambda value: 0.3200, Classification loss: 0.065721, CORAL loss: 0.055859, Total_Loss: 0.083596\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 32 [ 3/ 6]\tLambda value: 0.3200, Classification loss: 0.082071, CORAL loss: 0.080518, Total_Loss: 0.107837\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 32 [ 4/ 6]\tLambda value: 0.3200, Classification loss: 0.059427, CORAL loss: 0.065883, Total_Loss: 0.080510\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 32 [ 5/ 6]\tLambda value: 0.3200, Classification loss: 0.054763, CORAL loss: 0.064165, Total_Loss: 0.075296\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 32 [ 6/ 6]\tLambda value: 0.3200, Classification loss: 0.085408, CORAL loss: 0.055121, Total_Loss: 0.103047\n",
            "[EPOCH] 32: Classification loss: 0.072502, CORAL loss: 0.061916, Total_Loss: 0.092315\n",
            "[Test Source]: Epoch: 32, avg_loss: 0.0304, Accuracy: 2805/2817 (99.57%)\n",
            "[Test Target]: Epoch: 32, avg_loss: 1.8547, Accuracy: 392/795 (49.31%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 33 [ 1/ 6]\tLambda value: 0.3300, Classification loss: 0.070745, CORAL loss: 0.050484, Total_Loss: 0.087405\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 33 [ 2/ 6]\tLambda value: 0.3300, Classification loss: 0.067322, CORAL loss: 0.044070, Total_Loss: 0.081865\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 33 [ 3/ 6]\tLambda value: 0.3300, Classification loss: 0.087563, CORAL loss: 0.080794, Total_Loss: 0.114225\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 33 [ 4/ 6]\tLambda value: 0.3300, Classification loss: 0.050670, CORAL loss: 0.070208, Total_Loss: 0.073838\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 33 [ 5/ 6]\tLambda value: 0.3300, Classification loss: 0.056346, CORAL loss: 0.052366, Total_Loss: 0.073627\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 33 [ 6/ 6]\tLambda value: 0.3300, Classification loss: 0.066801, CORAL loss: 0.075464, Total_Loss: 0.091705\n",
            "[EPOCH] 33: Classification loss: 0.066574, CORAL loss: 0.062231, Total_Loss: 0.087111\n",
            "[Test Source]: Epoch: 33, avg_loss: 0.0300, Accuracy: 2807/2817 (99.65%)\n",
            "[Test Target]: Epoch: 33, avg_loss: 1.7824, Accuracy: 405/795 (50.94%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 34 [ 1/ 6]\tLambda value: 0.3400, Classification loss: 0.104697, CORAL loss: 0.054135, Total_Loss: 0.123103\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 34 [ 2/ 6]\tLambda value: 0.3400, Classification loss: 0.050750, CORAL loss: 0.038485, Total_Loss: 0.063835\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 34 [ 3/ 6]\tLambda value: 0.3400, Classification loss: 0.063231, CORAL loss: 0.043512, Total_Loss: 0.078025\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 34 [ 4/ 6]\tLambda value: 0.3400, Classification loss: 0.058862, CORAL loss: 0.051772, Total_Loss: 0.076464\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 34 [ 5/ 6]\tLambda value: 0.3400, Classification loss: 0.077885, CORAL loss: 0.053772, Total_Loss: 0.096168\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 34 [ 6/ 6]\tLambda value: 0.3400, Classification loss: 0.058442, CORAL loss: 0.050909, Total_Loss: 0.075751\n",
            "[EPOCH] 34: Classification loss: 0.068978, CORAL loss: 0.048764, Total_Loss: 0.085558\n",
            "[Test Source]: Epoch: 34, avg_loss: 0.0259, Accuracy: 2805/2817 (99.57%)\n",
            "[Test Target]: Epoch: 34, avg_loss: 1.8072, Accuracy: 407/795 (51.19%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 35 [ 1/ 6]\tLambda value: 0.3500, Classification loss: 0.058352, CORAL loss: 0.057549, Total_Loss: 0.078494\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 35 [ 2/ 6]\tLambda value: 0.3500, Classification loss: 0.081056, CORAL loss: 0.057903, Total_Loss: 0.101322\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 35 [ 3/ 6]\tLambda value: 0.3500, Classification loss: 0.046331, CORAL loss: 0.052346, Total_Loss: 0.064652\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 35 [ 4/ 6]\tLambda value: 0.3500, Classification loss: 0.050558, CORAL loss: 0.042578, Total_Loss: 0.065461\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 35 [ 5/ 6]\tLambda value: 0.3500, Classification loss: 0.054083, CORAL loss: 0.062132, Total_Loss: 0.075829\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 35 [ 6/ 6]\tLambda value: 0.3500, Classification loss: 0.066664, CORAL loss: 0.044971, Total_Loss: 0.082404\n",
            "[EPOCH] 35: Classification loss: 0.059507, CORAL loss: 0.052913, Total_Loss: 0.078027\n",
            "[Test Source]: Epoch: 35, avg_loss: 0.0219, Accuracy: 2810/2817 (99.75%)\n",
            "[Test Target]: Epoch: 35, avg_loss: 1.8785, Accuracy: 407/795 (51.19%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 36 [ 1/ 6]\tLambda value: 0.3600, Classification loss: 0.025918, CORAL loss: 0.046864, Total_Loss: 0.042789\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 36 [ 2/ 6]\tLambda value: 0.3600, Classification loss: 0.049773, CORAL loss: 0.043328, Total_Loss: 0.065371\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 36 [ 3/ 6]\tLambda value: 0.3600, Classification loss: 0.052860, CORAL loss: 0.072107, Total_Loss: 0.078818\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 36 [ 4/ 6]\tLambda value: 0.3600, Classification loss: 0.041105, CORAL loss: 0.044136, Total_Loss: 0.056994\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 36 [ 5/ 6]\tLambda value: 0.3600, Classification loss: 0.066674, CORAL loss: 0.047307, Total_Loss: 0.083705\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 36 [ 6/ 6]\tLambda value: 0.3600, Classification loss: 0.048269, CORAL loss: 0.050680, Total_Loss: 0.066514\n",
            "[EPOCH] 36: Classification loss: 0.047433, CORAL loss: 0.050737, Total_Loss: 0.065699\n",
            "[Test Source]: Epoch: 36, avg_loss: 0.0198, Accuracy: 2811/2817 (99.79%)\n",
            "[Test Target]: Epoch: 36, avg_loss: 1.9138, Accuracy: 404/795 (50.82%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 37 [ 1/ 6]\tLambda value: 0.3700, Classification loss: 0.035676, CORAL loss: 0.072234, Total_Loss: 0.062403\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 37 [ 2/ 6]\tLambda value: 0.3700, Classification loss: 0.055962, CORAL loss: 0.045931, Total_Loss: 0.072956\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 37 [ 3/ 6]\tLambda value: 0.3700, Classification loss: 0.032589, CORAL loss: 0.060891, Total_Loss: 0.055119\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 37 [ 4/ 6]\tLambda value: 0.3700, Classification loss: 0.037294, CORAL loss: 0.058726, Total_Loss: 0.059022\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 37 [ 5/ 6]\tLambda value: 0.3700, Classification loss: 0.042599, CORAL loss: 0.063972, Total_Loss: 0.066268\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 37 [ 6/ 6]\tLambda value: 0.3700, Classification loss: 0.036763, CORAL loss: 0.064088, Total_Loss: 0.060476\n",
            "[EPOCH] 37: Classification loss: 0.040147, CORAL loss: 0.060974, Total_Loss: 0.062707\n",
            "[Test Source]: Epoch: 37, avg_loss: 0.0180, Accuracy: 2811/2817 (99.79%)\n",
            "[Test Target]: Epoch: 37, avg_loss: 1.8716, Accuracy: 401/795 (50.44%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 38 [ 1/ 6]\tLambda value: 0.3800, Classification loss: 0.041616, CORAL loss: 0.081996, Total_Loss: 0.072774\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 38 [ 2/ 6]\tLambda value: 0.3800, Classification loss: 0.037278, CORAL loss: 0.045434, Total_Loss: 0.054543\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 38 [ 3/ 6]\tLambda value: 0.3800, Classification loss: 0.038436, CORAL loss: 0.056926, Total_Loss: 0.060068\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 38 [ 4/ 6]\tLambda value: 0.3800, Classification loss: 0.043908, CORAL loss: 0.045856, Total_Loss: 0.061333\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 38 [ 5/ 6]\tLambda value: 0.3800, Classification loss: 0.062806, CORAL loss: 0.062496, Total_Loss: 0.086555\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 38 [ 6/ 6]\tLambda value: 0.3800, Classification loss: 0.027970, CORAL loss: 0.081879, Total_Loss: 0.059084\n",
            "[EPOCH] 38: Classification loss: 0.042002, CORAL loss: 0.062431, Total_Loss: 0.065726\n",
            "[Test Source]: Epoch: 38, avg_loss: 0.0172, Accuracy: 2812/2817 (99.82%)\n",
            "[Test Target]: Epoch: 38, avg_loss: 1.8106, Accuracy: 406/795 (51.07%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 39 [ 1/ 6]\tLambda value: 0.3900, Classification loss: 0.035110, CORAL loss: 0.053346, Total_Loss: 0.055914\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 39 [ 2/ 6]\tLambda value: 0.3900, Classification loss: 0.038337, CORAL loss: 0.059541, Total_Loss: 0.061558\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 39 [ 3/ 6]\tLambda value: 0.3900, Classification loss: 0.052401, CORAL loss: 0.035108, Total_Loss: 0.066093\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 39 [ 4/ 6]\tLambda value: 0.3900, Classification loss: 0.033565, CORAL loss: 0.041803, Total_Loss: 0.049868\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 39 [ 5/ 6]\tLambda value: 0.3900, Classification loss: 0.057340, CORAL loss: 0.054682, Total_Loss: 0.078666\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 39 [ 6/ 6]\tLambda value: 0.3900, Classification loss: 0.060146, CORAL loss: 0.050044, Total_Loss: 0.079663\n",
            "[EPOCH] 39: Classification loss: 0.046150, CORAL loss: 0.049087, Total_Loss: 0.065294\n",
            "[Test Source]: Epoch: 39, avg_loss: 0.0152, Accuracy: 2814/2817 (99.89%)\n",
            "[Test Target]: Epoch: 39, avg_loss: 1.8224, Accuracy: 411/795 (51.70%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 40 [ 1/ 6]\tLambda value: 0.4000, Classification loss: 0.022808, CORAL loss: 0.045431, Total_Loss: 0.040980\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 40 [ 2/ 6]\tLambda value: 0.4000, Classification loss: 0.050653, CORAL loss: 0.047362, Total_Loss: 0.069598\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 40 [ 3/ 6]\tLambda value: 0.4000, Classification loss: 0.037943, CORAL loss: 0.067283, Total_Loss: 0.064856\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 40 [ 4/ 6]\tLambda value: 0.4000, Classification loss: 0.033344, CORAL loss: 0.046178, Total_Loss: 0.051815\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 40 [ 5/ 6]\tLambda value: 0.4000, Classification loss: 0.053727, CORAL loss: 0.073774, Total_Loss: 0.083236\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 40 [ 6/ 6]\tLambda value: 0.4000, Classification loss: 0.052348, CORAL loss: 0.059069, Total_Loss: 0.075976\n",
            "[EPOCH] 40: Classification loss: 0.041804, CORAL loss: 0.056516, Total_Loss: 0.064410\n",
            "[Test Source]: Epoch: 40, avg_loss: 0.0142, Accuracy: 2814/2817 (99.89%)\n",
            "[Test Target]: Epoch: 40, avg_loss: 1.8267, Accuracy: 408/795 (51.32%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 41 [ 1/ 6]\tLambda value: 0.4100, Classification loss: 0.067552, CORAL loss: 0.040681, Total_Loss: 0.084231\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 41 [ 2/ 6]\tLambda value: 0.4100, Classification loss: 0.039131, CORAL loss: 0.063536, Total_Loss: 0.065181\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 41 [ 3/ 6]\tLambda value: 0.4100, Classification loss: 0.052917, CORAL loss: 0.044688, Total_Loss: 0.071239\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 41 [ 4/ 6]\tLambda value: 0.4100, Classification loss: 0.039140, CORAL loss: 0.045779, Total_Loss: 0.057909\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 41 [ 5/ 6]\tLambda value: 0.4100, Classification loss: 0.037381, CORAL loss: 0.041856, Total_Loss: 0.054542\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 41 [ 6/ 6]\tLambda value: 0.4100, Classification loss: 0.051456, CORAL loss: 0.052541, Total_Loss: 0.072998\n",
            "[EPOCH] 41: Classification loss: 0.047930, CORAL loss: 0.048180, Total_Loss: 0.067683\n",
            "[Test Source]: Epoch: 41, avg_loss: 0.0150, Accuracy: 2814/2817 (99.89%)\n",
            "[Test Target]: Epoch: 41, avg_loss: 1.8823, Accuracy: 409/795 (51.45%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 42 [ 1/ 6]\tLambda value: 0.4200, Classification loss: 0.017428, CORAL loss: 0.047469, Total_Loss: 0.037365\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 42 [ 2/ 6]\tLambda value: 0.4200, Classification loss: 0.038546, CORAL loss: 0.044998, Total_Loss: 0.057445\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 42 [ 3/ 6]\tLambda value: 0.4200, Classification loss: 0.043834, CORAL loss: 0.079609, Total_Loss: 0.077270\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 42 [ 4/ 6]\tLambda value: 0.4200, Classification loss: 0.056503, CORAL loss: 0.058884, Total_Loss: 0.081234\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 42 [ 5/ 6]\tLambda value: 0.4200, Classification loss: 0.062558, CORAL loss: 0.054339, Total_Loss: 0.085381\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 42 [ 6/ 6]\tLambda value: 0.4200, Classification loss: 0.054777, CORAL loss: 0.046523, Total_Loss: 0.074317\n",
            "[EPOCH] 42: Classification loss: 0.045608, CORAL loss: 0.055303, Total_Loss: 0.068835\n",
            "[Test Source]: Epoch: 42, avg_loss: 0.0134, Accuracy: 2814/2817 (99.89%)\n",
            "[Test Target]: Epoch: 42, avg_loss: 1.9020, Accuracy: 397/795 (49.94%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 43 [ 1/ 6]\tLambda value: 0.4300, Classification loss: 0.047933, CORAL loss: 0.051197, Total_Loss: 0.069948\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 43 [ 2/ 6]\tLambda value: 0.4300, Classification loss: 0.049165, CORAL loss: 0.056124, Total_Loss: 0.073298\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 43 [ 3/ 6]\tLambda value: 0.4300, Classification loss: 0.036540, CORAL loss: 0.067719, Total_Loss: 0.065659\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 43 [ 4/ 6]\tLambda value: 0.4300, Classification loss: 0.055419, CORAL loss: 0.052284, Total_Loss: 0.077901\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 43 [ 5/ 6]\tLambda value: 0.4300, Classification loss: 0.032831, CORAL loss: 0.040522, Total_Loss: 0.050255\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 43 [ 6/ 6]\tLambda value: 0.4300, Classification loss: 0.033481, CORAL loss: 0.039406, Total_Loss: 0.050426\n",
            "[EPOCH] 43: Classification loss: 0.042562, CORAL loss: 0.051209, Total_Loss: 0.064581\n",
            "[Test Source]: Epoch: 43, avg_loss: 0.0137, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 43, avg_loss: 1.8566, Accuracy: 387/795 (48.68%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 44 [ 1/ 6]\tLambda value: 0.4400, Classification loss: 0.054119, CORAL loss: 0.033545, Total_Loss: 0.068879\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 44 [ 2/ 6]\tLambda value: 0.4400, Classification loss: 0.036072, CORAL loss: 0.062985, Total_Loss: 0.063786\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 44 [ 3/ 6]\tLambda value: 0.4400, Classification loss: 0.039840, CORAL loss: 0.042938, Total_Loss: 0.058733\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 44 [ 4/ 6]\tLambda value: 0.4400, Classification loss: 0.040298, CORAL loss: 0.039967, Total_Loss: 0.057883\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 44 [ 5/ 6]\tLambda value: 0.4400, Classification loss: 0.024963, CORAL loss: 0.038153, Total_Loss: 0.041751\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 44 [ 6/ 6]\tLambda value: 0.4400, Classification loss: 0.081674, CORAL loss: 0.043970, Total_Loss: 0.101021\n",
            "[EPOCH] 44: Classification loss: 0.046161, CORAL loss: 0.043593, Total_Loss: 0.065342\n",
            "[Test Source]: Epoch: 44, avg_loss: 0.0143, Accuracy: 2813/2817 (99.86%)\n",
            "[Test Target]: Epoch: 44, avg_loss: 1.8230, Accuracy: 390/795 (49.06%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 45 [ 1/ 6]\tLambda value: 0.4500, Classification loss: 0.032477, CORAL loss: 0.041432, Total_Loss: 0.051121\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 45 [ 2/ 6]\tLambda value: 0.4500, Classification loss: 0.038275, CORAL loss: 0.056645, Total_Loss: 0.063765\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 45 [ 3/ 6]\tLambda value: 0.4500, Classification loss: 0.039718, CORAL loss: 0.047035, Total_Loss: 0.060884\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 45 [ 4/ 6]\tLambda value: 0.4500, Classification loss: 0.045075, CORAL loss: 0.034086, Total_Loss: 0.060413\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 45 [ 5/ 6]\tLambda value: 0.4500, Classification loss: 0.054787, CORAL loss: 0.038839, Total_Loss: 0.072264\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 45 [ 6/ 6]\tLambda value: 0.4500, Classification loss: 0.041388, CORAL loss: 0.042365, Total_Loss: 0.060452\n",
            "[EPOCH] 45: Classification loss: 0.041953, CORAL loss: 0.043400, Total_Loss: 0.061483\n",
            "[Test Source]: Epoch: 45, avg_loss: 0.0130, Accuracy: 2813/2817 (99.86%)\n",
            "[Test Target]: Epoch: 45, avg_loss: 1.7790, Accuracy: 410/795 (51.57%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 46 [ 1/ 6]\tLambda value: 0.4600, Classification loss: 0.030645, CORAL loss: 0.031451, Total_Loss: 0.045112\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 46 [ 2/ 6]\tLambda value: 0.4600, Classification loss: 0.038137, CORAL loss: 0.033378, Total_Loss: 0.053491\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 46 [ 3/ 6]\tLambda value: 0.4600, Classification loss: 0.038941, CORAL loss: 0.035374, Total_Loss: 0.055213\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 46 [ 4/ 6]\tLambda value: 0.4600, Classification loss: 0.033327, CORAL loss: 0.046029, Total_Loss: 0.054501\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 46 [ 5/ 6]\tLambda value: 0.4600, Classification loss: 0.024206, CORAL loss: 0.054995, Total_Loss: 0.049503\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 46 [ 6/ 6]\tLambda value: 0.4600, Classification loss: 0.049028, CORAL loss: 0.052543, Total_Loss: 0.073197\n",
            "[EPOCH] 46: Classification loss: 0.035714, CORAL loss: 0.042295, Total_Loss: 0.055170\n",
            "[Test Source]: Epoch: 46, avg_loss: 0.0122, Accuracy: 2813/2817 (99.86%)\n",
            "[Test Target]: Epoch: 46, avg_loss: 1.7508, Accuracy: 420/795 (52.83%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 47 [ 1/ 6]\tLambda value: 0.4700, Classification loss: 0.043673, CORAL loss: 0.044380, Total_Loss: 0.064531\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 47 [ 2/ 6]\tLambda value: 0.4700, Classification loss: 0.020337, CORAL loss: 0.055137, Total_Loss: 0.046251\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 47 [ 3/ 6]\tLambda value: 0.4700, Classification loss: 0.040289, CORAL loss: 0.037529, Total_Loss: 0.057928\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 47 [ 4/ 6]\tLambda value: 0.4700, Classification loss: 0.042893, CORAL loss: 0.032065, Total_Loss: 0.057964\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 47 [ 5/ 6]\tLambda value: 0.4700, Classification loss: 0.027695, CORAL loss: 0.034824, Total_Loss: 0.044062\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 47 [ 6/ 6]\tLambda value: 0.4700, Classification loss: 0.041758, CORAL loss: 0.046491, Total_Loss: 0.063609\n",
            "[EPOCH] 47: Classification loss: 0.036107, CORAL loss: 0.041738, Total_Loss: 0.055724\n",
            "[Test Source]: Epoch: 47, avg_loss: 0.0115, Accuracy: 2813/2817 (99.86%)\n",
            "[Test Target]: Epoch: 47, avg_loss: 1.8138, Accuracy: 416/795 (52.33%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 48 [ 1/ 6]\tLambda value: 0.4800, Classification loss: 0.038888, CORAL loss: 0.043130, Total_Loss: 0.059591\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 48 [ 2/ 6]\tLambda value: 0.4800, Classification loss: 0.028241, CORAL loss: 0.043363, Total_Loss: 0.049056\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 48 [ 3/ 6]\tLambda value: 0.4800, Classification loss: 0.051736, CORAL loss: 0.042693, Total_Loss: 0.072229\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 48 [ 4/ 6]\tLambda value: 0.4800, Classification loss: 0.025979, CORAL loss: 0.032403, Total_Loss: 0.041532\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 48 [ 5/ 6]\tLambda value: 0.4800, Classification loss: 0.040661, CORAL loss: 0.032554, Total_Loss: 0.056287\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 48 [ 6/ 6]\tLambda value: 0.4800, Classification loss: 0.025453, CORAL loss: 0.047118, Total_Loss: 0.048069\n",
            "[EPOCH] 48: Classification loss: 0.035160, CORAL loss: 0.040210, Total_Loss: 0.054461\n",
            "[Test Source]: Epoch: 48, avg_loss: 0.0106, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 48, avg_loss: 1.8163, Accuracy: 409/795 (51.45%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 49 [ 1/ 6]\tLambda value: 0.4900, Classification loss: 0.024432, CORAL loss: 0.052265, Total_Loss: 0.050042\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 49 [ 2/ 6]\tLambda value: 0.4900, Classification loss: 0.059615, CORAL loss: 0.035929, Total_Loss: 0.077220\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 49 [ 3/ 6]\tLambda value: 0.4900, Classification loss: 0.046870, CORAL loss: 0.042679, Total_Loss: 0.067782\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 49 [ 4/ 6]\tLambda value: 0.4900, Classification loss: 0.035495, CORAL loss: 0.039225, Total_Loss: 0.054716\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 49 [ 5/ 6]\tLambda value: 0.4900, Classification loss: 0.036172, CORAL loss: 0.059656, Total_Loss: 0.065403\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 49 [ 6/ 6]\tLambda value: 0.4900, Classification loss: 0.054064, CORAL loss: 0.040110, Total_Loss: 0.073718\n",
            "[EPOCH] 49: Classification loss: 0.042775, CORAL loss: 0.044977, Total_Loss: 0.064814\n",
            "[Test Source]: Epoch: 49, avg_loss: 0.0108, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 49, avg_loss: 1.8016, Accuracy: 412/795 (51.82%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 50 [ 1/ 6]\tLambda value: 0.5000, Classification loss: 0.031201, CORAL loss: 0.043976, Total_Loss: 0.053189\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 50 [ 2/ 6]\tLambda value: 0.5000, Classification loss: 0.025185, CORAL loss: 0.054104, Total_Loss: 0.052237\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 50 [ 3/ 6]\tLambda value: 0.5000, Classification loss: 0.027674, CORAL loss: 0.032628, Total_Loss: 0.043988\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 50 [ 4/ 6]\tLambda value: 0.5000, Classification loss: 0.030142, CORAL loss: 0.049145, Total_Loss: 0.054715\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 50 [ 5/ 6]\tLambda value: 0.5000, Classification loss: 0.053235, CORAL loss: 0.026997, Total_Loss: 0.066733\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 50 [ 6/ 6]\tLambda value: 0.5000, Classification loss: 0.030997, CORAL loss: 0.043750, Total_Loss: 0.052872\n",
            "[EPOCH] 50: Classification loss: 0.033072, CORAL loss: 0.041766, Total_Loss: 0.053956\n",
            "[Test Source]: Epoch: 50, avg_loss: 0.0121, Accuracy: 2814/2817 (99.89%)\n",
            "[Test Target]: Epoch: 50, avg_loss: 1.7891, Accuracy: 419/795 (52.70%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 51 [ 1/ 6]\tLambda value: 0.5100, Classification loss: 0.050471, CORAL loss: 0.036078, Total_Loss: 0.068871\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 51 [ 2/ 6]\tLambda value: 0.5100, Classification loss: 0.057720, CORAL loss: 0.033183, Total_Loss: 0.074643\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 51 [ 3/ 6]\tLambda value: 0.5100, Classification loss: 0.060193, CORAL loss: 0.032010, Total_Loss: 0.076518\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 51 [ 4/ 6]\tLambda value: 0.5100, Classification loss: 0.028801, CORAL loss: 0.046874, Total_Loss: 0.052707\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 51 [ 5/ 6]\tLambda value: 0.5100, Classification loss: 0.033297, CORAL loss: 0.028208, Total_Loss: 0.047683\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 51 [ 6/ 6]\tLambda value: 0.5100, Classification loss: 0.053318, CORAL loss: 0.030804, Total_Loss: 0.069028\n",
            "[EPOCH] 51: Classification loss: 0.047300, CORAL loss: 0.034526, Total_Loss: 0.064908\n",
            "[Test Source]: Epoch: 51, avg_loss: 0.0100, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 51, avg_loss: 1.8068, Accuracy: 420/795 (52.83%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 52 [ 1/ 6]\tLambda value: 0.5200, Classification loss: 0.040197, CORAL loss: 0.025727, Total_Loss: 0.053575\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 52 [ 2/ 6]\tLambda value: 0.5200, Classification loss: 0.029674, CORAL loss: 0.040509, Total_Loss: 0.050739\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 52 [ 3/ 6]\tLambda value: 0.5200, Classification loss: 0.053071, CORAL loss: 0.037481, Total_Loss: 0.072562\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 52 [ 4/ 6]\tLambda value: 0.5200, Classification loss: 0.045783, CORAL loss: 0.039297, Total_Loss: 0.066217\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 52 [ 5/ 6]\tLambda value: 0.5200, Classification loss: 0.031790, CORAL loss: 0.032325, Total_Loss: 0.048599\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 52 [ 6/ 6]\tLambda value: 0.5200, Classification loss: 0.039624, CORAL loss: 0.052480, Total_Loss: 0.066914\n",
            "[EPOCH] 52: Classification loss: 0.040023, CORAL loss: 0.037970, Total_Loss: 0.059768\n",
            "[Test Source]: Epoch: 52, avg_loss: 0.0093, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 52, avg_loss: 1.8246, Accuracy: 426/795 (53.58%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 53 [ 1/ 6]\tLambda value: 0.5300, Classification loss: 0.046158, CORAL loss: 0.032259, Total_Loss: 0.063255\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 53 [ 2/ 6]\tLambda value: 0.5300, Classification loss: 0.043061, CORAL loss: 0.039357, Total_Loss: 0.063920\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 53 [ 3/ 6]\tLambda value: 0.5300, Classification loss: 0.025787, CORAL loss: 0.053427, Total_Loss: 0.054104\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 53 [ 4/ 6]\tLambda value: 0.5300, Classification loss: 0.029097, CORAL loss: 0.030372, Total_Loss: 0.045194\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 53 [ 5/ 6]\tLambda value: 0.5300, Classification loss: 0.025176, CORAL loss: 0.024934, Total_Loss: 0.038391\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 53 [ 6/ 6]\tLambda value: 0.5300, Classification loss: 0.046795, CORAL loss: 0.037378, Total_Loss: 0.066606\n",
            "[EPOCH] 53: Classification loss: 0.036012, CORAL loss: 0.036288, Total_Loss: 0.055245\n",
            "[Test Source]: Epoch: 53, avg_loss: 0.0089, Accuracy: 2814/2817 (99.89%)\n",
            "[Test Target]: Epoch: 53, avg_loss: 1.8560, Accuracy: 420/795 (52.83%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 54 [ 1/ 6]\tLambda value: 0.5400, Classification loss: 0.037630, CORAL loss: 0.037867, Total_Loss: 0.058078\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 54 [ 2/ 6]\tLambda value: 0.5400, Classification loss: 0.024449, CORAL loss: 0.032666, Total_Loss: 0.042089\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 54 [ 3/ 6]\tLambda value: 0.5400, Classification loss: 0.027248, CORAL loss: 0.033748, Total_Loss: 0.045471\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 54 [ 4/ 6]\tLambda value: 0.5400, Classification loss: 0.020191, CORAL loss: 0.038497, Total_Loss: 0.040980\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 54 [ 5/ 6]\tLambda value: 0.5400, Classification loss: 0.031730, CORAL loss: 0.037007, Total_Loss: 0.051714\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 54 [ 6/ 6]\tLambda value: 0.5400, Classification loss: 0.035317, CORAL loss: 0.026388, Total_Loss: 0.049566\n",
            "[EPOCH] 54: Classification loss: 0.029427, CORAL loss: 0.034362, Total_Loss: 0.047983\n",
            "[Test Source]: Epoch: 54, avg_loss: 0.0088, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 54, avg_loss: 1.8453, Accuracy: 421/795 (52.96%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 55 [ 1/ 6]\tLambda value: 0.5500, Classification loss: 0.024560, CORAL loss: 0.037290, Total_Loss: 0.045069\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 55 [ 2/ 6]\tLambda value: 0.5500, Classification loss: 0.021553, CORAL loss: 0.040464, Total_Loss: 0.043808\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 55 [ 3/ 6]\tLambda value: 0.5500, Classification loss: 0.050584, CORAL loss: 0.025364, Total_Loss: 0.064534\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 55 [ 4/ 6]\tLambda value: 0.5500, Classification loss: 0.021853, CORAL loss: 0.044274, Total_Loss: 0.046204\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 55 [ 5/ 6]\tLambda value: 0.5500, Classification loss: 0.027642, CORAL loss: 0.032802, Total_Loss: 0.045683\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 55 [ 6/ 6]\tLambda value: 0.5500, Classification loss: 0.033121, CORAL loss: 0.038598, Total_Loss: 0.054350\n",
            "[EPOCH] 55: Classification loss: 0.029885, CORAL loss: 0.036465, Total_Loss: 0.049941\n",
            "[Test Source]: Epoch: 55, avg_loss: 0.0085, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 55, avg_loss: 1.8465, Accuracy: 423/795 (53.21%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 56 [ 1/ 6]\tLambda value: 0.5600, Classification loss: 0.031112, CORAL loss: 0.037097, Total_Loss: 0.051886\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 56 [ 2/ 6]\tLambda value: 0.5600, Classification loss: 0.025791, CORAL loss: 0.034406, Total_Loss: 0.045058\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 56 [ 3/ 6]\tLambda value: 0.5600, Classification loss: 0.025963, CORAL loss: 0.066189, Total_Loss: 0.063029\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 56 [ 4/ 6]\tLambda value: 0.5600, Classification loss: 0.030438, CORAL loss: 0.047310, Total_Loss: 0.056932\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 56 [ 5/ 6]\tLambda value: 0.5600, Classification loss: 0.039854, CORAL loss: 0.056572, Total_Loss: 0.071534\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 56 [ 6/ 6]\tLambda value: 0.5600, Classification loss: 0.023198, CORAL loss: 0.032769, Total_Loss: 0.041548\n",
            "[EPOCH] 56: Classification loss: 0.029392, CORAL loss: 0.045724, Total_Loss: 0.054998\n",
            "[Test Source]: Epoch: 56, avg_loss: 0.0084, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 56, avg_loss: 1.8725, Accuracy: 415/795 (52.20%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 57 [ 1/ 6]\tLambda value: 0.5700, Classification loss: 0.036725, CORAL loss: 0.052536, Total_Loss: 0.066670\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 57 [ 2/ 6]\tLambda value: 0.5700, Classification loss: 0.027948, CORAL loss: 0.040188, Total_Loss: 0.050855\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 57 [ 3/ 6]\tLambda value: 0.5700, Classification loss: 0.039958, CORAL loss: 0.054392, Total_Loss: 0.070961\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 57 [ 4/ 6]\tLambda value: 0.5700, Classification loss: 0.033233, CORAL loss: 0.026890, Total_Loss: 0.048560\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 57 [ 5/ 6]\tLambda value: 0.5700, Classification loss: 0.023118, CORAL loss: 0.030724, Total_Loss: 0.040631\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 57 [ 6/ 6]\tLambda value: 0.5700, Classification loss: 0.038221, CORAL loss: 0.024459, Total_Loss: 0.052163\n",
            "[EPOCH] 57: Classification loss: 0.033200, CORAL loss: 0.038198, Total_Loss: 0.054973\n",
            "[Test Source]: Epoch: 57, avg_loss: 0.0091, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 57, avg_loss: 1.8769, Accuracy: 408/795 (51.32%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 58 [ 1/ 6]\tLambda value: 0.5800, Classification loss: 0.024137, CORAL loss: 0.028185, Total_Loss: 0.040484\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 58 [ 2/ 6]\tLambda value: 0.5800, Classification loss: 0.043863, CORAL loss: 0.031571, Total_Loss: 0.062174\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 58 [ 3/ 6]\tLambda value: 0.5800, Classification loss: 0.026412, CORAL loss: 0.042800, Total_Loss: 0.051236\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 58 [ 4/ 6]\tLambda value: 0.5800, Classification loss: 0.032842, CORAL loss: 0.031076, Total_Loss: 0.050866\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 58 [ 5/ 6]\tLambda value: 0.5800, Classification loss: 0.027558, CORAL loss: 0.030120, Total_Loss: 0.045027\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 58 [ 6/ 6]\tLambda value: 0.5800, Classification loss: 0.040218, CORAL loss: 0.033906, Total_Loss: 0.059883\n",
            "[EPOCH] 58: Classification loss: 0.032505, CORAL loss: 0.032943, Total_Loss: 0.051612\n",
            "[Test Source]: Epoch: 58, avg_loss: 0.0095, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 58, avg_loss: 1.8207, Accuracy: 414/795 (52.08%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 59 [ 1/ 6]\tLambda value: 0.5900, Classification loss: 0.032055, CORAL loss: 0.029706, Total_Loss: 0.049582\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 59 [ 2/ 6]\tLambda value: 0.5900, Classification loss: 0.028584, CORAL loss: 0.038535, Total_Loss: 0.051319\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 59 [ 3/ 6]\tLambda value: 0.5900, Classification loss: 0.026436, CORAL loss: 0.027207, Total_Loss: 0.042488\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 59 [ 4/ 6]\tLambda value: 0.5900, Classification loss: 0.034207, CORAL loss: 0.039415, Total_Loss: 0.057462\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 59 [ 5/ 6]\tLambda value: 0.5900, Classification loss: 0.034672, CORAL loss: 0.029763, Total_Loss: 0.052233\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 59 [ 6/ 6]\tLambda value: 0.5900, Classification loss: 0.030230, CORAL loss: 0.031560, Total_Loss: 0.048851\n",
            "[EPOCH] 59: Classification loss: 0.031031, CORAL loss: 0.032698, Total_Loss: 0.050322\n",
            "[Test Source]: Epoch: 59, avg_loss: 0.0091, Accuracy: 2814/2817 (99.89%)\n",
            "[Test Target]: Epoch: 59, avg_loss: 1.8024, Accuracy: 422/795 (53.08%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 60 [ 1/ 6]\tLambda value: 0.6000, Classification loss: 0.028807, CORAL loss: 0.027157, Total_Loss: 0.045101\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 60 [ 2/ 6]\tLambda value: 0.6000, Classification loss: 0.045737, CORAL loss: 0.041581, Total_Loss: 0.070686\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 60 [ 3/ 6]\tLambda value: 0.6000, Classification loss: 0.041453, CORAL loss: 0.029399, Total_Loss: 0.059093\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 60 [ 4/ 6]\tLambda value: 0.6000, Classification loss: 0.021412, CORAL loss: 0.026187, Total_Loss: 0.037124\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 60 [ 5/ 6]\tLambda value: 0.6000, Classification loss: 0.030963, CORAL loss: 0.034903, Total_Loss: 0.051905\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 60 [ 6/ 6]\tLambda value: 0.6000, Classification loss: 0.040805, CORAL loss: 0.037891, Total_Loss: 0.063540\n",
            "[EPOCH] 60: Classification loss: 0.034863, CORAL loss: 0.032853, Total_Loss: 0.054575\n",
            "[Test Source]: Epoch: 60, avg_loss: 0.0082, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 60, avg_loss: 1.8626, Accuracy: 406/795 (51.07%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 61 [ 1/ 6]\tLambda value: 0.6100, Classification loss: 0.023463, CORAL loss: 0.027235, Total_Loss: 0.040077\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 61 [ 2/ 6]\tLambda value: 0.6100, Classification loss: 0.033394, CORAL loss: 0.053607, Total_Loss: 0.066094\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 61 [ 3/ 6]\tLambda value: 0.6100, Classification loss: 0.020864, CORAL loss: 0.030808, Total_Loss: 0.039657\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 61 [ 4/ 6]\tLambda value: 0.6100, Classification loss: 0.033967, CORAL loss: 0.037671, Total_Loss: 0.056946\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 61 [ 5/ 6]\tLambda value: 0.6100, Classification loss: 0.023746, CORAL loss: 0.040751, Total_Loss: 0.048604\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 61 [ 6/ 6]\tLambda value: 0.6100, Classification loss: 0.027065, CORAL loss: 0.035052, Total_Loss: 0.048446\n",
            "[EPOCH] 61: Classification loss: 0.027083, CORAL loss: 0.037520, Total_Loss: 0.049971\n",
            "[Test Source]: Epoch: 61, avg_loss: 0.0078, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 61, avg_loss: 1.8812, Accuracy: 396/795 (49.81%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 62 [ 1/ 6]\tLambda value: 0.6200, Classification loss: 0.033160, CORAL loss: 0.045515, Total_Loss: 0.061379\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 62 [ 2/ 6]\tLambda value: 0.6200, Classification loss: 0.018297, CORAL loss: 0.030073, Total_Loss: 0.036942\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 62 [ 3/ 6]\tLambda value: 0.6200, Classification loss: 0.038226, CORAL loss: 0.027777, Total_Loss: 0.055448\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 62 [ 4/ 6]\tLambda value: 0.6200, Classification loss: 0.030236, CORAL loss: 0.030182, Total_Loss: 0.048949\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 62 [ 5/ 6]\tLambda value: 0.6200, Classification loss: 0.026583, CORAL loss: 0.032147, Total_Loss: 0.046514\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 62 [ 6/ 6]\tLambda value: 0.6200, Classification loss: 0.029170, CORAL loss: 0.046002, Total_Loss: 0.057691\n",
            "[EPOCH] 62: Classification loss: 0.029279, CORAL loss: 0.035283, Total_Loss: 0.051154\n",
            "[Test Source]: Epoch: 62, avg_loss: 0.0079, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 62, avg_loss: 1.8345, Accuracy: 407/795 (51.19%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 63 [ 1/ 6]\tLambda value: 0.6300, Classification loss: 0.029450, CORAL loss: 0.033260, Total_Loss: 0.050403\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 63 [ 2/ 6]\tLambda value: 0.6300, Classification loss: 0.032734, CORAL loss: 0.027843, Total_Loss: 0.050275\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 63 [ 3/ 6]\tLambda value: 0.6300, Classification loss: 0.036408, CORAL loss: 0.039343, Total_Loss: 0.061194\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 63 [ 4/ 6]\tLambda value: 0.6300, Classification loss: 0.023263, CORAL loss: 0.022471, Total_Loss: 0.037420\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 63 [ 5/ 6]\tLambda value: 0.6300, Classification loss: 0.021535, CORAL loss: 0.028969, Total_Loss: 0.039785\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 63 [ 6/ 6]\tLambda value: 0.6300, Classification loss: 0.016048, CORAL loss: 0.029721, Total_Loss: 0.034773\n",
            "[EPOCH] 63: Classification loss: 0.026573, CORAL loss: 0.030268, Total_Loss: 0.045642\n",
            "[Test Source]: Epoch: 63, avg_loss: 0.0079, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 63, avg_loss: 1.8513, Accuracy: 407/795 (51.19%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 64 [ 1/ 6]\tLambda value: 0.6400, Classification loss: 0.036385, CORAL loss: 0.023198, Total_Loss: 0.051232\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 64 [ 2/ 6]\tLambda value: 0.6400, Classification loss: 0.031905, CORAL loss: 0.036854, Total_Loss: 0.055491\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 64 [ 3/ 6]\tLambda value: 0.6400, Classification loss: 0.032774, CORAL loss: 0.025671, Total_Loss: 0.049203\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 64 [ 4/ 6]\tLambda value: 0.6400, Classification loss: 0.027023, CORAL loss: 0.025790, Total_Loss: 0.043528\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 64 [ 5/ 6]\tLambda value: 0.6400, Classification loss: 0.020220, CORAL loss: 0.031757, Total_Loss: 0.040544\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 64 [ 6/ 6]\tLambda value: 0.6400, Classification loss: 0.031470, CORAL loss: 0.020565, Total_Loss: 0.044632\n",
            "[EPOCH] 64: Classification loss: 0.029963, CORAL loss: 0.027306, Total_Loss: 0.047438\n",
            "[Test Source]: Epoch: 64, avg_loss: 0.0072, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 64, avg_loss: 1.7999, Accuracy: 412/795 (51.82%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 65 [ 1/ 6]\tLambda value: 0.6500, Classification loss: 0.026553, CORAL loss: 0.034864, Total_Loss: 0.049214\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 65 [ 2/ 6]\tLambda value: 0.6500, Classification loss: 0.031584, CORAL loss: 0.025867, Total_Loss: 0.048397\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 65 [ 3/ 6]\tLambda value: 0.6500, Classification loss: 0.032730, CORAL loss: 0.035032, Total_Loss: 0.055501\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 65 [ 4/ 6]\tLambda value: 0.6500, Classification loss: 0.030954, CORAL loss: 0.021565, Total_Loss: 0.044971\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 65 [ 5/ 6]\tLambda value: 0.6500, Classification loss: 0.041564, CORAL loss: 0.030441, Total_Loss: 0.061351\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 65 [ 6/ 6]\tLambda value: 0.6500, Classification loss: 0.024575, CORAL loss: 0.024628, Total_Loss: 0.040583\n",
            "[EPOCH] 65: Classification loss: 0.031327, CORAL loss: 0.028733, Total_Loss: 0.050003\n",
            "[Test Source]: Epoch: 65, avg_loss: 0.0067, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 65, avg_loss: 1.8303, Accuracy: 416/795 (52.33%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 66 [ 1/ 6]\tLambda value: 0.6600, Classification loss: 0.026597, CORAL loss: 0.028300, Total_Loss: 0.045274\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 66 [ 2/ 6]\tLambda value: 0.6600, Classification loss: 0.020536, CORAL loss: 0.047046, Total_Loss: 0.051586\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 66 [ 3/ 6]\tLambda value: 0.6600, Classification loss: 0.035261, CORAL loss: 0.028040, Total_Loss: 0.053768\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 66 [ 4/ 6]\tLambda value: 0.6600, Classification loss: 0.027124, CORAL loss: 0.034527, Total_Loss: 0.049912\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 66 [ 5/ 6]\tLambda value: 0.6600, Classification loss: 0.033677, CORAL loss: 0.029601, Total_Loss: 0.053213\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 66 [ 6/ 6]\tLambda value: 0.6600, Classification loss: 0.016524, CORAL loss: 0.040700, Total_Loss: 0.043386\n",
            "[EPOCH] 66: Classification loss: 0.026620, CORAL loss: 0.034702, Total_Loss: 0.049523\n",
            "[Test Source]: Epoch: 66, avg_loss: 0.0064, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 66, avg_loss: 1.8684, Accuracy: 412/795 (51.82%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 67 [ 1/ 6]\tLambda value: 0.6700, Classification loss: 0.017173, CORAL loss: 0.030320, Total_Loss: 0.037487\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 67 [ 2/ 6]\tLambda value: 0.6700, Classification loss: 0.030220, CORAL loss: 0.021421, Total_Loss: 0.044572\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 67 [ 3/ 6]\tLambda value: 0.6700, Classification loss: 0.021019, CORAL loss: 0.028196, Total_Loss: 0.039911\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 67 [ 4/ 6]\tLambda value: 0.6700, Classification loss: 0.031689, CORAL loss: 0.028245, Total_Loss: 0.050613\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 67 [ 5/ 6]\tLambda value: 0.6700, Classification loss: 0.035605, CORAL loss: 0.033452, Total_Loss: 0.058018\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 67 [ 6/ 6]\tLambda value: 0.6700, Classification loss: 0.016910, CORAL loss: 0.042855, Total_Loss: 0.045622\n",
            "[EPOCH] 67: Classification loss: 0.025436, CORAL loss: 0.030748, Total_Loss: 0.046037\n",
            "[Test Source]: Epoch: 67, avg_loss: 0.0064, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 67, avg_loss: 1.8596, Accuracy: 406/795 (51.07%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 68 [ 1/ 6]\tLambda value: 0.6800, Classification loss: 0.016103, CORAL loss: 0.035824, Total_Loss: 0.040464\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 68 [ 2/ 6]\tLambda value: 0.6800, Classification loss: 0.040032, CORAL loss: 0.032547, Total_Loss: 0.062164\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 68 [ 3/ 6]\tLambda value: 0.6800, Classification loss: 0.030133, CORAL loss: 0.030584, Total_Loss: 0.050930\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 68 [ 4/ 6]\tLambda value: 0.6800, Classification loss: 0.019215, CORAL loss: 0.031548, Total_Loss: 0.040668\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 68 [ 5/ 6]\tLambda value: 0.6800, Classification loss: 0.017693, CORAL loss: 0.029136, Total_Loss: 0.037506\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 68 [ 6/ 6]\tLambda value: 0.6800, Classification loss: 0.021683, CORAL loss: 0.025872, Total_Loss: 0.039276\n",
            "[EPOCH] 68: Classification loss: 0.024143, CORAL loss: 0.030919, Total_Loss: 0.045168\n",
            "[Test Source]: Epoch: 68, avg_loss: 0.0064, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 68, avg_loss: 1.8201, Accuracy: 417/795 (52.45%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 69 [ 1/ 6]\tLambda value: 0.6900, Classification loss: 0.028591, CORAL loss: 0.021838, Total_Loss: 0.043659\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 69 [ 2/ 6]\tLambda value: 0.6900, Classification loss: 0.026381, CORAL loss: 0.025906, Total_Loss: 0.044256\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 69 [ 3/ 6]\tLambda value: 0.6900, Classification loss: 0.024566, CORAL loss: 0.026347, Total_Loss: 0.042745\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 69 [ 4/ 6]\tLambda value: 0.6900, Classification loss: 0.019898, CORAL loss: 0.043472, Total_Loss: 0.049893\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 69 [ 5/ 6]\tLambda value: 0.6900, Classification loss: 0.027413, CORAL loss: 0.020797, Total_Loss: 0.041763\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 69 [ 6/ 6]\tLambda value: 0.6900, Classification loss: 0.028968, CORAL loss: 0.030767, Total_Loss: 0.050197\n",
            "[EPOCH] 69: Classification loss: 0.025969, CORAL loss: 0.028188, Total_Loss: 0.045419\n",
            "[Test Source]: Epoch: 69, avg_loss: 0.0070, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 69, avg_loss: 1.8415, Accuracy: 399/795 (50.19%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 70 [ 1/ 6]\tLambda value: 0.7000, Classification loss: 0.042105, CORAL loss: 0.024291, Total_Loss: 0.059109\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 70 [ 2/ 6]\tLambda value: 0.7000, Classification loss: 0.023643, CORAL loss: 0.022113, Total_Loss: 0.039122\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 70 [ 3/ 6]\tLambda value: 0.7000, Classification loss: 0.029253, CORAL loss: 0.015289, Total_Loss: 0.039955\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 70 [ 4/ 6]\tLambda value: 0.7000, Classification loss: 0.030980, CORAL loss: 0.031537, Total_Loss: 0.053056\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 70 [ 5/ 6]\tLambda value: 0.7000, Classification loss: 0.018132, CORAL loss: 0.030280, Total_Loss: 0.039328\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 70 [ 6/ 6]\tLambda value: 0.7000, Classification loss: 0.028081, CORAL loss: 0.026130, Total_Loss: 0.046372\n",
            "[EPOCH] 70: Classification loss: 0.028699, CORAL loss: 0.024940, Total_Loss: 0.046157\n",
            "[Test Source]: Epoch: 70, avg_loss: 0.0068, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 70, avg_loss: 1.8075, Accuracy: 406/795 (51.07%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 71 [ 1/ 6]\tLambda value: 0.7100, Classification loss: 0.019542, CORAL loss: 0.020845, Total_Loss: 0.034341\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 71 [ 2/ 6]\tLambda value: 0.7100, Classification loss: 0.039354, CORAL loss: 0.019770, Total_Loss: 0.053391\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 71 [ 3/ 6]\tLambda value: 0.7100, Classification loss: 0.031728, CORAL loss: 0.024671, Total_Loss: 0.049244\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 71 [ 4/ 6]\tLambda value: 0.7100, Classification loss: 0.017369, CORAL loss: 0.034769, Total_Loss: 0.042055\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 71 [ 5/ 6]\tLambda value: 0.7100, Classification loss: 0.024555, CORAL loss: 0.024289, Total_Loss: 0.041800\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 71 [ 6/ 6]\tLambda value: 0.7100, Classification loss: 0.020961, CORAL loss: 0.032346, Total_Loss: 0.043926\n",
            "[EPOCH] 71: Classification loss: 0.025585, CORAL loss: 0.026115, Total_Loss: 0.044126\n",
            "[Test Source]: Epoch: 71, avg_loss: 0.0063, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 71, avg_loss: 1.8474, Accuracy: 400/795 (50.31%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 72 [ 1/ 6]\tLambda value: 0.7200, Classification loss: 0.023759, CORAL loss: 0.029471, Total_Loss: 0.044977\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 72 [ 2/ 6]\tLambda value: 0.7200, Classification loss: 0.022153, CORAL loss: 0.030805, Total_Loss: 0.044332\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 72 [ 3/ 6]\tLambda value: 0.7200, Classification loss: 0.024443, CORAL loss: 0.024264, Total_Loss: 0.041913\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 72 [ 4/ 6]\tLambda value: 0.7200, Classification loss: 0.024588, CORAL loss: 0.027077, Total_Loss: 0.044083\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 72 [ 5/ 6]\tLambda value: 0.7200, Classification loss: 0.026609, CORAL loss: 0.022348, Total_Loss: 0.042700\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 72 [ 6/ 6]\tLambda value: 0.7200, Classification loss: 0.016328, CORAL loss: 0.025700, Total_Loss: 0.034832\n",
            "[EPOCH] 72: Classification loss: 0.022980, CORAL loss: 0.026611, Total_Loss: 0.042140\n",
            "[Test Source]: Epoch: 72, avg_loss: 0.0060, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 72, avg_loss: 1.8265, Accuracy: 414/795 (52.08%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 73 [ 1/ 6]\tLambda value: 0.7300, Classification loss: 0.017641, CORAL loss: 0.031401, Total_Loss: 0.040564\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 73 [ 2/ 6]\tLambda value: 0.7300, Classification loss: 0.025495, CORAL loss: 0.026973, Total_Loss: 0.045185\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 73 [ 3/ 6]\tLambda value: 0.7300, Classification loss: 0.040026, CORAL loss: 0.029914, Total_Loss: 0.061863\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 73 [ 4/ 6]\tLambda value: 0.7300, Classification loss: 0.044048, CORAL loss: 0.022147, Total_Loss: 0.060215\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 73 [ 5/ 6]\tLambda value: 0.7300, Classification loss: 0.025296, CORAL loss: 0.019486, Total_Loss: 0.039521\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 73 [ 6/ 6]\tLambda value: 0.7300, Classification loss: 0.019263, CORAL loss: 0.028460, Total_Loss: 0.040039\n",
            "[EPOCH] 73: Classification loss: 0.028628, CORAL loss: 0.026397, Total_Loss: 0.047898\n",
            "[Test Source]: Epoch: 73, avg_loss: 0.0058, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 73, avg_loss: 1.8564, Accuracy: 410/795 (51.57%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 74 [ 1/ 6]\tLambda value: 0.7400, Classification loss: 0.028427, CORAL loss: 0.024795, Total_Loss: 0.046775\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 74 [ 2/ 6]\tLambda value: 0.7400, Classification loss: 0.020953, CORAL loss: 0.027413, Total_Loss: 0.041239\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 74 [ 3/ 6]\tLambda value: 0.7400, Classification loss: 0.017087, CORAL loss: 0.018515, Total_Loss: 0.030788\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 74 [ 4/ 6]\tLambda value: 0.7400, Classification loss: 0.032328, CORAL loss: 0.022659, Total_Loss: 0.049095\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 74 [ 5/ 6]\tLambda value: 0.7400, Classification loss: 0.015560, CORAL loss: 0.027479, Total_Loss: 0.035895\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 74 [ 6/ 6]\tLambda value: 0.7400, Classification loss: 0.018520, CORAL loss: 0.022009, Total_Loss: 0.034806\n",
            "[EPOCH] 74: Classification loss: 0.022146, CORAL loss: 0.023812, Total_Loss: 0.039766\n",
            "[Test Source]: Epoch: 74, avg_loss: 0.0059, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 74, avg_loss: 1.8491, Accuracy: 415/795 (52.20%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 75 [ 1/ 6]\tLambda value: 0.7500, Classification loss: 0.030008, CORAL loss: 0.019611, Total_Loss: 0.044717\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 75 [ 2/ 6]\tLambda value: 0.7500, Classification loss: 0.020057, CORAL loss: 0.024066, Total_Loss: 0.038106\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 75 [ 3/ 6]\tLambda value: 0.7500, Classification loss: 0.018094, CORAL loss: 0.036666, Total_Loss: 0.045593\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 75 [ 4/ 6]\tLambda value: 0.7500, Classification loss: 0.038130, CORAL loss: 0.028319, Total_Loss: 0.059369\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 75 [ 5/ 6]\tLambda value: 0.7500, Classification loss: 0.018226, CORAL loss: 0.023725, Total_Loss: 0.036020\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 75 [ 6/ 6]\tLambda value: 0.7500, Classification loss: 0.022744, CORAL loss: 0.023598, Total_Loss: 0.040442\n",
            "[EPOCH] 75: Classification loss: 0.024543, CORAL loss: 0.025997, Total_Loss: 0.044041\n",
            "[Test Source]: Epoch: 75, avg_loss: 0.0059, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 75, avg_loss: 1.8548, Accuracy: 412/795 (51.82%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 76 [ 1/ 6]\tLambda value: 0.7600, Classification loss: 0.024275, CORAL loss: 0.039116, Total_Loss: 0.054003\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 76 [ 2/ 6]\tLambda value: 0.7600, Classification loss: 0.029419, CORAL loss: 0.023304, Total_Loss: 0.047130\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 76 [ 3/ 6]\tLambda value: 0.7600, Classification loss: 0.022874, CORAL loss: 0.021792, Total_Loss: 0.039436\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 76 [ 4/ 6]\tLambda value: 0.7600, Classification loss: 0.014449, CORAL loss: 0.034536, Total_Loss: 0.040697\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 76 [ 5/ 6]\tLambda value: 0.7600, Classification loss: 0.023667, CORAL loss: 0.020202, Total_Loss: 0.039020\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 76 [ 6/ 6]\tLambda value: 0.7600, Classification loss: 0.021356, CORAL loss: 0.021181, Total_Loss: 0.037453\n",
            "[EPOCH] 76: Classification loss: 0.022673, CORAL loss: 0.026689, Total_Loss: 0.042957\n",
            "[Test Source]: Epoch: 76, avg_loss: 0.0058, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 76, avg_loss: 1.8588, Accuracy: 407/795 (51.19%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 77 [ 1/ 6]\tLambda value: 0.7700, Classification loss: 0.022018, CORAL loss: 0.030414, Total_Loss: 0.045437\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 77 [ 2/ 6]\tLambda value: 0.7700, Classification loss: 0.024203, CORAL loss: 0.037957, Total_Loss: 0.053430\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 77 [ 3/ 6]\tLambda value: 0.7700, Classification loss: 0.025205, CORAL loss: 0.016677, Total_Loss: 0.038046\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 77 [ 4/ 6]\tLambda value: 0.7700, Classification loss: 0.018126, CORAL loss: 0.026315, Total_Loss: 0.038388\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 77 [ 5/ 6]\tLambda value: 0.7700, Classification loss: 0.018200, CORAL loss: 0.021530, Total_Loss: 0.034778\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 77 [ 6/ 6]\tLambda value: 0.7700, Classification loss: 0.020091, CORAL loss: 0.022142, Total_Loss: 0.037140\n",
            "[EPOCH] 77: Classification loss: 0.021307, CORAL loss: 0.025839, Total_Loss: 0.041203\n",
            "[Test Source]: Epoch: 77, avg_loss: 0.0059, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 77, avg_loss: 1.8893, Accuracy: 399/795 (50.19%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 78 [ 1/ 6]\tLambda value: 0.7800, Classification loss: 0.025250, CORAL loss: 0.025799, Total_Loss: 0.045373\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 78 [ 2/ 6]\tLambda value: 0.7800, Classification loss: 0.028978, CORAL loss: 0.016319, Total_Loss: 0.041707\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 78 [ 3/ 6]\tLambda value: 0.7800, Classification loss: 0.029758, CORAL loss: 0.018456, Total_Loss: 0.044153\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 78 [ 4/ 6]\tLambda value: 0.7800, Classification loss: 0.032439, CORAL loss: 0.023920, Total_Loss: 0.051096\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 78 [ 5/ 6]\tLambda value: 0.7800, Classification loss: 0.021289, CORAL loss: 0.019965, Total_Loss: 0.036862\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 78 [ 6/ 6]\tLambda value: 0.7800, Classification loss: 0.024987, CORAL loss: 0.020076, Total_Loss: 0.040647\n",
            "[EPOCH] 78: Classification loss: 0.027117, CORAL loss: 0.020756, Total_Loss: 0.043306\n",
            "[Test Source]: Epoch: 78, avg_loss: 0.0058, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 78, avg_loss: 1.9133, Accuracy: 391/795 (49.18%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 79 [ 1/ 6]\tLambda value: 0.7900, Classification loss: 0.025624, CORAL loss: 0.026647, Total_Loss: 0.046674\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 79 [ 2/ 6]\tLambda value: 0.7900, Classification loss: 0.039065, CORAL loss: 0.023635, Total_Loss: 0.057737\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 79 [ 3/ 6]\tLambda value: 0.7900, Classification loss: 0.019970, CORAL loss: 0.019570, Total_Loss: 0.035430\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 79 [ 4/ 6]\tLambda value: 0.7900, Classification loss: 0.018021, CORAL loss: 0.024593, Total_Loss: 0.037449\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 79 [ 5/ 6]\tLambda value: 0.7900, Classification loss: 0.031224, CORAL loss: 0.032203, Total_Loss: 0.056665\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 79 [ 6/ 6]\tLambda value: 0.7900, Classification loss: 0.022371, CORAL loss: 0.023059, Total_Loss: 0.040588\n",
            "[EPOCH] 79: Classification loss: 0.026046, CORAL loss: 0.024951, Total_Loss: 0.045757\n",
            "[Test Source]: Epoch: 79, avg_loss: 0.0053, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 79, avg_loss: 1.9055, Accuracy: 400/795 (50.31%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 80 [ 1/ 6]\tLambda value: 0.8000, Classification loss: 0.017357, CORAL loss: 0.025142, Total_Loss: 0.037471\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 80 [ 2/ 6]\tLambda value: 0.8000, Classification loss: 0.024956, CORAL loss: 0.038017, Total_Loss: 0.055370\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 80 [ 3/ 6]\tLambda value: 0.8000, Classification loss: 0.017917, CORAL loss: 0.025688, Total_Loss: 0.038467\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 80 [ 4/ 6]\tLambda value: 0.8000, Classification loss: 0.019572, CORAL loss: 0.026106, Total_Loss: 0.040457\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 80 [ 5/ 6]\tLambda value: 0.8000, Classification loss: 0.021213, CORAL loss: 0.036622, Total_Loss: 0.050510\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 80 [ 6/ 6]\tLambda value: 0.8000, Classification loss: 0.025953, CORAL loss: 0.022452, Total_Loss: 0.043915\n",
            "[EPOCH] 80: Classification loss: 0.021161, CORAL loss: 0.029005, Total_Loss: 0.044365\n",
            "[Test Source]: Epoch: 80, avg_loss: 0.0055, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 80, avg_loss: 1.8911, Accuracy: 402/795 (50.57%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 81 [ 1/ 6]\tLambda value: 0.8100, Classification loss: 0.011251, CORAL loss: 0.031857, Total_Loss: 0.037055\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 81 [ 2/ 6]\tLambda value: 0.8100, Classification loss: 0.028834, CORAL loss: 0.021880, Total_Loss: 0.046557\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 81 [ 3/ 6]\tLambda value: 0.8100, Classification loss: 0.019128, CORAL loss: 0.028901, Total_Loss: 0.042538\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 81 [ 4/ 6]\tLambda value: 0.8100, Classification loss: 0.022054, CORAL loss: 0.021368, Total_Loss: 0.039362\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 81 [ 5/ 6]\tLambda value: 0.8100, Classification loss: 0.028477, CORAL loss: 0.025707, Total_Loss: 0.049300\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 81 [ 6/ 6]\tLambda value: 0.8100, Classification loss: 0.021761, CORAL loss: 0.021078, Total_Loss: 0.038834\n",
            "[EPOCH] 81: Classification loss: 0.021918, CORAL loss: 0.025132, Total_Loss: 0.042274\n",
            "[Test Source]: Epoch: 81, avg_loss: 0.0056, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 81, avg_loss: 1.8826, Accuracy: 404/795 (50.82%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 82 [ 1/ 6]\tLambda value: 0.8200, Classification loss: 0.023154, CORAL loss: 0.034675, Total_Loss: 0.051588\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 82 [ 2/ 6]\tLambda value: 0.8200, Classification loss: 0.017303, CORAL loss: 0.018601, Total_Loss: 0.032555\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 82 [ 3/ 6]\tLambda value: 0.8200, Classification loss: 0.015179, CORAL loss: 0.034487, Total_Loss: 0.043458\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 82 [ 4/ 6]\tLambda value: 0.8200, Classification loss: 0.027381, CORAL loss: 0.020586, Total_Loss: 0.044261\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 82 [ 5/ 6]\tLambda value: 0.8200, Classification loss: 0.026682, CORAL loss: 0.025538, Total_Loss: 0.047624\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 82 [ 6/ 6]\tLambda value: 0.8200, Classification loss: 0.016146, CORAL loss: 0.017996, Total_Loss: 0.030903\n",
            "[EPOCH] 82: Classification loss: 0.020974, CORAL loss: 0.025314, Total_Loss: 0.041731\n",
            "[Test Source]: Epoch: 82, avg_loss: 0.0061, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 82, avg_loss: 1.9316, Accuracy: 390/795 (49.06%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 83 [ 1/ 6]\tLambda value: 0.8300, Classification loss: 0.022119, CORAL loss: 0.026756, Total_Loss: 0.044327\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 83 [ 2/ 6]\tLambda value: 0.8300, Classification loss: 0.030565, CORAL loss: 0.030352, Total_Loss: 0.055757\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 83 [ 3/ 6]\tLambda value: 0.8300, Classification loss: 0.025052, CORAL loss: 0.021308, Total_Loss: 0.042738\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 83 [ 4/ 6]\tLambda value: 0.8300, Classification loss: 0.026215, CORAL loss: 0.021132, Total_Loss: 0.043755\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 83 [ 5/ 6]\tLambda value: 0.8300, Classification loss: 0.029624, CORAL loss: 0.025620, Total_Loss: 0.050889\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 83 [ 6/ 6]\tLambda value: 0.8300, Classification loss: 0.039746, CORAL loss: 0.019307, Total_Loss: 0.055771\n",
            "[EPOCH] 83: Classification loss: 0.028887, CORAL loss: 0.024079, Total_Loss: 0.048873\n",
            "[Test Source]: Epoch: 83, avg_loss: 0.0062, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 83, avg_loss: 1.8852, Accuracy: 402/795 (50.57%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 84 [ 1/ 6]\tLambda value: 0.8400, Classification loss: 0.021643, CORAL loss: 0.030018, Total_Loss: 0.046858\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 84 [ 2/ 6]\tLambda value: 0.8400, Classification loss: 0.018801, CORAL loss: 0.027477, Total_Loss: 0.041882\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 84 [ 3/ 6]\tLambda value: 0.8400, Classification loss: 0.023737, CORAL loss: 0.014563, Total_Loss: 0.035970\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 84 [ 4/ 6]\tLambda value: 0.8400, Classification loss: 0.023872, CORAL loss: 0.020893, Total_Loss: 0.041422\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 84 [ 5/ 6]\tLambda value: 0.8400, Classification loss: 0.019657, CORAL loss: 0.018611, Total_Loss: 0.035290\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 84 [ 6/ 6]\tLambda value: 0.8400, Classification loss: 0.015845, CORAL loss: 0.020446, Total_Loss: 0.033020\n",
            "[EPOCH] 84: Classification loss: 0.020592, CORAL loss: 0.022001, Total_Loss: 0.039074\n",
            "[Test Source]: Epoch: 84, avg_loss: 0.0057, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 84, avg_loss: 1.8878, Accuracy: 398/795 (50.06%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 85 [ 1/ 6]\tLambda value: 0.8500, Classification loss: 0.014559, CORAL loss: 0.025872, Total_Loss: 0.036551\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 85 [ 2/ 6]\tLambda value: 0.8500, Classification loss: 0.025835, CORAL loss: 0.016969, Total_Loss: 0.040259\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 85 [ 3/ 6]\tLambda value: 0.8500, Classification loss: 0.021810, CORAL loss: 0.024026, Total_Loss: 0.042231\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 85 [ 4/ 6]\tLambda value: 0.8500, Classification loss: 0.029689, CORAL loss: 0.014300, Total_Loss: 0.041844\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 85 [ 5/ 6]\tLambda value: 0.8500, Classification loss: 0.021856, CORAL loss: 0.021060, Total_Loss: 0.039758\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 85 [ 6/ 6]\tLambda value: 0.8500, Classification loss: 0.015747, CORAL loss: 0.021675, Total_Loss: 0.034171\n",
            "[EPOCH] 85: Classification loss: 0.021583, CORAL loss: 0.020650, Total_Loss: 0.039136\n",
            "[Test Source]: Epoch: 85, avg_loss: 0.0053, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 85, avg_loss: 1.8987, Accuracy: 397/795 (49.94%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 86 [ 1/ 6]\tLambda value: 0.8600, Classification loss: 0.019659, CORAL loss: 0.019156, Total_Loss: 0.036134\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 86 [ 2/ 6]\tLambda value: 0.8600, Classification loss: 0.021174, CORAL loss: 0.023904, Total_Loss: 0.041732\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 86 [ 3/ 6]\tLambda value: 0.8600, Classification loss: 0.026819, CORAL loss: 0.020891, Total_Loss: 0.044785\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 86 [ 4/ 6]\tLambda value: 0.8600, Classification loss: 0.029523, CORAL loss: 0.017963, Total_Loss: 0.044971\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 86 [ 5/ 6]\tLambda value: 0.8600, Classification loss: 0.019743, CORAL loss: 0.018069, Total_Loss: 0.035282\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 86 [ 6/ 6]\tLambda value: 0.8600, Classification loss: 0.020225, CORAL loss: 0.021030, Total_Loss: 0.038311\n",
            "[EPOCH] 86: Classification loss: 0.022857, CORAL loss: 0.020169, Total_Loss: 0.040202\n",
            "[Test Source]: Epoch: 86, avg_loss: 0.0051, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 86, avg_loss: 1.9295, Accuracy: 392/795 (49.31%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 87 [ 1/ 6]\tLambda value: 0.8700, Classification loss: 0.018098, CORAL loss: 0.021738, Total_Loss: 0.037010\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 87 [ 2/ 6]\tLambda value: 0.8700, Classification loss: 0.017109, CORAL loss: 0.021603, Total_Loss: 0.035903\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 87 [ 3/ 6]\tLambda value: 0.8700, Classification loss: 0.016702, CORAL loss: 0.024406, Total_Loss: 0.037935\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 87 [ 4/ 6]\tLambda value: 0.8700, Classification loss: 0.022930, CORAL loss: 0.021794, Total_Loss: 0.041890\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 87 [ 5/ 6]\tLambda value: 0.8700, Classification loss: 0.018195, CORAL loss: 0.021161, Total_Loss: 0.036605\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 87 [ 6/ 6]\tLambda value: 0.8700, Classification loss: 0.016953, CORAL loss: 0.018011, Total_Loss: 0.032622\n",
            "[EPOCH] 87: Classification loss: 0.018331, CORAL loss: 0.021452, Total_Loss: 0.036994\n",
            "[Test Source]: Epoch: 87, avg_loss: 0.0050, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 87, avg_loss: 1.9441, Accuracy: 382/795 (48.05%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 88 [ 1/ 6]\tLambda value: 0.8800, Classification loss: 0.022726, CORAL loss: 0.030739, Total_Loss: 0.049777\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 88 [ 2/ 6]\tLambda value: 0.8800, Classification loss: 0.014294, CORAL loss: 0.019963, Total_Loss: 0.031861\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 88 [ 3/ 6]\tLambda value: 0.8800, Classification loss: 0.019963, CORAL loss: 0.017777, Total_Loss: 0.035607\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 88 [ 4/ 6]\tLambda value: 0.8800, Classification loss: 0.024547, CORAL loss: 0.015848, Total_Loss: 0.038493\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 88 [ 5/ 6]\tLambda value: 0.8800, Classification loss: 0.019993, CORAL loss: 0.017857, Total_Loss: 0.035707\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 88 [ 6/ 6]\tLambda value: 0.8800, Classification loss: 0.017007, CORAL loss: 0.018769, Total_Loss: 0.033524\n",
            "[EPOCH] 88: Classification loss: 0.019755, CORAL loss: 0.020159, Total_Loss: 0.037495\n",
            "[Test Source]: Epoch: 88, avg_loss: 0.0050, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 88, avg_loss: 1.9242, Accuracy: 392/795 (49.31%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 89 [ 1/ 6]\tLambda value: 0.8900, Classification loss: 0.022997, CORAL loss: 0.019069, Total_Loss: 0.039969\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 89 [ 2/ 6]\tLambda value: 0.8900, Classification loss: 0.021409, CORAL loss: 0.017320, Total_Loss: 0.036824\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 89 [ 3/ 6]\tLambda value: 0.8900, Classification loss: 0.035561, CORAL loss: 0.019466, Total_Loss: 0.052886\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 89 [ 4/ 6]\tLambda value: 0.8900, Classification loss: 0.019518, CORAL loss: 0.022329, Total_Loss: 0.039391\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 89 [ 5/ 6]\tLambda value: 0.8900, Classification loss: 0.018785, CORAL loss: 0.019347, Total_Loss: 0.036004\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 89 [ 6/ 6]\tLambda value: 0.8900, Classification loss: 0.020435, CORAL loss: 0.020085, Total_Loss: 0.038311\n",
            "[EPOCH] 89: Classification loss: 0.023117, CORAL loss: 0.019603, Total_Loss: 0.040564\n",
            "[Test Source]: Epoch: 89, avg_loss: 0.0049, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 89, avg_loss: 1.8916, Accuracy: 389/795 (48.93%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 90 [ 1/ 6]\tLambda value: 0.9000, Classification loss: 0.024418, CORAL loss: 0.017719, Total_Loss: 0.040364\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 90 [ 2/ 6]\tLambda value: 0.9000, Classification loss: 0.013902, CORAL loss: 0.021614, Total_Loss: 0.033355\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 90 [ 3/ 6]\tLambda value: 0.9000, Classification loss: 0.016697, CORAL loss: 0.019795, Total_Loss: 0.034513\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 90 [ 4/ 6]\tLambda value: 0.9000, Classification loss: 0.019224, CORAL loss: 0.021931, Total_Loss: 0.038961\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 90 [ 5/ 6]\tLambda value: 0.9000, Classification loss: 0.024922, CORAL loss: 0.026117, Total_Loss: 0.048427\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 90 [ 6/ 6]\tLambda value: 0.9000, Classification loss: 0.034420, CORAL loss: 0.015081, Total_Loss: 0.047993\n",
            "[EPOCH] 90: Classification loss: 0.022264, CORAL loss: 0.020376, Total_Loss: 0.040602\n",
            "[Test Source]: Epoch: 90, avg_loss: 0.0048, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 90, avg_loss: 1.9040, Accuracy: 387/795 (48.68%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 91 [ 1/ 6]\tLambda value: 0.9100, Classification loss: 0.023851, CORAL loss: 0.033250, Total_Loss: 0.054109\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 91 [ 2/ 6]\tLambda value: 0.9100, Classification loss: 0.012063, CORAL loss: 0.015718, Total_Loss: 0.026367\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 91 [ 3/ 6]\tLambda value: 0.9100, Classification loss: 0.014645, CORAL loss: 0.016865, Total_Loss: 0.029992\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 91 [ 4/ 6]\tLambda value: 0.9100, Classification loss: 0.016382, CORAL loss: 0.020476, Total_Loss: 0.035015\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 91 [ 5/ 6]\tLambda value: 0.9100, Classification loss: 0.012973, CORAL loss: 0.028901, Total_Loss: 0.039272\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 91 [ 6/ 6]\tLambda value: 0.9100, Classification loss: 0.016106, CORAL loss: 0.020143, Total_Loss: 0.034436\n",
            "[EPOCH] 91: Classification loss: 0.016003, CORAL loss: 0.022559, Total_Loss: 0.036532\n",
            "[Test Source]: Epoch: 91, avg_loss: 0.0050, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 91, avg_loss: 1.9395, Accuracy: 392/795 (49.31%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 92 [ 1/ 6]\tLambda value: 0.9200, Classification loss: 0.020786, CORAL loss: 0.025001, Total_Loss: 0.043787\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 92 [ 2/ 6]\tLambda value: 0.9200, Classification loss: 0.023437, CORAL loss: 0.025129, Total_Loss: 0.046556\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 92 [ 3/ 6]\tLambda value: 0.9200, Classification loss: 0.018999, CORAL loss: 0.017880, Total_Loss: 0.035448\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 92 [ 4/ 6]\tLambda value: 0.9200, Classification loss: 0.025855, CORAL loss: 0.020414, Total_Loss: 0.044636\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 92 [ 5/ 6]\tLambda value: 0.9200, Classification loss: 0.017370, CORAL loss: 0.014955, Total_Loss: 0.031129\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 92 [ 6/ 6]\tLambda value: 0.9200, Classification loss: 0.014172, CORAL loss: 0.029284, Total_Loss: 0.041113\n",
            "[EPOCH] 92: Classification loss: 0.020103, CORAL loss: 0.022111, Total_Loss: 0.040445\n",
            "[Test Source]: Epoch: 92, avg_loss: 0.0051, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 92, avg_loss: 1.9480, Accuracy: 392/795 (49.31%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 93 [ 1/ 6]\tLambda value: 0.9300, Classification loss: 0.018435, CORAL loss: 0.017433, Total_Loss: 0.034647\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 93 [ 2/ 6]\tLambda value: 0.9300, Classification loss: 0.020696, CORAL loss: 0.021901, Total_Loss: 0.041064\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 93 [ 3/ 6]\tLambda value: 0.9300, Classification loss: 0.017574, CORAL loss: 0.018238, Total_Loss: 0.034535\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 93 [ 4/ 6]\tLambda value: 0.9300, Classification loss: 0.023553, CORAL loss: 0.017412, Total_Loss: 0.039745\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 93 [ 5/ 6]\tLambda value: 0.9300, Classification loss: 0.018349, CORAL loss: 0.024022, Total_Loss: 0.040690\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 93 [ 6/ 6]\tLambda value: 0.9300, Classification loss: 0.035586, CORAL loss: 0.018495, Total_Loss: 0.052787\n",
            "[EPOCH] 93: Classification loss: 0.022365, CORAL loss: 0.019583, Total_Loss: 0.040578\n",
            "[Test Source]: Epoch: 93, avg_loss: 0.0051, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 93, avg_loss: 1.9632, Accuracy: 391/795 (49.18%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 94 [ 1/ 6]\tLambda value: 0.9400, Classification loss: 0.022259, CORAL loss: 0.017104, Total_Loss: 0.038337\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 94 [ 2/ 6]\tLambda value: 0.9400, Classification loss: 0.022244, CORAL loss: 0.018734, Total_Loss: 0.039854\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 94 [ 3/ 6]\tLambda value: 0.9400, Classification loss: 0.013457, CORAL loss: 0.020017, Total_Loss: 0.032273\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 94 [ 4/ 6]\tLambda value: 0.9400, Classification loss: 0.020414, CORAL loss: 0.021448, Total_Loss: 0.040575\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 94 [ 5/ 6]\tLambda value: 0.9400, Classification loss: 0.029957, CORAL loss: 0.021103, Total_Loss: 0.049794\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 94 [ 6/ 6]\tLambda value: 0.9400, Classification loss: 0.020715, CORAL loss: 0.019868, Total_Loss: 0.039391\n",
            "[EPOCH] 94: Classification loss: 0.021508, CORAL loss: 0.019713, Total_Loss: 0.040037\n",
            "[Test Source]: Epoch: 94, avg_loss: 0.0051, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 94, avg_loss: 1.9506, Accuracy: 389/795 (48.93%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 95 [ 1/ 6]\tLambda value: 0.9500, Classification loss: 0.020905, CORAL loss: 0.016419, Total_Loss: 0.036503\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 95 [ 2/ 6]\tLambda value: 0.9500, Classification loss: 0.011424, CORAL loss: 0.014566, Total_Loss: 0.025262\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 95 [ 3/ 6]\tLambda value: 0.9500, Classification loss: 0.013988, CORAL loss: 0.015212, Total_Loss: 0.028439\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 95 [ 4/ 6]\tLambda value: 0.9500, Classification loss: 0.021008, CORAL loss: 0.019421, Total_Loss: 0.039457\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 95 [ 5/ 6]\tLambda value: 0.9500, Classification loss: 0.016606, CORAL loss: 0.022432, Total_Loss: 0.037916\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 95 [ 6/ 6]\tLambda value: 0.9500, Classification loss: 0.020935, CORAL loss: 0.013167, Total_Loss: 0.033444\n",
            "[EPOCH] 95: Classification loss: 0.017478, CORAL loss: 0.016869, Total_Loss: 0.033504\n",
            "[Test Source]: Epoch: 95, avg_loss: 0.0050, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 95, avg_loss: 1.9761, Accuracy: 388/795 (48.81%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 96 [ 1/ 6]\tLambda value: 0.9600, Classification loss: 0.019369, CORAL loss: 0.023383, Total_Loss: 0.041818\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 96 [ 2/ 6]\tLambda value: 0.9600, Classification loss: 0.021417, CORAL loss: 0.021599, Total_Loss: 0.042153\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 96 [ 3/ 6]\tLambda value: 0.9600, Classification loss: 0.019615, CORAL loss: 0.013337, Total_Loss: 0.032418\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 96 [ 4/ 6]\tLambda value: 0.9600, Classification loss: 0.026085, CORAL loss: 0.018955, Total_Loss: 0.044281\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 96 [ 5/ 6]\tLambda value: 0.9600, Classification loss: 0.019184, CORAL loss: 0.023295, Total_Loss: 0.041547\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 96 [ 6/ 6]\tLambda value: 0.9600, Classification loss: 0.019507, CORAL loss: 0.025580, Total_Loss: 0.044064\n",
            "[EPOCH] 96: Classification loss: 0.020863, CORAL loss: 0.021025, Total_Loss: 0.041047\n",
            "[Test Source]: Epoch: 96, avg_loss: 0.0046, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 96, avg_loss: 1.9570, Accuracy: 393/795 (49.43%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 97 [ 1/ 6]\tLambda value: 0.9700, Classification loss: 0.019147, CORAL loss: 0.022535, Total_Loss: 0.041006\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 97 [ 2/ 6]\tLambda value: 0.9700, Classification loss: 0.025940, CORAL loss: 0.014885, Total_Loss: 0.040379\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 97 [ 3/ 6]\tLambda value: 0.9700, Classification loss: 0.020537, CORAL loss: 0.013696, Total_Loss: 0.033822\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 97 [ 4/ 6]\tLambda value: 0.9700, Classification loss: 0.020247, CORAL loss: 0.015413, Total_Loss: 0.035198\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 97 [ 5/ 6]\tLambda value: 0.9700, Classification loss: 0.025886, CORAL loss: 0.016120, Total_Loss: 0.041522\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 97 [ 6/ 6]\tLambda value: 0.9700, Classification loss: 0.015741, CORAL loss: 0.018442, Total_Loss: 0.033630\n",
            "[EPOCH] 97: Classification loss: 0.021250, CORAL loss: 0.016848, Total_Loss: 0.037593\n",
            "[Test Source]: Epoch: 97, avg_loss: 0.0042, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 97, avg_loss: 1.9330, Accuracy: 400/795 (50.31%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 98 [ 1/ 6]\tLambda value: 0.9800, Classification loss: 0.020610, CORAL loss: 0.016720, Total_Loss: 0.036996\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 98 [ 2/ 6]\tLambda value: 0.9800, Classification loss: 0.011176, CORAL loss: 0.018432, Total_Loss: 0.029239\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 98 [ 3/ 6]\tLambda value: 0.9800, Classification loss: 0.019957, CORAL loss: 0.018406, Total_Loss: 0.037996\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 98 [ 4/ 6]\tLambda value: 0.9800, Classification loss: 0.029222, CORAL loss: 0.018036, Total_Loss: 0.046898\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 98 [ 5/ 6]\tLambda value: 0.9800, Classification loss: 0.013574, CORAL loss: 0.018533, Total_Loss: 0.031735\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 98 [ 6/ 6]\tLambda value: 0.9800, Classification loss: 0.011354, CORAL loss: 0.018564, Total_Loss: 0.029546\n",
            "[EPOCH] 98: Classification loss: 0.017649, CORAL loss: 0.018115, Total_Loss: 0.035402\n",
            "[Test Source]: Epoch: 98, avg_loss: 0.0041, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 98, avg_loss: 1.9205, Accuracy: 400/795 (50.31%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 99 [ 1/ 6]\tLambda value: 0.9900, Classification loss: 0.023610, CORAL loss: 0.018676, Total_Loss: 0.042099\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 99 [ 2/ 6]\tLambda value: 0.9900, Classification loss: 0.014566, CORAL loss: 0.026027, Total_Loss: 0.040332\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 99 [ 3/ 6]\tLambda value: 0.9900, Classification loss: 0.017334, CORAL loss: 0.017623, Total_Loss: 0.034781\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 99 [ 4/ 6]\tLambda value: 0.9900, Classification loss: 0.017258, CORAL loss: 0.025166, Total_Loss: 0.042172\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 99 [ 5/ 6]\tLambda value: 0.9900, Classification loss: 0.013818, CORAL loss: 0.019535, Total_Loss: 0.033158\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 99 [ 6/ 6]\tLambda value: 0.9900, Classification loss: 0.013458, CORAL loss: 0.014359, Total_Loss: 0.027673\n",
            "[EPOCH] 99: Classification loss: 0.016674, CORAL loss: 0.020231, Total_Loss: 0.036703\n",
            "[Test Source]: Epoch: 99, avg_loss: 0.0042, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 99, avg_loss: 1.9256, Accuracy: 395/795 (49.69%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 100 [ 1/ 6]\tLambda value: 1.0000, Classification loss: 0.018734, CORAL loss: 0.017068, Total_Loss: 0.035803\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 100 [ 2/ 6]\tLambda value: 1.0000, Classification loss: 0.015366, CORAL loss: 0.019239, Total_Loss: 0.034605\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 100 [ 3/ 6]\tLambda value: 1.0000, Classification loss: 0.018921, CORAL loss: 0.021602, Total_Loss: 0.040523\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 100 [ 4/ 6]\tLambda value: 1.0000, Classification loss: 0.014221, CORAL loss: 0.017760, Total_Loss: 0.031981\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 100 [ 5/ 6]\tLambda value: 1.0000, Classification loss: 0.016429, CORAL loss: 0.012310, Total_Loss: 0.028739\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 100 [ 6/ 6]\tLambda value: 1.0000, Classification loss: 0.021740, CORAL loss: 0.022561, Total_Loss: 0.044301\n",
            "[EPOCH] 100: Classification loss: 0.017569, CORAL loss: 0.018423, Total_Loss: 0.035992\n",
            "[Test Source]: Epoch: 100, avg_loss: 0.0044, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 100, avg_loss: 1.8747, Accuracy: 403/795 (50.69%)\n",
            "\n",
            "saving training with adaptation...\n",
            "[INFO] Object saved to adaptation_training_statistic.pkl\n",
            "[INFO] Object saved to adaptation_testing_s_statistic.pkl\n",
            "[INFO] Object saved to adaptation_testing_t_statistic.pkl\n",
            "checkpoint saved in adaptation_checkpoint.tar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7POyt8e5zpem",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e0c825b2-9f70-4f1d-c494-6a150984cc6a"
      },
      "source": [
        "# train DeepCORAL w/o domain adaptation\n",
        "!python /content/main.py --epochs 100 --batch_size_source 128 --batch_size_target 128 --name_source amazon --name_target webcam"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "creating source/target dataloaders...\n",
            "source data: amazon\n",
            "target data: webcam\n",
            "using cuda...\n",
            "loading pre-trained AlexNet...\n",
            "loaded model correctly...\n",
            "model type: <class 'model.DeepCORAL'>\n",
            "adapt domain: False\n",
            "running training for 100 epochs...\n",
            "HBox(children=(IntProgress(value=0), HTML(value='')))\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  1 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 3.423044, CORAL loss: 0.000007, Total_Loss: 3.423044\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  1 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 3.142355, CORAL loss: 0.000011, Total_Loss: 3.142355\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  1 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 2.623153, CORAL loss: 0.000152, Total_Loss: 2.623153\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  1 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 2.077032, CORAL loss: 0.002272, Total_Loss: 2.077032\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  1 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 2.022359, CORAL loss: 0.004830, Total_Loss: 2.022359\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  1 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 1.673506, CORAL loss: 0.005988, Total_Loss: 1.673506\n",
            "[EPOCH] 1: Classification loss: 2.493575, CORAL loss: 0.002210, Total_Loss: 2.493575\n",
            "[Test Source]: Epoch: 1, avg_loss: 1.2742, Accuracy: 1804/2817 (64.04%)\n",
            "[Test Target]: Epoch: 1, avg_loss: 2.0949, Accuracy: 331/795 (41.64%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  2 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 1.492964, CORAL loss: 0.022659, Total_Loss: 1.492964\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  2 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 1.038340, CORAL loss: 0.057296, Total_Loss: 1.038340\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  2 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 1.546258, CORAL loss: 0.051448, Total_Loss: 1.546258\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  2 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 1.455985, CORAL loss: 0.090141, Total_Loss: 1.455985\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  2 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 1.343570, CORAL loss: 0.093839, Total_Loss: 1.343570\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  2 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 1.415649, CORAL loss: 0.108752, Total_Loss: 1.415649\n",
            "[EPOCH] 2: Classification loss: 1.382128, CORAL loss: 0.070689, Total_Loss: 1.382128\n",
            "[Test Source]: Epoch: 2, avg_loss: 0.9086, Accuracy: 2118/2817 (75.19%)\n",
            "[Test Target]: Epoch: 2, avg_loss: 2.0865, Accuracy: 341/795 (42.89%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  3 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 1.065969, CORAL loss: 0.136424, Total_Loss: 1.065969\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  3 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.942275, CORAL loss: 0.127456, Total_Loss: 0.942275\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  3 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.823267, CORAL loss: 0.309886, Total_Loss: 0.823267\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  3 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.996539, CORAL loss: 0.359696, Total_Loss: 0.996539\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  3 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.934515, CORAL loss: 0.172574, Total_Loss: 0.934515\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  3 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 1.142781, CORAL loss: 0.418341, Total_Loss: 1.142781\n",
            "[EPOCH] 3: Classification loss: 0.984224, CORAL loss: 0.254063, Total_Loss: 0.984224\n",
            "[Test Source]: Epoch: 3, avg_loss: 0.7451, Accuracy: 2252/2817 (79.94%)\n",
            "[Test Target]: Epoch: 3, avg_loss: 2.1577, Accuracy: 349/795 (43.90%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  4 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.788817, CORAL loss: 0.250679, Total_Loss: 0.788817\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  4 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 1.050831, CORAL loss: 0.306881, Total_Loss: 1.050831\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  4 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.996908, CORAL loss: 0.342581, Total_Loss: 0.996908\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  4 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.657504, CORAL loss: 0.175245, Total_Loss: 0.657504\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  4 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.699548, CORAL loss: 0.459027, Total_Loss: 0.699548\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  4 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.567410, CORAL loss: 0.333499, Total_Loss: 0.567410\n",
            "[EPOCH] 4: Classification loss: 0.793503, CORAL loss: 0.311319, Total_Loss: 0.793503\n",
            "[Test Source]: Epoch: 4, avg_loss: 0.6347, Accuracy: 2334/2817 (82.85%)\n",
            "[Test Target]: Epoch: 4, avg_loss: 2.1981, Accuracy: 348/795 (43.77%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  5 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.719494, CORAL loss: 0.170086, Total_Loss: 0.719494\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  5 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.739854, CORAL loss: 0.178749, Total_Loss: 0.739854\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  5 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.873249, CORAL loss: 0.277480, Total_Loss: 0.873249\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  5 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.736402, CORAL loss: 0.206381, Total_Loss: 0.736402\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  5 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.613740, CORAL loss: 0.210150, Total_Loss: 0.613740\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  5 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.559898, CORAL loss: 0.230036, Total_Loss: 0.559898\n",
            "[EPOCH] 5: Classification loss: 0.707106, CORAL loss: 0.212147, Total_Loss: 0.707106\n",
            "[Test Source]: Epoch: 5, avg_loss: 0.5400, Accuracy: 2412/2817 (85.62%)\n",
            "[Test Target]: Epoch: 5, avg_loss: 2.0046, Accuracy: 360/795 (45.28%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  6 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.931116, CORAL loss: 0.765826, Total_Loss: 0.931116\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  6 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.700708, CORAL loss: 0.188791, Total_Loss: 0.700708\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  6 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.475539, CORAL loss: 0.132709, Total_Loss: 0.475539\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  6 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.571771, CORAL loss: 0.182785, Total_Loss: 0.571771\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  6 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.662705, CORAL loss: 0.122014, Total_Loss: 0.662705\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  6 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.387309, CORAL loss: 0.243523, Total_Loss: 0.387309\n",
            "[EPOCH] 6: Classification loss: 0.621525, CORAL loss: 0.272608, Total_Loss: 0.621525\n",
            "[Test Source]: Epoch: 6, avg_loss: 0.4604, Accuracy: 2478/2817 (87.97%)\n",
            "[Test Target]: Epoch: 6, avg_loss: 1.8871, Accuracy: 369/795 (46.42%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  7 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.435182, CORAL loss: 0.055483, Total_Loss: 0.435182\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  7 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.504031, CORAL loss: 0.122455, Total_Loss: 0.504031\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  7 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.537815, CORAL loss: 0.126519, Total_Loss: 0.537815\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  7 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.540366, CORAL loss: 0.121376, Total_Loss: 0.540366\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  7 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.457351, CORAL loss: 0.151475, Total_Loss: 0.457351\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  7 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.417919, CORAL loss: 0.092396, Total_Loss: 0.417919\n",
            "[EPOCH] 7: Classification loss: 0.482111, CORAL loss: 0.111617, Total_Loss: 0.482111\n",
            "[Test Source]: Epoch: 7, avg_loss: 0.4163, Accuracy: 2513/2817 (89.21%)\n",
            "[Test Target]: Epoch: 7, avg_loss: 2.0218, Accuracy: 335/795 (42.14%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  8 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.417490, CORAL loss: 0.160353, Total_Loss: 0.417490\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  8 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.447687, CORAL loss: 0.098484, Total_Loss: 0.447687\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  8 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.478244, CORAL loss: 0.193035, Total_Loss: 0.478244\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  8 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.511481, CORAL loss: 0.103689, Total_Loss: 0.511481\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  8 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.449819, CORAL loss: 0.193817, Total_Loss: 0.449819\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  8 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.556101, CORAL loss: 0.293804, Total_Loss: 0.556101\n",
            "[EPOCH] 8: Classification loss: 0.476804, CORAL loss: 0.173864, Total_Loss: 0.476804\n",
            "[Test Source]: Epoch: 8, avg_loss: 0.3526, Accuracy: 2567/2817 (91.13%)\n",
            "[Test Target]: Epoch: 8, avg_loss: 1.9460, Accuracy: 349/795 (43.90%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  9 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.588547, CORAL loss: 0.103903, Total_Loss: 0.588547\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  9 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.552973, CORAL loss: 0.206826, Total_Loss: 0.552973\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  9 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.238850, CORAL loss: 0.264833, Total_Loss: 0.238850\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  9 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.429807, CORAL loss: 0.193382, Total_Loss: 0.429807\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  9 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.439153, CORAL loss: 0.272001, Total_Loss: 0.439153\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch:  9 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.329715, CORAL loss: 0.173732, Total_Loss: 0.329715\n",
            "[EPOCH] 9: Classification loss: 0.429841, CORAL loss: 0.202446, Total_Loss: 0.429841\n",
            "[Test Source]: Epoch: 9, avg_loss: 0.2941, Accuracy: 2610/2817 (92.65%)\n",
            "[Test Target]: Epoch: 9, avg_loss: 1.9671, Accuracy: 354/795 (44.53%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 10 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.328125, CORAL loss: 0.347254, Total_Loss: 0.328125\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 10 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.275970, CORAL loss: 0.320184, Total_Loss: 0.275970\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 10 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.207825, CORAL loss: 0.229291, Total_Loss: 0.207825\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 10 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.469661, CORAL loss: 0.226415, Total_Loss: 0.469661\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 10 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.343738, CORAL loss: 0.236991, Total_Loss: 0.343738\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 10 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.320375, CORAL loss: 0.256416, Total_Loss: 0.320375\n",
            "[EPOCH] 10: Classification loss: 0.324282, CORAL loss: 0.269425, Total_Loss: 0.324282\n",
            "[Test Source]: Epoch: 10, avg_loss: 0.2759, Accuracy: 2625/2817 (93.18%)\n",
            "[Test Target]: Epoch: 10, avg_loss: 2.0086, Accuracy: 345/795 (43.40%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 11 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.247813, CORAL loss: 0.278110, Total_Loss: 0.247813\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 11 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.344092, CORAL loss: 0.296498, Total_Loss: 0.344092\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 11 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.309051, CORAL loss: 0.207902, Total_Loss: 0.309051\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 11 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.529594, CORAL loss: 0.242100, Total_Loss: 0.529594\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 11 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.470370, CORAL loss: 0.215786, Total_Loss: 0.470370\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 11 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.376212, CORAL loss: 0.351337, Total_Loss: 0.376212\n",
            "[EPOCH] 11: Classification loss: 0.379522, CORAL loss: 0.265289, Total_Loss: 0.379522\n",
            "[Test Source]: Epoch: 11, avg_loss: 0.2310, Accuracy: 2656/2817 (94.28%)\n",
            "[Test Target]: Epoch: 11, avg_loss: 2.0819, Accuracy: 336/795 (42.26%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 12 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.248729, CORAL loss: 0.277228, Total_Loss: 0.248729\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 12 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.379604, CORAL loss: 0.260729, Total_Loss: 0.379604\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 12 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.280413, CORAL loss: 0.247657, Total_Loss: 0.280413\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 12 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.427168, CORAL loss: 0.191315, Total_Loss: 0.427168\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 12 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.303088, CORAL loss: 0.334398, Total_Loss: 0.303088\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 12 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.304530, CORAL loss: 0.228514, Total_Loss: 0.304530\n",
            "[EPOCH] 12: Classification loss: 0.323922, CORAL loss: 0.256640, Total_Loss: 0.323922\n",
            "[Test Source]: Epoch: 12, avg_loss: 0.2072, Accuracy: 2661/2817 (94.46%)\n",
            "[Test Target]: Epoch: 12, avg_loss: 2.0979, Accuracy: 336/795 (42.26%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 13 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.408845, CORAL loss: 0.180705, Total_Loss: 0.408845\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 13 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.172935, CORAL loss: 0.209781, Total_Loss: 0.172935\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 13 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.307262, CORAL loss: 0.237283, Total_Loss: 0.307262\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 13 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.309475, CORAL loss: 0.370517, Total_Loss: 0.309475\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 13 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.265277, CORAL loss: 0.196214, Total_Loss: 0.265277\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 13 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.281189, CORAL loss: 0.232078, Total_Loss: 0.281189\n",
            "[EPOCH] 13: Classification loss: 0.290830, CORAL loss: 0.237763, Total_Loss: 0.290830\n",
            "[Test Source]: Epoch: 13, avg_loss: 0.1821, Accuracy: 2691/2817 (95.53%)\n",
            "[Test Target]: Epoch: 13, avg_loss: 2.1007, Accuracy: 335/795 (42.14%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 14 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.265907, CORAL loss: 0.259740, Total_Loss: 0.265907\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 14 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.244155, CORAL loss: 0.268199, Total_Loss: 0.244155\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 14 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.311774, CORAL loss: 0.296328, Total_Loss: 0.311774\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 14 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.294193, CORAL loss: 0.234830, Total_Loss: 0.294193\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 14 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.289716, CORAL loss: 0.216706, Total_Loss: 0.289716\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 14 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.156942, CORAL loss: 0.366566, Total_Loss: 0.156942\n",
            "[EPOCH] 14: Classification loss: 0.260448, CORAL loss: 0.273728, Total_Loss: 0.260448\n",
            "[Test Source]: Epoch: 14, avg_loss: 0.1669, Accuracy: 2700/2817 (95.85%)\n",
            "[Test Target]: Epoch: 14, avg_loss: 2.1036, Accuracy: 337/795 (42.39%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 15 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.248248, CORAL loss: 0.314098, Total_Loss: 0.248248\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 15 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.220539, CORAL loss: 0.749274, Total_Loss: 0.220539\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 15 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.258418, CORAL loss: 0.404237, Total_Loss: 0.258418\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 15 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.189691, CORAL loss: 0.446225, Total_Loss: 0.189691\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 15 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.194004, CORAL loss: 0.383225, Total_Loss: 0.194004\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 15 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.286380, CORAL loss: 0.208184, Total_Loss: 0.286380\n",
            "[EPOCH] 15: Classification loss: 0.232880, CORAL loss: 0.417541, Total_Loss: 0.232880\n",
            "[Test Source]: Epoch: 15, avg_loss: 0.1472, Accuracy: 2712/2817 (96.27%)\n",
            "[Test Target]: Epoch: 15, avg_loss: 2.1381, Accuracy: 342/795 (43.02%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 16 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.105252, CORAL loss: 0.446295, Total_Loss: 0.105252\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 16 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.277568, CORAL loss: 0.303699, Total_Loss: 0.277568\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 16 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.213567, CORAL loss: 0.454295, Total_Loss: 0.213567\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 16 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.103681, CORAL loss: 0.273181, Total_Loss: 0.103681\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 16 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.179049, CORAL loss: 0.346659, Total_Loss: 0.179049\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 16 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.205467, CORAL loss: 0.195455, Total_Loss: 0.205467\n",
            "[EPOCH] 16: Classification loss: 0.180764, CORAL loss: 0.336597, Total_Loss: 0.180764\n",
            "[Test Source]: Epoch: 16, avg_loss: 0.1366, Accuracy: 2724/2817 (96.70%)\n",
            "[Test Target]: Epoch: 16, avg_loss: 2.3088, Accuracy: 328/795 (41.26%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 17 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.220466, CORAL loss: 0.260569, Total_Loss: 0.220466\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 17 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.179926, CORAL loss: 0.459069, Total_Loss: 0.179926\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 17 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.220717, CORAL loss: 0.328868, Total_Loss: 0.220717\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 17 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.261883, CORAL loss: 0.943822, Total_Loss: 0.261883\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 17 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.194127, CORAL loss: 0.426705, Total_Loss: 0.194127\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 17 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.170938, CORAL loss: 0.373946, Total_Loss: 0.170938\n",
            "[EPOCH] 17: Classification loss: 0.208009, CORAL loss: 0.465497, Total_Loss: 0.208009\n",
            "[Test Source]: Epoch: 17, avg_loss: 0.1113, Accuracy: 2737/2817 (97.16%)\n",
            "[Test Target]: Epoch: 17, avg_loss: 2.1946, Accuracy: 330/795 (41.51%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 18 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.193687, CORAL loss: 0.652525, Total_Loss: 0.193687\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 18 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.121287, CORAL loss: 0.701793, Total_Loss: 0.121287\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 18 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.150058, CORAL loss: 0.278693, Total_Loss: 0.150058\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 18 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.226635, CORAL loss: 0.222425, Total_Loss: 0.226635\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 18 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.112756, CORAL loss: 0.308888, Total_Loss: 0.112756\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 18 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.243039, CORAL loss: 0.958724, Total_Loss: 0.243039\n",
            "[EPOCH] 18: Classification loss: 0.174577, CORAL loss: 0.520508, Total_Loss: 0.174577\n",
            "[Test Source]: Epoch: 18, avg_loss: 0.0970, Accuracy: 2752/2817 (97.69%)\n",
            "[Test Target]: Epoch: 18, avg_loss: 2.0321, Accuracy: 356/795 (44.78%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 19 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.165377, CORAL loss: 0.509033, Total_Loss: 0.165377\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 19 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.197991, CORAL loss: 0.924105, Total_Loss: 0.197991\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 19 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.149028, CORAL loss: 0.771429, Total_Loss: 0.149028\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 19 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.153032, CORAL loss: 0.438803, Total_Loss: 0.153032\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 19 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.196322, CORAL loss: 0.695141, Total_Loss: 0.196322\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 19 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.197439, CORAL loss: 0.223278, Total_Loss: 0.197439\n",
            "[EPOCH] 19: Classification loss: 0.176531, CORAL loss: 0.593631, Total_Loss: 0.176531\n",
            "[Test Source]: Epoch: 19, avg_loss: 0.0820, Accuracy: 2760/2817 (97.98%)\n",
            "[Test Target]: Epoch: 19, avg_loss: 2.0635, Accuracy: 370/795 (46.54%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 20 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.138720, CORAL loss: 0.639238, Total_Loss: 0.138720\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 20 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.154416, CORAL loss: 0.882655, Total_Loss: 0.154416\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 20 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.112739, CORAL loss: 0.349407, Total_Loss: 0.112739\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 20 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.148873, CORAL loss: 0.649959, Total_Loss: 0.148873\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 20 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.128175, CORAL loss: 0.530730, Total_Loss: 0.128175\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 20 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.181412, CORAL loss: 0.648714, Total_Loss: 0.181412\n",
            "[EPOCH] 20: Classification loss: 0.144056, CORAL loss: 0.616784, Total_Loss: 0.144056\n",
            "[Test Source]: Epoch: 20, avg_loss: 0.0690, Accuracy: 2770/2817 (98.33%)\n",
            "[Test Target]: Epoch: 20, avg_loss: 2.1547, Accuracy: 374/795 (47.04%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 21 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.213694, CORAL loss: 0.804477, Total_Loss: 0.213694\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 21 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.113556, CORAL loss: 0.657911, Total_Loss: 0.113556\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 21 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.116755, CORAL loss: 0.306092, Total_Loss: 0.116755\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 21 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.090375, CORAL loss: 0.539904, Total_Loss: 0.090375\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 21 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.096792, CORAL loss: 0.899995, Total_Loss: 0.096792\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 21 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.183030, CORAL loss: 0.270671, Total_Loss: 0.183030\n",
            "[EPOCH] 21: Classification loss: 0.135700, CORAL loss: 0.579842, Total_Loss: 0.135700\n",
            "[Test Source]: Epoch: 21, avg_loss: 0.0584, Accuracy: 2779/2817 (98.65%)\n",
            "[Test Target]: Epoch: 21, avg_loss: 2.2645, Accuracy: 348/795 (43.77%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 22 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.150048, CORAL loss: 0.519666, Total_Loss: 0.150048\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 22 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.128321, CORAL loss: 0.575576, Total_Loss: 0.128321\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 22 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.158599, CORAL loss: 1.339466, Total_Loss: 0.158599\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 22 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.103189, CORAL loss: 0.557260, Total_Loss: 0.103189\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 22 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.063779, CORAL loss: 0.814144, Total_Loss: 0.063779\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 22 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.118653, CORAL loss: 0.701686, Total_Loss: 0.118653\n",
            "[EPOCH] 22: Classification loss: 0.120432, CORAL loss: 0.751300, Total_Loss: 0.120432\n",
            "[Test Source]: Epoch: 22, avg_loss: 0.0470, Accuracy: 2794/2817 (99.18%)\n",
            "[Test Target]: Epoch: 22, avg_loss: 2.1507, Accuracy: 345/795 (43.40%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 23 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.069294, CORAL loss: 0.289835, Total_Loss: 0.069294\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 23 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.129048, CORAL loss: 0.708628, Total_Loss: 0.129048\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 23 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.108698, CORAL loss: 0.730939, Total_Loss: 0.108698\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 23 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.085570, CORAL loss: 0.741809, Total_Loss: 0.085570\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 23 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.084807, CORAL loss: 0.783864, Total_Loss: 0.084807\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 23 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.179172, CORAL loss: 0.984686, Total_Loss: 0.179172\n",
            "[EPOCH] 23: Classification loss: 0.109432, CORAL loss: 0.706627, Total_Loss: 0.109432\n",
            "[Test Source]: Epoch: 23, avg_loss: 0.0503, Accuracy: 2786/2817 (98.90%)\n",
            "[Test Target]: Epoch: 23, avg_loss: 2.2047, Accuracy: 353/795 (44.40%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 24 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.105550, CORAL loss: 0.545298, Total_Loss: 0.105550\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 24 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.063297, CORAL loss: 0.526347, Total_Loss: 0.063297\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 24 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.061348, CORAL loss: 1.008819, Total_Loss: 0.061348\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 24 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.270838, CORAL loss: 0.674200, Total_Loss: 0.270838\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 24 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.066418, CORAL loss: 0.756956, Total_Loss: 0.066418\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 24 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.054341, CORAL loss: 0.596648, Total_Loss: 0.054341\n",
            "[EPOCH] 24: Classification loss: 0.103632, CORAL loss: 0.684711, Total_Loss: 0.103632\n",
            "[Test Source]: Epoch: 24, avg_loss: 0.0435, Accuracy: 2792/2817 (99.11%)\n",
            "[Test Target]: Epoch: 24, avg_loss: 2.3133, Accuracy: 362/795 (45.53%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 25 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.094314, CORAL loss: 0.644351, Total_Loss: 0.094314\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 25 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.049864, CORAL loss: 0.800746, Total_Loss: 0.049864\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 25 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.095310, CORAL loss: 0.685065, Total_Loss: 0.095310\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 25 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.098763, CORAL loss: 0.710486, Total_Loss: 0.098763\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 25 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.134021, CORAL loss: 1.077862, Total_Loss: 0.134021\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 25 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.063535, CORAL loss: 0.574990, Total_Loss: 0.063535\n",
            "[EPOCH] 25: Classification loss: 0.089301, CORAL loss: 0.748917, Total_Loss: 0.089301\n",
            "[Test Source]: Epoch: 25, avg_loss: 0.0358, Accuracy: 2796/2817 (99.25%)\n",
            "[Test Target]: Epoch: 25, avg_loss: 2.4033, Accuracy: 348/795 (43.77%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 26 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.066671, CORAL loss: 0.699999, Total_Loss: 0.066671\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 26 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.045919, CORAL loss: 1.438404, Total_Loss: 0.045919\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 26 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.049251, CORAL loss: 1.265409, Total_Loss: 0.049251\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 26 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.087435, CORAL loss: 0.489718, Total_Loss: 0.087435\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 26 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.062285, CORAL loss: 1.073169, Total_Loss: 0.062285\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 26 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.098158, CORAL loss: 1.216782, Total_Loss: 0.098158\n",
            "[EPOCH] 26: Classification loss: 0.068286, CORAL loss: 1.030580, Total_Loss: 0.068286\n",
            "[Test Source]: Epoch: 26, avg_loss: 0.0287, Accuracy: 2801/2817 (99.43%)\n",
            "[Test Target]: Epoch: 26, avg_loss: 2.3268, Accuracy: 349/795 (43.90%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 27 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.075740, CORAL loss: 0.623627, Total_Loss: 0.075740\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 27 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.074871, CORAL loss: 0.931432, Total_Loss: 0.074871\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 27 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.052521, CORAL loss: 1.002931, Total_Loss: 0.052521\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 27 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.124365, CORAL loss: 1.148303, Total_Loss: 0.124365\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 27 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.105342, CORAL loss: 1.067177, Total_Loss: 0.105342\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 27 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.050563, CORAL loss: 1.326952, Total_Loss: 0.050563\n",
            "[EPOCH] 27: Classification loss: 0.080567, CORAL loss: 1.016737, Total_Loss: 0.080567\n",
            "[Test Source]: Epoch: 27, avg_loss: 0.0303, Accuracy: 2797/2817 (99.29%)\n",
            "[Test Target]: Epoch: 27, avg_loss: 2.3026, Accuracy: 360/795 (45.28%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 28 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.068626, CORAL loss: 0.589099, Total_Loss: 0.068626\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 28 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.062373, CORAL loss: 1.477869, Total_Loss: 0.062373\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 28 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.040960, CORAL loss: 1.003929, Total_Loss: 0.040960\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 28 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.093587, CORAL loss: 1.330347, Total_Loss: 0.093587\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 28 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.085870, CORAL loss: 1.047806, Total_Loss: 0.085870\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 28 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.121135, CORAL loss: 1.755169, Total_Loss: 0.121135\n",
            "[EPOCH] 28: Classification loss: 0.078759, CORAL loss: 1.200703, Total_Loss: 0.078759\n",
            "[Test Source]: Epoch: 28, avg_loss: 0.0284, Accuracy: 2798/2817 (99.33%)\n",
            "[Test Target]: Epoch: 28, avg_loss: 2.2359, Accuracy: 382/795 (48.05%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 29 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.060223, CORAL loss: 2.563475, Total_Loss: 0.060223\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 29 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.107451, CORAL loss: 1.174234, Total_Loss: 0.107451\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 29 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.048053, CORAL loss: 0.609628, Total_Loss: 0.048053\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 29 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.028035, CORAL loss: 1.606895, Total_Loss: 0.028035\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 29 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.053120, CORAL loss: 1.002918, Total_Loss: 0.053120\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 29 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.047155, CORAL loss: 0.907715, Total_Loss: 0.047155\n",
            "[EPOCH] 29: Classification loss: 0.057340, CORAL loss: 1.310811, Total_Loss: 0.057340\n",
            "[Test Source]: Epoch: 29, avg_loss: 0.0278, Accuracy: 2802/2817 (99.47%)\n",
            "[Test Target]: Epoch: 29, avg_loss: 2.2264, Accuracy: 376/795 (47.30%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 30 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.095209, CORAL loss: 0.870196, Total_Loss: 0.095209\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 30 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.076492, CORAL loss: 1.095535, Total_Loss: 0.076492\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 30 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.043293, CORAL loss: 0.812257, Total_Loss: 0.043293\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 30 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.067496, CORAL loss: 0.867187, Total_Loss: 0.067496\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 30 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.139257, CORAL loss: 1.139859, Total_Loss: 0.139257\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 30 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.043528, CORAL loss: 0.920499, Total_Loss: 0.043528\n",
            "[EPOCH] 30: Classification loss: 0.077546, CORAL loss: 0.950922, Total_Loss: 0.077546\n",
            "[Test Source]: Epoch: 30, avg_loss: 0.0231, Accuracy: 2803/2817 (99.50%)\n",
            "[Test Target]: Epoch: 30, avg_loss: 2.3481, Accuracy: 356/795 (44.78%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 31 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.036544, CORAL loss: 1.229503, Total_Loss: 0.036544\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 31 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.094464, CORAL loss: 0.819741, Total_Loss: 0.094464\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 31 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.065167, CORAL loss: 0.655895, Total_Loss: 0.065167\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 31 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.091303, CORAL loss: 0.538177, Total_Loss: 0.091303\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 31 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.076969, CORAL loss: 0.857061, Total_Loss: 0.076969\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 31 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.045754, CORAL loss: 1.183320, Total_Loss: 0.045754\n",
            "[EPOCH] 31: Classification loss: 0.068367, CORAL loss: 0.880616, Total_Loss: 0.068367\n",
            "[Test Source]: Epoch: 31, avg_loss: 0.0261, Accuracy: 2804/2817 (99.54%)\n",
            "[Test Target]: Epoch: 31, avg_loss: 2.4447, Accuracy: 333/795 (41.89%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 32 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.064048, CORAL loss: 0.874506, Total_Loss: 0.064048\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 32 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.077612, CORAL loss: 0.735658, Total_Loss: 0.077612\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 32 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.076733, CORAL loss: 1.779446, Total_Loss: 0.076733\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 32 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.036122, CORAL loss: 0.905028, Total_Loss: 0.036122\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 32 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.062342, CORAL loss: 1.244494, Total_Loss: 0.062342\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 32 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.148525, CORAL loss: 1.964009, Total_Loss: 0.148525\n",
            "[EPOCH] 32: Classification loss: 0.077564, CORAL loss: 1.250524, Total_Loss: 0.077564\n",
            "[Test Source]: Epoch: 32, avg_loss: 0.0232, Accuracy: 2804/2817 (99.54%)\n",
            "[Test Target]: Epoch: 32, avg_loss: 2.2757, Accuracy: 370/795 (46.54%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 33 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.052234, CORAL loss: 1.996095, Total_Loss: 0.052234\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 33 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.160808, CORAL loss: 1.483236, Total_Loss: 0.160808\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 33 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.036904, CORAL loss: 0.577497, Total_Loss: 0.036904\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 33 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.034510, CORAL loss: 1.167126, Total_Loss: 0.034510\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 33 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.093380, CORAL loss: 1.005540, Total_Loss: 0.093380\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 33 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.088611, CORAL loss: 0.678522, Total_Loss: 0.088611\n",
            "[EPOCH] 33: Classification loss: 0.077741, CORAL loss: 1.151336, Total_Loss: 0.077741\n",
            "[Test Source]: Epoch: 33, avg_loss: 0.0186, Accuracy: 2806/2817 (99.61%)\n",
            "[Test Target]: Epoch: 33, avg_loss: 2.3116, Accuracy: 359/795 (45.16%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 34 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.070588, CORAL loss: 0.720210, Total_Loss: 0.070588\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 34 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.043845, CORAL loss: 1.285502, Total_Loss: 0.043845\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 34 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.031548, CORAL loss: 0.924981, Total_Loss: 0.031548\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 34 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.063665, CORAL loss: 1.334490, Total_Loss: 0.063665\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 34 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.048286, CORAL loss: 1.110843, Total_Loss: 0.048286\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 34 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.060815, CORAL loss: 0.408980, Total_Loss: 0.060815\n",
            "[EPOCH] 34: Classification loss: 0.053125, CORAL loss: 0.964168, Total_Loss: 0.053125\n",
            "[Test Source]: Epoch: 34, avg_loss: 0.0202, Accuracy: 2806/2817 (99.61%)\n",
            "[Test Target]: Epoch: 34, avg_loss: 2.4811, Accuracy: 331/795 (41.64%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 35 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.072970, CORAL loss: 0.872113, Total_Loss: 0.072970\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 35 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.038515, CORAL loss: 0.970539, Total_Loss: 0.038515\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 35 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.048812, CORAL loss: 0.721884, Total_Loss: 0.048812\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 35 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.095070, CORAL loss: 2.460585, Total_Loss: 0.095070\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 35 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.036542, CORAL loss: 1.370898, Total_Loss: 0.036542\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 35 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.016524, CORAL loss: 1.362659, Total_Loss: 0.016524\n",
            "[EPOCH] 35: Classification loss: 0.051405, CORAL loss: 1.293113, Total_Loss: 0.051405\n",
            "[Test Source]: Epoch: 35, avg_loss: 0.0119, Accuracy: 2810/2817 (99.75%)\n",
            "[Test Target]: Epoch: 35, avg_loss: 2.4945, Accuracy: 335/795 (42.14%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 36 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.064199, CORAL loss: 1.725094, Total_Loss: 0.064199\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 36 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.024543, CORAL loss: 1.410895, Total_Loss: 0.024543\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 36 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.041630, CORAL loss: 1.070558, Total_Loss: 0.041630\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 36 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.057460, CORAL loss: 1.667894, Total_Loss: 0.057460\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 36 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.078133, CORAL loss: 1.390521, Total_Loss: 0.078133\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 36 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.122032, CORAL loss: 0.946495, Total_Loss: 0.122032\n",
            "[EPOCH] 36: Classification loss: 0.064666, CORAL loss: 1.368576, Total_Loss: 0.064666\n",
            "[Test Source]: Epoch: 36, avg_loss: 0.0100, Accuracy: 2813/2817 (99.86%)\n",
            "[Test Target]: Epoch: 36, avg_loss: 2.4533, Accuracy: 346/795 (43.52%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 37 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.043645, CORAL loss: 0.996061, Total_Loss: 0.043645\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 37 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.027924, CORAL loss: 1.158296, Total_Loss: 0.027924\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 37 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.027462, CORAL loss: 0.938880, Total_Loss: 0.027462\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 37 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.074191, CORAL loss: 2.598385, Total_Loss: 0.074191\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 37 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.035721, CORAL loss: 1.056272, Total_Loss: 0.035721\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 37 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.072108, CORAL loss: 2.876757, Total_Loss: 0.072108\n",
            "[EPOCH] 37: Classification loss: 0.046842, CORAL loss: 1.604109, Total_Loss: 0.046842\n",
            "[Test Source]: Epoch: 37, avg_loss: 0.0094, Accuracy: 2814/2817 (99.89%)\n",
            "[Test Target]: Epoch: 37, avg_loss: 2.4912, Accuracy: 347/795 (43.65%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 38 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.056763, CORAL loss: 1.596501, Total_Loss: 0.056763\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 38 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.029864, CORAL loss: 1.370917, Total_Loss: 0.029864\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 38 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.031261, CORAL loss: 1.799096, Total_Loss: 0.031261\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 38 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.092413, CORAL loss: 1.063457, Total_Loss: 0.092413\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 38 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.030076, CORAL loss: 0.528887, Total_Loss: 0.030076\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 38 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.099420, CORAL loss: 1.215789, Total_Loss: 0.099420\n",
            "[EPOCH] 38: Classification loss: 0.056633, CORAL loss: 1.262441, Total_Loss: 0.056633\n",
            "[Test Source]: Epoch: 38, avg_loss: 0.0086, Accuracy: 2813/2817 (99.86%)\n",
            "[Test Target]: Epoch: 38, avg_loss: 2.5848, Accuracy: 335/795 (42.14%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 39 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.076014, CORAL loss: 1.213400, Total_Loss: 0.076014\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 39 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.041815, CORAL loss: 1.429334, Total_Loss: 0.041815\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 39 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.015626, CORAL loss: 1.381080, Total_Loss: 0.015626\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 39 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.018457, CORAL loss: 0.988707, Total_Loss: 0.018457\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 39 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.038377, CORAL loss: 1.451195, Total_Loss: 0.038377\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 39 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.092893, CORAL loss: 1.460707, Total_Loss: 0.092893\n",
            "[EPOCH] 39: Classification loss: 0.047197, CORAL loss: 1.320737, Total_Loss: 0.047197\n",
            "[Test Source]: Epoch: 39, avg_loss: 0.0114, Accuracy: 2813/2817 (99.86%)\n",
            "[Test Target]: Epoch: 39, avg_loss: 2.4371, Accuracy: 341/795 (42.89%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 40 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.059183, CORAL loss: 0.674920, Total_Loss: 0.059183\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 40 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.060881, CORAL loss: 1.128216, Total_Loss: 0.060881\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 40 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.050163, CORAL loss: 1.370329, Total_Loss: 0.050163\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 40 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.052231, CORAL loss: 1.104994, Total_Loss: 0.052231\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 40 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.067579, CORAL loss: 0.710276, Total_Loss: 0.067579\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 40 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.019425, CORAL loss: 1.344522, Total_Loss: 0.019425\n",
            "[EPOCH] 40: Classification loss: 0.051577, CORAL loss: 1.055543, Total_Loss: 0.051577\n",
            "[Test Source]: Epoch: 40, avg_loss: 0.0080, Accuracy: 2814/2817 (99.89%)\n",
            "[Test Target]: Epoch: 40, avg_loss: 2.3542, Accuracy: 347/795 (43.65%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 41 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.044418, CORAL loss: 1.684241, Total_Loss: 0.044418\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 41 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.051420, CORAL loss: 1.259842, Total_Loss: 0.051420\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 41 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.044440, CORAL loss: 0.826186, Total_Loss: 0.044440\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 41 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.034411, CORAL loss: 1.118932, Total_Loss: 0.034411\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 41 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.013868, CORAL loss: 2.647262, Total_Loss: 0.013868\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 41 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.055762, CORAL loss: 1.590122, Total_Loss: 0.055762\n",
            "[EPOCH] 41: Classification loss: 0.040720, CORAL loss: 1.521097, Total_Loss: 0.040720\n",
            "[Test Source]: Epoch: 41, avg_loss: 0.0069, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 41, avg_loss: 2.4727, Accuracy: 340/795 (42.77%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 42 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.025376, CORAL loss: 0.970225, Total_Loss: 0.025376\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 42 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.093704, CORAL loss: 1.819740, Total_Loss: 0.093704\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 42 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.039879, CORAL loss: 1.161600, Total_Loss: 0.039879\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 42 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.025965, CORAL loss: 1.653377, Total_Loss: 0.025965\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 42 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.031430, CORAL loss: 1.392439, Total_Loss: 0.031430\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 42 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.009036, CORAL loss: 1.279793, Total_Loss: 0.009036\n",
            "[EPOCH] 42: Classification loss: 0.037565, CORAL loss: 1.379529, Total_Loss: 0.037565\n",
            "[Test Source]: Epoch: 42, avg_loss: 0.0064, Accuracy: 2814/2817 (99.89%)\n",
            "[Test Target]: Epoch: 42, avg_loss: 2.4710, Accuracy: 332/795 (41.76%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 43 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.033295, CORAL loss: 1.829912, Total_Loss: 0.033295\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 43 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.034967, CORAL loss: 1.030016, Total_Loss: 0.034967\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 43 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.030122, CORAL loss: 1.918314, Total_Loss: 0.030122\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 43 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.028928, CORAL loss: 1.947160, Total_Loss: 0.028928\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 43 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.028252, CORAL loss: 1.652021, Total_Loss: 0.028252\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 43 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.030571, CORAL loss: 1.256987, Total_Loss: 0.030571\n",
            "[EPOCH] 43: Classification loss: 0.031022, CORAL loss: 1.605735, Total_Loss: 0.031022\n",
            "[Test Source]: Epoch: 43, avg_loss: 0.0077, Accuracy: 2813/2817 (99.86%)\n",
            "[Test Target]: Epoch: 43, avg_loss: 2.4635, Accuracy: 353/795 (44.40%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 44 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.032564, CORAL loss: 1.328205, Total_Loss: 0.032564\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 44 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.018300, CORAL loss: 1.823923, Total_Loss: 0.018300\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 44 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.026126, CORAL loss: 0.756835, Total_Loss: 0.026126\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 44 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.038581, CORAL loss: 0.847743, Total_Loss: 0.038581\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 44 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.015244, CORAL loss: 1.219137, Total_Loss: 0.015244\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 44 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.008064, CORAL loss: 1.156795, Total_Loss: 0.008064\n",
            "[EPOCH] 44: Classification loss: 0.023146, CORAL loss: 1.188773, Total_Loss: 0.023146\n",
            "[Test Source]: Epoch: 44, avg_loss: 0.0073, Accuracy: 2813/2817 (99.86%)\n",
            "[Test Target]: Epoch: 44, avg_loss: 2.4073, Accuracy: 362/795 (45.53%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 45 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.044025, CORAL loss: 1.434001, Total_Loss: 0.044025\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 45 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.061957, CORAL loss: 2.531760, Total_Loss: 0.061957\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 45 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.023951, CORAL loss: 2.142164, Total_Loss: 0.023951\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 45 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.019577, CORAL loss: 1.196324, Total_Loss: 0.019577\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 45 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.019174, CORAL loss: 1.899484, Total_Loss: 0.019174\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 45 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.017923, CORAL loss: 2.619659, Total_Loss: 0.017923\n",
            "[EPOCH] 45: Classification loss: 0.031101, CORAL loss: 1.970565, Total_Loss: 0.031101\n",
            "[Test Source]: Epoch: 45, avg_loss: 0.0071, Accuracy: 2813/2817 (99.86%)\n",
            "[Test Target]: Epoch: 45, avg_loss: 2.3766, Accuracy: 364/795 (45.79%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 46 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.013499, CORAL loss: 1.496631, Total_Loss: 0.013499\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 46 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.037309, CORAL loss: 1.168095, Total_Loss: 0.037309\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 46 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.025076, CORAL loss: 1.092359, Total_Loss: 0.025076\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 46 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.012891, CORAL loss: 2.958966, Total_Loss: 0.012891\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 46 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.020924, CORAL loss: 2.023342, Total_Loss: 0.020924\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 46 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.025645, CORAL loss: 1.913554, Total_Loss: 0.025645\n",
            "[EPOCH] 46: Classification loss: 0.022557, CORAL loss: 1.775491, Total_Loss: 0.022557\n",
            "[Test Source]: Epoch: 46, avg_loss: 0.0063, Accuracy: 2814/2817 (99.89%)\n",
            "[Test Target]: Epoch: 46, avg_loss: 2.4245, Accuracy: 370/795 (46.54%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 47 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.039249, CORAL loss: 1.770630, Total_Loss: 0.039249\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 47 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.078799, CORAL loss: 1.276802, Total_Loss: 0.078799\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 47 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.013485, CORAL loss: 1.931527, Total_Loss: 0.013485\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 47 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.018664, CORAL loss: 2.213318, Total_Loss: 0.018664\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 47 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.040783, CORAL loss: 1.682244, Total_Loss: 0.040783\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 47 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.042607, CORAL loss: 1.477685, Total_Loss: 0.042607\n",
            "[EPOCH] 47: Classification loss: 0.038931, CORAL loss: 1.725368, Total_Loss: 0.038931\n",
            "[Test Source]: Epoch: 47, avg_loss: 0.0048, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 47, avg_loss: 2.5819, Accuracy: 337/795 (42.39%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 48 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.034154, CORAL loss: 3.657321, Total_Loss: 0.034154\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 48 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.031448, CORAL loss: 1.920462, Total_Loss: 0.031448\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 48 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.042740, CORAL loss: 1.327011, Total_Loss: 0.042740\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 48 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.070882, CORAL loss: 1.244261, Total_Loss: 0.070882\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 48 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.042840, CORAL loss: 1.437889, Total_Loss: 0.042840\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 48 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.025735, CORAL loss: 2.541812, Total_Loss: 0.025735\n",
            "[EPOCH] 48: Classification loss: 0.041300, CORAL loss: 2.021459, Total_Loss: 0.041300\n",
            "[Test Source]: Epoch: 48, avg_loss: 0.0047, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 48, avg_loss: 2.5545, Accuracy: 342/795 (43.02%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 49 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.025820, CORAL loss: 1.472479, Total_Loss: 0.025820\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 49 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.031399, CORAL loss: 1.729791, Total_Loss: 0.031399\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 49 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.028254, CORAL loss: 1.667252, Total_Loss: 0.028254\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 49 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.014679, CORAL loss: 4.522742, Total_Loss: 0.014679\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 49 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.016223, CORAL loss: 1.199107, Total_Loss: 0.016223\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 49 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.033648, CORAL loss: 1.588598, Total_Loss: 0.033648\n",
            "[EPOCH] 49: Classification loss: 0.025004, CORAL loss: 2.029995, Total_Loss: 0.025004\n",
            "[Test Source]: Epoch: 49, avg_loss: 0.0048, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 49, avg_loss: 2.4117, Accuracy: 342/795 (43.02%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 50 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.012073, CORAL loss: 1.689658, Total_Loss: 0.012073\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 50 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.023006, CORAL loss: 1.642832, Total_Loss: 0.023006\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 50 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.041373, CORAL loss: 1.628857, Total_Loss: 0.041373\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 50 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.036259, CORAL loss: 1.382709, Total_Loss: 0.036259\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 50 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.044110, CORAL loss: 1.484918, Total_Loss: 0.044110\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 50 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.013962, CORAL loss: 1.074482, Total_Loss: 0.013962\n",
            "[EPOCH] 50: Classification loss: 0.028464, CORAL loss: 1.483909, Total_Loss: 0.028464\n",
            "[Test Source]: Epoch: 50, avg_loss: 0.0053, Accuracy: 2814/2817 (99.89%)\n",
            "[Test Target]: Epoch: 50, avg_loss: 2.4098, Accuracy: 349/795 (43.90%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 51 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.027546, CORAL loss: 1.793119, Total_Loss: 0.027546\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 51 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.015041, CORAL loss: 2.239063, Total_Loss: 0.015041\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 51 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.052907, CORAL loss: 2.044130, Total_Loss: 0.052907\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 51 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.023070, CORAL loss: 1.736803, Total_Loss: 0.023070\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 51 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.029680, CORAL loss: 1.134906, Total_Loss: 0.029680\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 51 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.020405, CORAL loss: 1.686069, Total_Loss: 0.020405\n",
            "[EPOCH] 51: Classification loss: 0.028108, CORAL loss: 1.772348, Total_Loss: 0.028108\n",
            "[Test Source]: Epoch: 51, avg_loss: 0.0038, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 51, avg_loss: 2.4696, Accuracy: 344/795 (43.27%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 52 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.023564, CORAL loss: 1.653606, Total_Loss: 0.023564\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 52 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.008048, CORAL loss: 1.728021, Total_Loss: 0.008048\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 52 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.024204, CORAL loss: 2.534506, Total_Loss: 0.024204\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 52 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.042149, CORAL loss: 1.567457, Total_Loss: 0.042149\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 52 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.024106, CORAL loss: 1.786174, Total_Loss: 0.024106\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 52 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.027743, CORAL loss: 1.855079, Total_Loss: 0.027743\n",
            "[EPOCH] 52: Classification loss: 0.024969, CORAL loss: 1.854140, Total_Loss: 0.024969\n",
            "[Test Source]: Epoch: 52, avg_loss: 0.0027, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 52, avg_loss: 2.5369, Accuracy: 343/795 (43.14%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 53 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.025037, CORAL loss: 1.764507, Total_Loss: 0.025037\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 53 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.014192, CORAL loss: 1.821824, Total_Loss: 0.014192\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 53 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.017150, CORAL loss: 3.100362, Total_Loss: 0.017150\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 53 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.040078, CORAL loss: 2.738741, Total_Loss: 0.040078\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 53 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.036229, CORAL loss: 2.328782, Total_Loss: 0.036229\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 53 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.018941, CORAL loss: 1.206124, Total_Loss: 0.018941\n",
            "[EPOCH] 53: Classification loss: 0.025271, CORAL loss: 2.160057, Total_Loss: 0.025271\n",
            "[Test Source]: Epoch: 53, avg_loss: 0.0025, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 53, avg_loss: 2.6393, Accuracy: 331/795 (41.64%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 54 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.015433, CORAL loss: 2.108471, Total_Loss: 0.015433\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 54 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.015016, CORAL loss: 1.037701, Total_Loss: 0.015016\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 54 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.010657, CORAL loss: 1.915396, Total_Loss: 0.010657\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 54 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.023614, CORAL loss: 1.657988, Total_Loss: 0.023614\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 54 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.015626, CORAL loss: 2.047956, Total_Loss: 0.015626\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 54 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.016778, CORAL loss: 1.778439, Total_Loss: 0.016778\n",
            "[EPOCH] 54: Classification loss: 0.016187, CORAL loss: 1.757658, Total_Loss: 0.016187\n",
            "[Test Source]: Epoch: 54, avg_loss: 0.0024, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 54, avg_loss: 2.5688, Accuracy: 347/795 (43.65%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 55 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.023775, CORAL loss: 1.994459, Total_Loss: 0.023775\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 55 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.023940, CORAL loss: 1.564719, Total_Loss: 0.023940\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 55 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.024307, CORAL loss: 2.337698, Total_Loss: 0.024307\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 55 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.029283, CORAL loss: 1.803346, Total_Loss: 0.029283\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 55 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.006909, CORAL loss: 2.631511, Total_Loss: 0.006909\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 55 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.019197, CORAL loss: 1.646163, Total_Loss: 0.019197\n",
            "[EPOCH] 55: Classification loss: 0.021235, CORAL loss: 1.996316, Total_Loss: 0.021235\n",
            "[Test Source]: Epoch: 55, avg_loss: 0.0025, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 55, avg_loss: 2.5333, Accuracy: 350/795 (44.03%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 56 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.005725, CORAL loss: 1.820305, Total_Loss: 0.005725\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 56 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.016327, CORAL loss: 1.425511, Total_Loss: 0.016327\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 56 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.027371, CORAL loss: 2.013447, Total_Loss: 0.027371\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 56 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.026431, CORAL loss: 1.483222, Total_Loss: 0.026431\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 56 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.013895, CORAL loss: 4.306452, Total_Loss: 0.013895\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 56 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.004608, CORAL loss: 2.561596, Total_Loss: 0.004608\n",
            "[EPOCH] 56: Classification loss: 0.015726, CORAL loss: 2.268422, Total_Loss: 0.015726\n",
            "[Test Source]: Epoch: 56, avg_loss: 0.0029, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 56, avg_loss: 2.4763, Accuracy: 354/795 (44.53%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 57 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.015669, CORAL loss: 1.300935, Total_Loss: 0.015669\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 57 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.011394, CORAL loss: 3.597130, Total_Loss: 0.011394\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 57 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.021512, CORAL loss: 2.113938, Total_Loss: 0.021512\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 57 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.015603, CORAL loss: 2.393047, Total_Loss: 0.015603\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 57 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.012321, CORAL loss: 3.389541, Total_Loss: 0.012321\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 57 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.039867, CORAL loss: 1.690914, Total_Loss: 0.039867\n",
            "[EPOCH] 57: Classification loss: 0.019394, CORAL loss: 2.414251, Total_Loss: 0.019394\n",
            "[Test Source]: Epoch: 57, avg_loss: 0.0026, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 57, avg_loss: 2.5313, Accuracy: 359/795 (45.16%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 58 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.013193, CORAL loss: 1.715520, Total_Loss: 0.013193\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 58 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.011515, CORAL loss: 1.543194, Total_Loss: 0.011515\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 58 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.006114, CORAL loss: 1.996688, Total_Loss: 0.006114\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 58 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.018544, CORAL loss: 1.667560, Total_Loss: 0.018544\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 58 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.014120, CORAL loss: 5.089103, Total_Loss: 0.014120\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 58 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.012071, CORAL loss: 1.908508, Total_Loss: 0.012071\n",
            "[EPOCH] 58: Classification loss: 0.012593, CORAL loss: 2.320095, Total_Loss: 0.012593\n",
            "[Test Source]: Epoch: 58, avg_loss: 0.0020, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 58, avg_loss: 2.6070, Accuracy: 351/795 (44.15%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 59 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.039689, CORAL loss: 1.436129, Total_Loss: 0.039689\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 59 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.012679, CORAL loss: 1.790700, Total_Loss: 0.012679\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 59 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.009264, CORAL loss: 2.597441, Total_Loss: 0.009264\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 59 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.023130, CORAL loss: 2.830982, Total_Loss: 0.023130\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 59 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.033022, CORAL loss: 1.859998, Total_Loss: 0.033022\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 59 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.016372, CORAL loss: 1.627324, Total_Loss: 0.016372\n",
            "[EPOCH] 59: Classification loss: 0.022359, CORAL loss: 2.023762, Total_Loss: 0.022359\n",
            "[Test Source]: Epoch: 59, avg_loss: 0.0020, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 59, avg_loss: 2.6643, Accuracy: 351/795 (44.15%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 60 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.012363, CORAL loss: 2.207998, Total_Loss: 0.012363\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 60 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.021478, CORAL loss: 2.326525, Total_Loss: 0.021478\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 60 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.008198, CORAL loss: 2.119328, Total_Loss: 0.008198\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 60 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.011849, CORAL loss: 1.925537, Total_Loss: 0.011849\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 60 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.011485, CORAL loss: 1.588875, Total_Loss: 0.011485\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 60 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.004852, CORAL loss: 1.197085, Total_Loss: 0.004852\n",
            "[EPOCH] 60: Classification loss: 0.011704, CORAL loss: 1.894225, Total_Loss: 0.011704\n",
            "[Test Source]: Epoch: 60, avg_loss: 0.0017, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 60, avg_loss: 2.6380, Accuracy: 338/795 (42.52%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 61 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.017616, CORAL loss: 2.315479, Total_Loss: 0.017616\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 61 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.024883, CORAL loss: 2.940768, Total_Loss: 0.024883\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 61 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.013143, CORAL loss: 2.320565, Total_Loss: 0.013143\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 61 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.020035, CORAL loss: 2.273698, Total_Loss: 0.020035\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 61 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.019072, CORAL loss: 2.417249, Total_Loss: 0.019072\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 61 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.015855, CORAL loss: 3.519504, Total_Loss: 0.015855\n",
            "[EPOCH] 61: Classification loss: 0.018434, CORAL loss: 2.631211, Total_Loss: 0.018434\n",
            "[Test Source]: Epoch: 61, avg_loss: 0.0016, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 61, avg_loss: 2.6577, Accuracy: 343/795 (43.14%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 62 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.007572, CORAL loss: 2.964912, Total_Loss: 0.007572\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 62 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.016380, CORAL loss: 1.344497, Total_Loss: 0.016380\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 62 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.007196, CORAL loss: 1.764285, Total_Loss: 0.007196\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 62 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.030456, CORAL loss: 2.269261, Total_Loss: 0.030456\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 62 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.031092, CORAL loss: 1.640259, Total_Loss: 0.031092\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 62 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.007420, CORAL loss: 2.337931, Total_Loss: 0.007420\n",
            "[EPOCH] 62: Classification loss: 0.016686, CORAL loss: 2.053524, Total_Loss: 0.016686\n",
            "[Test Source]: Epoch: 62, avg_loss: 0.0016, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 62, avg_loss: 2.6450, Accuracy: 345/795 (43.40%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 63 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.023134, CORAL loss: 3.004412, Total_Loss: 0.023134\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 63 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.012017, CORAL loss: 2.190077, Total_Loss: 0.012017\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 63 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.009262, CORAL loss: 2.188489, Total_Loss: 0.009262\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 63 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.022459, CORAL loss: 1.246378, Total_Loss: 0.022459\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 63 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.030757, CORAL loss: 2.138465, Total_Loss: 0.030757\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 63 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.023168, CORAL loss: 2.289119, Total_Loss: 0.023168\n",
            "[EPOCH] 63: Classification loss: 0.020133, CORAL loss: 2.176157, Total_Loss: 0.020133\n",
            "[Test Source]: Epoch: 63, avg_loss: 0.0016, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 63, avg_loss: 2.7907, Accuracy: 344/795 (43.27%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 64 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.008841, CORAL loss: 2.136739, Total_Loss: 0.008841\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 64 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.018414, CORAL loss: 2.321601, Total_Loss: 0.018414\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 64 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.020921, CORAL loss: 1.774718, Total_Loss: 0.020921\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 64 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.005874, CORAL loss: 2.597856, Total_Loss: 0.005874\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 64 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.008589, CORAL loss: 3.132980, Total_Loss: 0.008589\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 64 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.008992, CORAL loss: 2.546718, Total_Loss: 0.008992\n",
            "[EPOCH] 64: Classification loss: 0.011938, CORAL loss: 2.418436, Total_Loss: 0.011938\n",
            "[Test Source]: Epoch: 64, avg_loss: 0.0013, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 64, avg_loss: 2.7657, Accuracy: 346/795 (43.52%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 65 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.013161, CORAL loss: 1.676903, Total_Loss: 0.013161\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 65 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.009042, CORAL loss: 1.610198, Total_Loss: 0.009042\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 65 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.007899, CORAL loss: 2.349051, Total_Loss: 0.007899\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 65 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.022220, CORAL loss: 2.391650, Total_Loss: 0.022220\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 65 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.006922, CORAL loss: 1.637274, Total_Loss: 0.006922\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 65 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.033106, CORAL loss: 3.161194, Total_Loss: 0.033106\n",
            "[EPOCH] 65: Classification loss: 0.015392, CORAL loss: 2.137711, Total_Loss: 0.015392\n",
            "[Test Source]: Epoch: 65, avg_loss: 0.0012, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 65, avg_loss: 2.7032, Accuracy: 342/795 (43.02%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 66 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.015410, CORAL loss: 3.143063, Total_Loss: 0.015410\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 66 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.006089, CORAL loss: 3.729641, Total_Loss: 0.006089\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 66 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.023427, CORAL loss: 1.745064, Total_Loss: 0.023427\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 66 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.010376, CORAL loss: 1.558179, Total_Loss: 0.010376\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 66 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.017458, CORAL loss: 2.156014, Total_Loss: 0.017458\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 66 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.013009, CORAL loss: 1.744538, Total_Loss: 0.013009\n",
            "[EPOCH] 66: Classification loss: 0.014295, CORAL loss: 2.346083, Total_Loss: 0.014295\n",
            "[Test Source]: Epoch: 66, avg_loss: 0.0014, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 66, avg_loss: 2.7314, Accuracy: 345/795 (43.40%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 67 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.025895, CORAL loss: 1.906018, Total_Loss: 0.025895\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 67 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.016518, CORAL loss: 2.730528, Total_Loss: 0.016518\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 67 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.016633, CORAL loss: 2.223058, Total_Loss: 0.016633\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 67 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.007438, CORAL loss: 1.717656, Total_Loss: 0.007438\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 67 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.011007, CORAL loss: 1.772005, Total_Loss: 0.011007\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 67 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.012048, CORAL loss: 2.578085, Total_Loss: 0.012048\n",
            "[EPOCH] 67: Classification loss: 0.014923, CORAL loss: 2.154558, Total_Loss: 0.014923\n",
            "[Test Source]: Epoch: 67, avg_loss: 0.0015, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 67, avg_loss: 2.7182, Accuracy: 346/795 (43.52%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 68 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.045909, CORAL loss: 1.667681, Total_Loss: 0.045909\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 68 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.021362, CORAL loss: 2.245968, Total_Loss: 0.021362\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 68 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.010564, CORAL loss: 1.369996, Total_Loss: 0.010564\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 68 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.015121, CORAL loss: 3.127677, Total_Loss: 0.015121\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 68 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.005591, CORAL loss: 2.841420, Total_Loss: 0.005591\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 68 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.010359, CORAL loss: 2.768569, Total_Loss: 0.010359\n",
            "[EPOCH] 68: Classification loss: 0.018151, CORAL loss: 2.336885, Total_Loss: 0.018151\n",
            "[Test Source]: Epoch: 68, avg_loss: 0.0017, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 68, avg_loss: 2.8040, Accuracy: 348/795 (43.77%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 69 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.009677, CORAL loss: 3.669425, Total_Loss: 0.009677\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 69 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.012964, CORAL loss: 1.803382, Total_Loss: 0.012964\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 69 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.017169, CORAL loss: 1.855725, Total_Loss: 0.017169\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 69 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.011348, CORAL loss: 4.602731, Total_Loss: 0.011348\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 69 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.012079, CORAL loss: 2.021697, Total_Loss: 0.012079\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 69 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.008945, CORAL loss: 2.340377, Total_Loss: 0.008945\n",
            "[EPOCH] 69: Classification loss: 0.012030, CORAL loss: 2.715556, Total_Loss: 0.012030\n",
            "[Test Source]: Epoch: 69, avg_loss: 0.0014, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 69, avg_loss: 2.7804, Accuracy: 346/795 (43.52%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 70 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.008592, CORAL loss: 1.608219, Total_Loss: 0.008592\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 70 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.013258, CORAL loss: 1.737276, Total_Loss: 0.013258\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 70 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.024085, CORAL loss: 1.978485, Total_Loss: 0.024085\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 70 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.026491, CORAL loss: 2.379755, Total_Loss: 0.026491\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 70 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.025377, CORAL loss: 2.753098, Total_Loss: 0.025377\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 70 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.009415, CORAL loss: 2.797709, Total_Loss: 0.009415\n",
            "[EPOCH] 70: Classification loss: 0.017870, CORAL loss: 2.209090, Total_Loss: 0.017870\n",
            "[Test Source]: Epoch: 70, avg_loss: 0.0011, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 70, avg_loss: 2.7207, Accuracy: 351/795 (44.15%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 71 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.011290, CORAL loss: 1.602738, Total_Loss: 0.011290\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 71 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.009779, CORAL loss: 1.887806, Total_Loss: 0.009779\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 71 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.013976, CORAL loss: 2.319935, Total_Loss: 0.013976\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 71 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.006377, CORAL loss: 1.981506, Total_Loss: 0.006377\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 71 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.016715, CORAL loss: 2.207290, Total_Loss: 0.016715\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 71 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.024460, CORAL loss: 3.443151, Total_Loss: 0.024460\n",
            "[EPOCH] 71: Classification loss: 0.013766, CORAL loss: 2.240405, Total_Loss: 0.013766\n",
            "[Test Source]: Epoch: 71, avg_loss: 0.0019, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 71, avg_loss: 2.7791, Accuracy: 343/795 (43.14%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 72 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.015822, CORAL loss: 2.302693, Total_Loss: 0.015822\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 72 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.009720, CORAL loss: 1.438252, Total_Loss: 0.009720\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 72 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.004154, CORAL loss: 1.103864, Total_Loss: 0.004154\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 72 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.064666, CORAL loss: 4.488245, Total_Loss: 0.064666\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 72 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.024138, CORAL loss: 3.391973, Total_Loss: 0.024138\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 72 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.014320, CORAL loss: 2.742861, Total_Loss: 0.014320\n",
            "[EPOCH] 72: Classification loss: 0.022137, CORAL loss: 2.577981, Total_Loss: 0.022137\n",
            "[Test Source]: Epoch: 72, avg_loss: 0.0019, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 72, avg_loss: 2.7412, Accuracy: 342/795 (43.02%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 73 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.003011, CORAL loss: 1.768344, Total_Loss: 0.003011\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 73 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.033236, CORAL loss: 1.855925, Total_Loss: 0.033236\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 73 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.032916, CORAL loss: 2.697759, Total_Loss: 0.032916\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 73 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.007119, CORAL loss: 3.722649, Total_Loss: 0.007119\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 73 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.005390, CORAL loss: 2.057566, Total_Loss: 0.005390\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 73 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.037802, CORAL loss: 2.042305, Total_Loss: 0.037802\n",
            "[EPOCH] 73: Classification loss: 0.019912, CORAL loss: 2.357425, Total_Loss: 0.019912\n",
            "[Test Source]: Epoch: 73, avg_loss: 0.0015, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 73, avg_loss: 2.9213, Accuracy: 331/795 (41.64%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 74 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.011884, CORAL loss: 2.524095, Total_Loss: 0.011884\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 74 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.040418, CORAL loss: 4.385340, Total_Loss: 0.040418\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 74 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.018025, CORAL loss: 2.175270, Total_Loss: 0.018025\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 74 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.036401, CORAL loss: 2.104283, Total_Loss: 0.036401\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 74 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.033433, CORAL loss: 2.082649, Total_Loss: 0.033433\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 74 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.010021, CORAL loss: 1.990296, Total_Loss: 0.010021\n",
            "[EPOCH] 74: Classification loss: 0.025030, CORAL loss: 2.543655, Total_Loss: 0.025030\n",
            "[Test Source]: Epoch: 74, avg_loss: 0.0016, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 74, avg_loss: 2.9125, Accuracy: 329/795 (41.38%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 75 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.012516, CORAL loss: 2.360048, Total_Loss: 0.012516\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 75 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.022272, CORAL loss: 1.517347, Total_Loss: 0.022272\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 75 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.018076, CORAL loss: 3.180087, Total_Loss: 0.018076\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 75 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.007657, CORAL loss: 2.031573, Total_Loss: 0.007657\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 75 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.013984, CORAL loss: 2.300789, Total_Loss: 0.013984\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 75 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.006201, CORAL loss: 2.237343, Total_Loss: 0.006201\n",
            "[EPOCH] 75: Classification loss: 0.013451, CORAL loss: 2.271198, Total_Loss: 0.013451\n",
            "[Test Source]: Epoch: 75, avg_loss: 0.0015, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 75, avg_loss: 2.8455, Accuracy: 332/795 (41.76%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 76 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.007642, CORAL loss: 2.085978, Total_Loss: 0.007642\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 76 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.026840, CORAL loss: 2.589818, Total_Loss: 0.026840\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 76 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.007729, CORAL loss: 2.693489, Total_Loss: 0.007729\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 76 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.012419, CORAL loss: 4.001004, Total_Loss: 0.012419\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 76 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.006006, CORAL loss: 2.495209, Total_Loss: 0.006006\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 76 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.008392, CORAL loss: 2.282075, Total_Loss: 0.008392\n",
            "[EPOCH] 76: Classification loss: 0.011505, CORAL loss: 2.691262, Total_Loss: 0.011505\n",
            "[Test Source]: Epoch: 76, avg_loss: 0.0010, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 76, avg_loss: 2.7540, Accuracy: 342/795 (43.02%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 77 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.009498, CORAL loss: 1.663931, Total_Loss: 0.009498\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 77 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.012755, CORAL loss: 1.930795, Total_Loss: 0.012755\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 77 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.018743, CORAL loss: 4.370639, Total_Loss: 0.018743\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 77 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.011338, CORAL loss: 2.524434, Total_Loss: 0.011338\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 77 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.003660, CORAL loss: 3.069704, Total_Loss: 0.003660\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 77 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.007768, CORAL loss: 2.124275, Total_Loss: 0.007768\n",
            "[EPOCH] 77: Classification loss: 0.010627, CORAL loss: 2.613963, Total_Loss: 0.010627\n",
            "[Test Source]: Epoch: 77, avg_loss: 0.0009, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 77, avg_loss: 2.6159, Accuracy: 365/795 (45.91%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 78 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.008471, CORAL loss: 2.317786, Total_Loss: 0.008471\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 78 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.012354, CORAL loss: 1.994840, Total_Loss: 0.012354\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 78 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.010852, CORAL loss: 4.312350, Total_Loss: 0.010852\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 78 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.023363, CORAL loss: 6.629038, Total_Loss: 0.023363\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 78 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.035788, CORAL loss: 2.533110, Total_Loss: 0.035788\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 78 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.008229, CORAL loss: 1.909067, Total_Loss: 0.008229\n",
            "[EPOCH] 78: Classification loss: 0.016510, CORAL loss: 3.282699, Total_Loss: 0.016510\n",
            "[Test Source]: Epoch: 78, avg_loss: 0.0009, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 78, avg_loss: 2.6197, Accuracy: 361/795 (45.41%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 79 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.012034, CORAL loss: 2.902430, Total_Loss: 0.012034\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 79 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.005299, CORAL loss: 1.647133, Total_Loss: 0.005299\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 79 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.057330, CORAL loss: 1.932648, Total_Loss: 0.057330\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 79 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.006812, CORAL loss: 3.430516, Total_Loss: 0.006812\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 79 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.010734, CORAL loss: 2.511070, Total_Loss: 0.010734\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 79 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.012779, CORAL loss: 2.342290, Total_Loss: 0.012779\n",
            "[EPOCH] 79: Classification loss: 0.017498, CORAL loss: 2.461015, Total_Loss: 0.017498\n",
            "[Test Source]: Epoch: 79, avg_loss: 0.0011, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 79, avg_loss: 2.7999, Accuracy: 360/795 (45.28%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 80 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.014348, CORAL loss: 2.539168, Total_Loss: 0.014348\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 80 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.015012, CORAL loss: 3.174442, Total_Loss: 0.015012\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 80 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.016182, CORAL loss: 2.689472, Total_Loss: 0.016182\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 80 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.041225, CORAL loss: 2.645205, Total_Loss: 0.041225\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 80 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.012623, CORAL loss: 3.192313, Total_Loss: 0.012623\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 80 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.049381, CORAL loss: 2.909026, Total_Loss: 0.049381\n",
            "[EPOCH] 80: Classification loss: 0.024795, CORAL loss: 2.858271, Total_Loss: 0.024795\n",
            "[Test Source]: Epoch: 80, avg_loss: 0.0007, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 80, avg_loss: 2.7506, Accuracy: 358/795 (45.03%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 81 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.012619, CORAL loss: 3.008305, Total_Loss: 0.012619\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 81 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.011235, CORAL loss: 2.600347, Total_Loss: 0.011235\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 81 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.026292, CORAL loss: 2.212039, Total_Loss: 0.026292\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 81 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.005571, CORAL loss: 3.134028, Total_Loss: 0.005571\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 81 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.029844, CORAL loss: 1.605528, Total_Loss: 0.029844\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 81 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.033556, CORAL loss: 3.694918, Total_Loss: 0.033556\n",
            "[EPOCH] 81: Classification loss: 0.019853, CORAL loss: 2.709194, Total_Loss: 0.019853\n",
            "[Test Source]: Epoch: 81, avg_loss: 0.0012, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 81, avg_loss: 2.6309, Accuracy: 348/795 (43.77%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 82 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.011744, CORAL loss: 3.818884, Total_Loss: 0.011744\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 82 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.048332, CORAL loss: 2.575624, Total_Loss: 0.048332\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 82 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.009803, CORAL loss: 3.126170, Total_Loss: 0.009803\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 82 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.006384, CORAL loss: 3.712167, Total_Loss: 0.006384\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 82 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.003024, CORAL loss: 2.027464, Total_Loss: 0.003024\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 82 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.013361, CORAL loss: 2.695602, Total_Loss: 0.013361\n",
            "[EPOCH] 82: Classification loss: 0.015442, CORAL loss: 2.992652, Total_Loss: 0.015442\n",
            "[Test Source]: Epoch: 82, avg_loss: 0.0019, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 82, avg_loss: 2.6334, Accuracy: 355/795 (44.65%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 83 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.005642, CORAL loss: 3.909874, Total_Loss: 0.005642\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 83 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.017690, CORAL loss: 3.402847, Total_Loss: 0.017690\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 83 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.026298, CORAL loss: 3.426991, Total_Loss: 0.026298\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 83 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.014463, CORAL loss: 3.783626, Total_Loss: 0.014463\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 83 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.009144, CORAL loss: 3.698034, Total_Loss: 0.009144\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 83 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.017689, CORAL loss: 1.677381, Total_Loss: 0.017689\n",
            "[EPOCH] 83: Classification loss: 0.015155, CORAL loss: 3.316459, Total_Loss: 0.015155\n",
            "[Test Source]: Epoch: 83, avg_loss: 0.0027, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 83, avg_loss: 2.6519, Accuracy: 356/795 (44.78%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 84 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.017722, CORAL loss: 3.622178, Total_Loss: 0.017722\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 84 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.019541, CORAL loss: 2.227539, Total_Loss: 0.019541\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 84 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.012537, CORAL loss: 2.339498, Total_Loss: 0.012537\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 84 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.010356, CORAL loss: 1.869759, Total_Loss: 0.010356\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 84 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.014232, CORAL loss: 3.220262, Total_Loss: 0.014232\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 84 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.019589, CORAL loss: 6.693928, Total_Loss: 0.019589\n",
            "[EPOCH] 84: Classification loss: 0.015663, CORAL loss: 3.328861, Total_Loss: 0.015663\n",
            "[Test Source]: Epoch: 84, avg_loss: 0.0027, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 84, avg_loss: 2.6691, Accuracy: 345/795 (43.40%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 85 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.004718, CORAL loss: 2.836966, Total_Loss: 0.004718\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 85 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.013532, CORAL loss: 1.725977, Total_Loss: 0.013532\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 85 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.024228, CORAL loss: 3.001908, Total_Loss: 0.024228\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 85 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.018357, CORAL loss: 2.520576, Total_Loss: 0.018357\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 85 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.004371, CORAL loss: 3.621538, Total_Loss: 0.004371\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 85 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.011183, CORAL loss: 2.168949, Total_Loss: 0.011183\n",
            "[EPOCH] 85: Classification loss: 0.012731, CORAL loss: 2.645986, Total_Loss: 0.012731\n",
            "[Test Source]: Epoch: 85, avg_loss: 0.0023, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 85, avg_loss: 2.5536, Accuracy: 356/795 (44.78%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 86 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.010736, CORAL loss: 3.378067, Total_Loss: 0.010736\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 86 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.017523, CORAL loss: 2.263748, Total_Loss: 0.017523\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 86 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.003446, CORAL loss: 1.772271, Total_Loss: 0.003446\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 86 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.009424, CORAL loss: 3.011845, Total_Loss: 0.009424\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 86 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.008619, CORAL loss: 1.613323, Total_Loss: 0.008619\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 86 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.023285, CORAL loss: 3.203790, Total_Loss: 0.023285\n",
            "[EPOCH] 86: Classification loss: 0.012172, CORAL loss: 2.540507, Total_Loss: 0.012172\n",
            "[Test Source]: Epoch: 86, avg_loss: 0.0024, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 86, avg_loss: 2.6147, Accuracy: 339/795 (42.64%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 87 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.022788, CORAL loss: 1.705120, Total_Loss: 0.022788\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 87 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.005983, CORAL loss: 3.012031, Total_Loss: 0.005983\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 87 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.007221, CORAL loss: 4.433520, Total_Loss: 0.007221\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 87 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.006496, CORAL loss: 4.486980, Total_Loss: 0.006496\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 87 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.017549, CORAL loss: 2.133733, Total_Loss: 0.017549\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 87 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.045083, CORAL loss: 2.570947, Total_Loss: 0.045083\n",
            "[EPOCH] 87: Classification loss: 0.017520, CORAL loss: 3.057055, Total_Loss: 0.017520\n",
            "[Test Source]: Epoch: 87, avg_loss: 0.0012, Accuracy: 2815/2817 (99.93%)\n",
            "[Test Target]: Epoch: 87, avg_loss: 2.5900, Accuracy: 346/795 (43.52%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 88 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.015096, CORAL loss: 2.701021, Total_Loss: 0.015096\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 88 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.013006, CORAL loss: 4.051409, Total_Loss: 0.013006\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 88 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.007903, CORAL loss: 2.928004, Total_Loss: 0.007903\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 88 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.003130, CORAL loss: 3.765069, Total_Loss: 0.003130\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 88 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.007251, CORAL loss: 3.031657, Total_Loss: 0.007251\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 88 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.004612, CORAL loss: 5.031679, Total_Loss: 0.004612\n",
            "[EPOCH] 88: Classification loss: 0.008500, CORAL loss: 3.584806, Total_Loss: 0.008500\n",
            "[Test Source]: Epoch: 88, avg_loss: 0.0012, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 88, avg_loss: 2.6655, Accuracy: 352/795 (44.28%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 89 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.003630, CORAL loss: 6.390502, Total_Loss: 0.003630\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 89 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.005102, CORAL loss: 2.757541, Total_Loss: 0.005102\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 89 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.007520, CORAL loss: 3.280616, Total_Loss: 0.007520\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 89 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.007809, CORAL loss: 2.995863, Total_Loss: 0.007809\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 89 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.007934, CORAL loss: 4.394015, Total_Loss: 0.007934\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 89 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.025661, CORAL loss: 2.199133, Total_Loss: 0.025661\n",
            "[EPOCH] 89: Classification loss: 0.009609, CORAL loss: 3.669612, Total_Loss: 0.009609\n",
            "[Test Source]: Epoch: 89, avg_loss: 0.0012, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 89, avg_loss: 2.7474, Accuracy: 344/795 (43.27%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 90 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.011153, CORAL loss: 2.749975, Total_Loss: 0.011153\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 90 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.020652, CORAL loss: 3.685089, Total_Loss: 0.020652\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 90 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.017285, CORAL loss: 3.856505, Total_Loss: 0.017285\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 90 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.002487, CORAL loss: 3.427758, Total_Loss: 0.002487\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 90 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.006512, CORAL loss: 3.587428, Total_Loss: 0.006512\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 90 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.017308, CORAL loss: 2.497735, Total_Loss: 0.017308\n",
            "[EPOCH] 90: Classification loss: 0.012566, CORAL loss: 3.300748, Total_Loss: 0.012566\n",
            "[Test Source]: Epoch: 90, avg_loss: 0.0007, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 90, avg_loss: 2.7171, Accuracy: 340/795 (42.77%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 91 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.005485, CORAL loss: 2.332687, Total_Loss: 0.005485\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 91 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.003076, CORAL loss: 4.066303, Total_Loss: 0.003076\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 91 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.011455, CORAL loss: 2.550611, Total_Loss: 0.011455\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 91 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.003614, CORAL loss: 3.822703, Total_Loss: 0.003614\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 91 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.010450, CORAL loss: 1.750438, Total_Loss: 0.010450\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 91 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.022380, CORAL loss: 3.499277, Total_Loss: 0.022380\n",
            "[EPOCH] 91: Classification loss: 0.009410, CORAL loss: 3.003670, Total_Loss: 0.009410\n",
            "[Test Source]: Epoch: 91, avg_loss: 0.0007, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 91, avg_loss: 2.7938, Accuracy: 346/795 (43.52%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 92 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.002729, CORAL loss: 4.926181, Total_Loss: 0.002729\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 92 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.005450, CORAL loss: 6.337136, Total_Loss: 0.005450\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 92 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.016983, CORAL loss: 3.198832, Total_Loss: 0.016983\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 92 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.013470, CORAL loss: 1.793052, Total_Loss: 0.013470\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 92 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.010629, CORAL loss: 4.116849, Total_Loss: 0.010629\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 92 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.005656, CORAL loss: 2.840380, Total_Loss: 0.005656\n",
            "[EPOCH] 92: Classification loss: 0.009153, CORAL loss: 3.868738, Total_Loss: 0.009153\n",
            "[Test Source]: Epoch: 92, avg_loss: 0.0007, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 92, avg_loss: 2.7268, Accuracy: 352/795 (44.28%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 93 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.002497, CORAL loss: 3.048733, Total_Loss: 0.002497\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 93 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.004455, CORAL loss: 3.630752, Total_Loss: 0.004455\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 93 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.008443, CORAL loss: 2.720904, Total_Loss: 0.008443\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 93 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.036618, CORAL loss: 2.760812, Total_Loss: 0.036618\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 93 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.005235, CORAL loss: 6.012688, Total_Loss: 0.005235\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 93 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.007169, CORAL loss: 3.507951, Total_Loss: 0.007169\n",
            "[EPOCH] 93: Classification loss: 0.010736, CORAL loss: 3.613640, Total_Loss: 0.010736\n",
            "[Test Source]: Epoch: 93, avg_loss: 0.0006, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 93, avg_loss: 2.6420, Accuracy: 359/795 (45.16%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 94 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.013261, CORAL loss: 3.145736, Total_Loss: 0.013261\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 94 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.007906, CORAL loss: 4.078452, Total_Loss: 0.007906\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 94 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.002612, CORAL loss: 5.781577, Total_Loss: 0.002612\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 94 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.004163, CORAL loss: 2.382611, Total_Loss: 0.004163\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 94 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.001033, CORAL loss: 5.532717, Total_Loss: 0.001033\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 94 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.004513, CORAL loss: 2.553817, Total_Loss: 0.004513\n",
            "[EPOCH] 94: Classification loss: 0.005581, CORAL loss: 3.912485, Total_Loss: 0.005581\n",
            "[Test Source]: Epoch: 94, avg_loss: 0.0006, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 94, avg_loss: 2.7116, Accuracy: 355/795 (44.65%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 95 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.001920, CORAL loss: 3.090366, Total_Loss: 0.001920\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 95 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.007911, CORAL loss: 2.771926, Total_Loss: 0.007911\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 95 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.021283, CORAL loss: 3.742239, Total_Loss: 0.021283\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 95 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.003053, CORAL loss: 2.924004, Total_Loss: 0.003053\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 95 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.003800, CORAL loss: 7.198248, Total_Loss: 0.003800\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 95 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.004949, CORAL loss: 2.770615, Total_Loss: 0.004949\n",
            "[EPOCH] 95: Classification loss: 0.007152, CORAL loss: 3.749566, Total_Loss: 0.007152\n",
            "[Test Source]: Epoch: 95, avg_loss: 0.0008, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 95, avg_loss: 2.7291, Accuracy: 362/795 (45.53%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 96 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.008641, CORAL loss: 2.975271, Total_Loss: 0.008641\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 96 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.024260, CORAL loss: 3.100252, Total_Loss: 0.024260\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 96 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.005941, CORAL loss: 2.335893, Total_Loss: 0.005941\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 96 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.017179, CORAL loss: 5.725026, Total_Loss: 0.017179\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 96 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.018702, CORAL loss: 2.743376, Total_Loss: 0.018702\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 96 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.048821, CORAL loss: 3.672092, Total_Loss: 0.048821\n",
            "[EPOCH] 96: Classification loss: 0.020591, CORAL loss: 3.425319, Total_Loss: 0.020591\n",
            "[Test Source]: Epoch: 96, avg_loss: 0.0006, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 96, avg_loss: 2.7635, Accuracy: 361/795 (45.41%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 97 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.003689, CORAL loss: 2.671918, Total_Loss: 0.003689\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 97 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.016425, CORAL loss: 3.272263, Total_Loss: 0.016425\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 97 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.008396, CORAL loss: 2.694887, Total_Loss: 0.008396\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 97 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.002077, CORAL loss: 4.590810, Total_Loss: 0.002077\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 97 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.009703, CORAL loss: 2.407173, Total_Loss: 0.009703\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 97 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.016010, CORAL loss: 3.461265, Total_Loss: 0.016010\n",
            "[EPOCH] 97: Classification loss: 0.009383, CORAL loss: 3.183053, Total_Loss: 0.009383\n",
            "[Test Source]: Epoch: 97, avg_loss: 0.0006, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 97, avg_loss: 2.7232, Accuracy: 351/795 (44.15%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 98 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.006201, CORAL loss: 3.442788, Total_Loss: 0.006201\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 98 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.004488, CORAL loss: 4.185667, Total_Loss: 0.004488\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 98 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.018586, CORAL loss: 3.687187, Total_Loss: 0.018586\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 98 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.006003, CORAL loss: 2.902515, Total_Loss: 0.006003\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 98 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.005953, CORAL loss: 3.731707, Total_Loss: 0.005953\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 98 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.024528, CORAL loss: 2.618881, Total_Loss: 0.024528\n",
            "[EPOCH] 98: Classification loss: 0.010960, CORAL loss: 3.428124, Total_Loss: 0.010960\n",
            "[Test Source]: Epoch: 98, avg_loss: 0.0006, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 98, avg_loss: 2.7405, Accuracy: 345/795 (43.40%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 99 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.007684, CORAL loss: 3.604685, Total_Loss: 0.007684\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 99 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.006469, CORAL loss: 3.899533, Total_Loss: 0.006469\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 99 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.003396, CORAL loss: 3.364886, Total_Loss: 0.003396\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 99 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.004632, CORAL loss: 2.213176, Total_Loss: 0.004632\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 99 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.003393, CORAL loss: 3.546883, Total_Loss: 0.003393\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 99 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.014802, CORAL loss: 2.749525, Total_Loss: 0.014802\n",
            "[EPOCH] 99: Classification loss: 0.006729, CORAL loss: 3.229781, Total_Loss: 0.006729\n",
            "[Test Source]: Epoch: 99, avg_loss: 0.0008, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 99, avg_loss: 2.8306, Accuracy: 342/795 (43.02%)\n",
            "HBox(children=(IntProgress(value=0, max=6), HTML(value='')))\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 100 [ 1/ 6]\tLambda value: 0.0000, Classification loss: 0.036344, CORAL loss: 2.067363, Total_Loss: 0.036344\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 100 [ 2/ 6]\tLambda value: 0.0000, Classification loss: 0.003471, CORAL loss: 4.340016, Total_Loss: 0.003471\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 100 [ 3/ 6]\tLambda value: 0.0000, Classification loss: 0.028368, CORAL loss: 3.454838, Total_Loss: 0.028368\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 100 [ 4/ 6]\tLambda value: 0.0000, Classification loss: 0.006455, CORAL loss: 3.442291, Total_Loss: 0.006455\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 100 [ 5/ 6]\tLambda value: 0.0000, Classification loss: 0.011491, CORAL loss: 1.964538, Total_Loss: 0.011491\n",
            "CUDA: True\n",
            "compute covariance bath size n: 128\n",
            "compute covariance bath size n: 128\n",
            "Train Epoch: 100 [ 6/ 6]\tLambda value: 0.0000, Classification loss: 0.001730, CORAL loss: 2.744386, Total_Loss: 0.001730\n",
            "[EPOCH] 100: Classification loss: 0.014643, CORAL loss: 3.002238, Total_Loss: 0.014643\n",
            "[Test Source]: Epoch: 100, avg_loss: 0.0006, Accuracy: 2816/2817 (99.96%)\n",
            "[Test Target]: Epoch: 100, avg_loss: 2.9735, Accuracy: 341/795 (42.89%)\n",
            "\n",
            "saving training without adaptation...\n",
            "[INFO] Object saved to no_adaptation_training_statistic.pkl\n",
            "[INFO] Object saved to no_adaptation_testing_s_statistic.pkl\n",
            "[INFO] Object saved to no_adaptation_testing_t_statistic.pkl\n",
            "checkpoint saved in no_adaptation_checkpoint.tar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b1HlY7yypWT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b5932858-d178-4346-a6b3-ca3c23bb6c22"
      },
      "source": [
        "import torch\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "\n",
        "def plot_loss_acc():\n",
        "  pass\n",
        "\n",
        "# load dictionaries with log information\n",
        "path_adapt_log = [\"/content/adaptation_training_statistic.pkl\",\n",
        "                  \"/content/adaptation_testing_s_statistic.pkl\",\n",
        "                  \"/content/adaptation_testing_t_statistic.pkl\"]\n",
        "\n",
        "path_no_adapt_log = [\"/content/no_adaptation_training_statistic.pkl\",\n",
        "                     \"/content/no_adaptation_testing_s_statistic.pkl\",\n",
        "                     \"/content/no_adaptation_testing_t_statistic.pkl\"]\n",
        "\n",
        "adapt_training_dict = pickle.load(open(path_adapt_log[0], 'rb'))\n",
        "adapt_testing_source_dict = pickle.load(open(path_adapt_log[1], 'rb'))\n",
        "adapt_testing_target_dict = pickle.load(open(path_adapt_log[2], 'rb'))\n",
        "\n",
        "no_adapt_training_dict = pickle.load(open(path_no_adapt_log[0], 'rb'))\n",
        "no_adapt_testing_source_dict = pickle.load(open(path_no_adapt_log[1], 'rb'))\n",
        "no_adapt_testing_target_dict = pickle.load(open(path_no_adapt_log[2], 'rb'))\n",
        "\n",
        "adaptation = {\n",
        "    \"classification_loss\": [],\n",
        "    \"coral_loss\": [],\n",
        "    \"source_accuracy\": [],\n",
        "    \"target_accuracy\": []\n",
        "}\n",
        "\n",
        "no_adaptation = {\n",
        "    \"source_accuracy\": [],\n",
        "    \"target_accuracy\": []\n",
        "}\n",
        "\n",
        "# get average coral and classification loss for steps in each epoch\n",
        "for epoch_idx in range(len(adapt_training_dict)): # epoch\n",
        "  coral_loss = 0\n",
        "  class_loss = 0\n",
        "\n",
        "  for step_idx in range(len(adapt_training_dict[epoch_idx])):\n",
        "    coral_loss += adapt_training_dict[epoch_idx][step_idx][\"coral_loss\"]\n",
        "    class_loss += adapt_training_dict[epoch_idx][step_idx][\"classification_loss\"]\n",
        "\n",
        "  # store average losses and accuracies in adaptation dictionary\n",
        "  adaptation[\"classification_loss\"].append(class_loss/len(adapt_training_dict[epoch_idx]))\n",
        "  adaptation[\"coral_loss\"].append(coral_loss/len(adapt_training_dict[epoch_idx]))\n",
        "  adaptation[\"source_accuracy\"].append(adapt_testing_source_dict[epoch_idx][\"accuracy %\"])\n",
        "  adaptation[\"target_accuracy\"].append(adapt_testing_target_dict[epoch_idx][\"accuracy %\"])\n",
        "\n",
        "  # store accuracies in no-adaptation dictionary\n",
        "  no_adaptation[\"source_accuracy\"].append(no_adapt_testing_source_dict[epoch_idx][\"accuracy %\"])\n",
        "  no_adaptation[\"target_accuracy\"].append(no_adapt_testing_target_dict[epoch_idx][\"accuracy %\"])\n",
        "\n",
        "# plot accuracies for test data in source and target domains\n",
        "fig=plt.figure(figsize=(8, 6), dpi=100)\n",
        "fig.show()\n",
        "\n",
        "plt.xlabel(\"epochs\", fontsize=15)\n",
        "plt.ylabel(\"classification accuracy (%)\", fontsize=15)\n",
        "\n",
        "plt.plot(adaptation['target_accuracy'], label=\"test acc. w/ coral loss\", marker='*', markersize=8)\n",
        "plt.plot(no_adaptation['target_accuracy'], label=\"test acc. w/o coral loss\", marker='.', markersize=8)\n",
        "\n",
        "plt.plot(adaptation['source_accuracy'], label=\"training acc. w/ coral loss\", marker='^', markersize=8)\n",
        "plt.plot(no_adaptation['source_accuracy'], label=\"training acc. w/o coral loss\", marker='+', markersize=8)\n",
        "\n",
        "plt.legend(loc=\"best\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "fig.savefig(\"/content/webcam_to_amazon_test_train_accuracies.jpg\")\n",
        "\n",
        "# plot accuracies for test data in source and target domains\n",
        "fig=plt.figure(figsize=(8, 6), dpi=100)\n",
        "fig.show()\n",
        "\n",
        "plt.xlabel(\"epochs\", fontsize=15)\n",
        "plt.ylabel(\"classification accuracy (%)\", fontsize=15)\n",
        "\n",
        "plt.plot(adaptation[\"classification_loss\"], label=\"classification_loss\", marker='*', markersize=8)\n",
        "plt.plot(adaptation[\"coral_loss\"], label=\"coral_loss\", marker='.', markersize=8)\n",
        "\n",
        "plt.legend(loc=\"best\")\n",
        "plt.grid()\n",
        "plt.show()\n",
        "fig.savefig(\"/content/webcam_to_amazon_train_losses.jpg\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr0AAAIKCAYAAAAu6/cVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAArkAAAIKCAYAAAAnAFdvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXBERERHJOQpyRURERCTn/D/VCCMeFU3+xwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Rz8qGcUNJPC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}